# Inferencia estadística

A grandes rasgos, en la inferencia estadística buscamos hacer afirmaciones acerca 
de una colección de datos de la cual sólo tenemos información parcial.

Nos concentraremos en dos de las situaciones más comunes:

1. **Inferencia a poblaciones**: el proceso generador de datos "selecciona" a algunos
elementos de una población, y queremos decir algo acerca de la población completa.

Por ejemplo, consideremos esta población de 15 personas:

```{r}
#| echo: false
#| warning: false
#| message: false
library(tidyverse)
library(gt)
theme_set(theme_minimal())
source("R/funciones_auxiliares_notas.R")
pob_1 <- tibble(id = 1:15, 
       edad = sample(18:65, 15),
       estatura = c(1.58, 1.72, 1.64, 1.50, rep(NA, 11)),
       peso = c(60, 72, 56, 60, rep(NA, 11))
       )
pob_1 |> gt()
```

Para una muestra de ellos tenemos información acerca de su estatura y peso.
¿Qué podríamos decir acerca de la estatura y el peso de la población general?

2. **Inferencia causal**: el proceso generador "asigna" tratamientos a una población o parte
de ella, y quisiéramos saber cómo se comportarían las unidades tratadas si no recibieran
tratamiento, y también cómo se comportarían unidades no tratadas si recibieran el tratamiento.

En este caso, la situación se ve como sigue. Imaginemos que tenemos 15 personas con
dolor de cabeza, y obtenemos los siguientes datos:

```{r}
#| echo: false
pob_2 <- tibble(id = 1:15, 
       edad = sample(18:65, 15),
       tomo_aspirina = sample(c(0, 1), 15, replace = TRUE)) |> 
  mutate(dolor_con_aspirina = ifelse(tomo_aspirina == 1, 6, NA)) |> 
  mutate(dolor_sin_aspirina = ifelse(tomo_aspirina == 0, 3, NA)) |> 
  mutate(dolor = ifelse(tomo_aspirina == 1, dolor_con_aspirina, dolor_sin_aspirina)) |> 
  select(id, edad, dolor_con_aspirina, dolor_sin_aspirina, tomo_aspirina, dolor)
pob_2 |> gt()
```

Nuestra pregunta en este caso es del tipo: ¿ayuda la aspirina a reducir el dolor de cabeza en esta población? ¿qué tanto ayuda? Igualmente, tenemos información incompleta, en el sentido de que
sólo observamos un resultado potencial de cada persona, dependiendo
de si tomó aspirina o no. Si supiéramos los dos resultados potenciales de cada persona
entonces podríamos contestar la pregunta sin dificultad.


::: callout-note
## Datos incompletos e incertidumbre

Casi por regla general, el hecho de que tengamos datos incompletos
implica que una respuesta apropiada a la pregunta incorporará cierto
grado de incertidumbre.

Entender si es posible producir respuestas precisas a nuestras preguntas,
y si es posible cuantificar correctamente la incertidumbre na la respuesta
es una tarea central en la estadística.

:::


## Proceso de selección o asignación

Las preguntas que planteamos arriba son difíciles de contestar cuando no
conocemos bien el proceso de selección de individuos en la muestra o no
conocemos el proceso de asignación de la aspirina. 

Por ejemplo, llegaríamos a conclusiones muy distintas si nos dijeran que:


1. Escogimos las 5 personas que usan ropa talla chica.
2. Escogimos las 5 personas que llegaron primero en una carrera de 100 metros.
3. Escogimos las personas cuyo día de nacimiento era más bajo.

O en el ejemplo de la aspirina,

1. Sólo dimos aspirinas a las personas que reportaron un nivel de dolor de cabeza muy alto.
2. Solo dimos aspirina a las personas que llegaron primero en una carrera de 100 metros.
3. Dimos una aspirina exclusivamente a las personas cuyo día de nacimiento es par.

::: callout-tip

Discute qué conclusiones podrías llegar en cada uno de estos escenarios.

:::

Los casos 1 y 2 en ambas poblaciones son en general difíciles de resolver
adecuadamente, y explicaremos con más ejemplos. Adicionalmente, es también más difícil
cuantificar el nivel de incertidumbre de nuestras respuestas, pues dependen de muchos
detalles del proceso de selección o asignación.

::: callout-tip
## Proceso generador de datos

Cuando el proceso de selección de observaciones o asignación tiene relaciones complicadas
con las cantidades de interés, puede ser muy difícil dar respuesta a preguntas
inferenciales de manera adecuada, y es importante entender el **proceso que 
genera los datos**, muchas veces a un nivel muy detallado.

:::


## Procesos generadores de datos e inferencia causal

Consideramos los datos de ENLACE (2011), y en particular los resultados promedio 
de matemáticas en sexto grado por escuela. ENLACE era una prueba que se aplicaba
en todas las escuelas, de forma que tenemos información de la población completa
de interés.

Nos interesa saber cómo varían los resultados en función de el tipo de primaria:
pública o privada. 


El rango
de la calificación de matemáticas para un alumno es de 0-800, y aproximadamente
la mitad de los alumnos califica en el rengo de 450 a 550. Vemos dispersión
considerable en las calificaciones de las escuelas, y diferencias considerables 
entre tipo de escuelas:

```{r, message = FALSE, echo = FALSE}
enlace <- read_csv("datos/enlace.csv")
enlace <- enlace |>  filter(num_evaluados_total > 0, mate_6 > 0) |>
    mutate(marginacion = fct_reorder(marginacion, mate_6, median)) |> 
    mutate(tipo = recode(tipo, `INDÍGENA`="Indígena/Conafe", CONAFE="Indígena/Conafe", GENERAL="General", PARTICULAR="Particular")) |> 
    mutate(tipo = fct_reorder(tipo, mate_6, mean)) 
```

```{r, message = FALSE}
enlace_tbl <- enlace |> group_by(tipo) |> 
    summarise(n_escuelas = n(),
              cuantiles = list(cuantil(mate_6, c(0.05, 0.25, 0.5, 0.75, 0.95)))) |> 
    unnest(cols = cuantiles) |> mutate(valor = round(valor)) 
enlace_tbl |> spread(cuantil, valor) |>  formatear_tabla()
```

Podemos graficar de varias maneras, por ejemplo, mostrando los cuantiles 0.05, 0.25, 0.5, 0.75 y 0.95:


```{r, fig.width = 10, fig.height = 6, echo = FALSE, message = FALSE}
g_medianas <- ggplot(enlace_tbl %>% filter(cuantil == 0.50), aes(x = tipo, y = valor)) +
    geom_point(colour = "red") + ylim(c(150,880)) + labs(subtitle = "Gráfica 1")
g_80_p <- ggplot(enlace_tbl  %>% spread(cuantil,valor), aes(x = tipo, y = `0.5`)) +
    geom_linerange(aes(ymin= `0.05`, ymax = `0.95`), colour = "gray40") +
    geom_linerange(aes(ymin= `0.25`, ymax = `0.75`), size = 2, colour = "white") +
    geom_point(colour = "red", size = 3) +
     ylim(c(150,880)) + labs(subtitle = "Gráfica 1")+
    ylab("Promedios Matemáticas")
g_80_p
```


Y vemos que las escuelas privadas tienen mejor resultados que las públicas por
un margen considerable. Ahora preguntamos: ¿la calidad de las escuelas es lo 
que *causa* estos resultados? Por ejemplo, ¿si cambiáramos un niño de una escuela
pública a una privada su resultado sería mejor? 

Es dificil contestar esta pregunta, porque no entendemos el proceso generador
de datos que asigna niños a escuelas. Una posible hipótesis de cómo se asigna el 
tratamiento y cómo se relaciona con la calificación en Enlace:

```{r}
library(dagitty)
library(ggdag)
dag_cafe <- dagitty('dag{"Escuela" [exposure,pos="-3,3"]
  "Calif" [outcome,pos="3,3"]
  "Marginación" [pos="0,1"]
  "Educación padres" [pos = "2,2"]
  "Recursos escolares" [pos = "0,4"]
  "Marginación"  -> "Escuela"
    "Escuela" -> "Calif"
    "Marginación" -> "Educación padres" -> "Calif"
    "Escuela" -> "Recursos escolares" -> "Calif"
  }')
dag_cafe_tidy <- tidy_dagitty(dag_cafe) #|> 
  #mutate(tipo = ifelse(name == "Cafe" & to == "Cancer", "dotted", "solid"))
dag_cafe_tidy |>
  ggplot(aes(x = x, y = y, xend = xend, yend = yend )) + 
  geom_dag_edges() +
  geom_dag_point(colour = "salmon", size = 20) +
  geom_dag_text(colour = "gray20") +
  theme_dag()
```
- El grado de marginación del hogar de un estudiante influye en el tipo de escuela
al que asiste.
- Pero también influye en la calificación que obtiene el estudiante, por ejemplo
actuando mediante el nivel de educación de los padres.
- Esto implica que cuando cruzamos tipo de escuela y calificación obtenida, en parte
estamos viendo el efecto que la escuela tiene en los estudiantes, pero también un
efecto común de la marginación.
- La comparación entre tipos de escuelas está sesgada si el propósito es estimar
el efecto de tipo de escuela en los resultados de los estudiantes.


```{r}
#| message: false
#| warning: false
enlace_tbl_marg <- enlace %>% 
    group_by(tipo, marginacion) %>% 
    summarise(n_alumnos = sum(num_evaluados_total),
              cuantiles = list(cuantil(mate_6, c(0.05, 0.25, 0.5, 0.75, 0.95)))) %>% 
    unnest(cols = cuantiles) %>% mutate(valor = round(valor)) %>% 
    filter( n_alumnos > 20)
```

Podemos considerar el grado de marginación del municipio donde está cada escuela,
y vemos la diferencia tan grande se debe en parte a las escuelas privadas tienden estar
en municipios de baja marginación. Por ejemplo, los promedios no son tan diferentes
para escuelas públicas en zonas de marginación muy baja comparado con escuelas privadas
en zonas de marginación alta:

```{r, fig.width = 10, fig.height = 4, echo = FALSE}
g_80_p <- ggplot(enlace_tbl_marg  |>  spread(cuantil, valor), 
                                     aes(x = marginacion, y = `0.5`)) +
    geom_linerange(aes(ymin= `0.05`, ymax = `0.95`), colour = "gray40") +
    geom_linerange(aes(ymin= `0.25`, ymax = `0.75`), size = 2, colour = "white") +
    geom_point(colour = "red", aes(size = log10(n_alumnos/1000))) +
    ylab("Promedios Matemáticas") + facet_wrap(~tipo, nrow = 1) +
    theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
    scale_size_continuous(name = "Miles de \nAlumnos",
                          breaks = c(-0.3, 0, 1, 2, 2.7),
                          labels = c(0.5, 1, 10, 100, 500)) 
g_80_p
```

En esta nueva comparación, existen muchos otros factores que probablemente tenemos que
pensar, algunos de ellos no estarán disponibles en los datos, y otros puede que se escapen
de nuestra consideración. 

- El problema central en este análisis es que el proceso generador de datos, en cuanto
a quíen le toca ir a cada escuela, es complejo. 
- Hacer inferencia causal en este caso es retador y
depende de varios supuestos **que no son estadísticos**.





## Procesos generadores de datos 2: inferencia causal

En un estudio de 1981, investigadores reportaron una
asociación de cáncer de páncreas con consumo de café. Sus resultados agregados
fueron:

```{r}
tab_cafe <- crossing(num_tazas = c(0, 1.5, 3.5, 5), enf_pancreas = c("si", "no")) |> 
  mutate(n = c(88, 20, 271, 153, 154, 106, 88, 130))
tab_cafe |> pivot_wider(names_from = enf_pancreas, values_from = n) |> 
  mutate(prop_si = si / (no + si))
```

Lo que indica una *asociación* fuerte entre consumo de café y proporción de pacientes
con cáncer de páncres. Los pacientes fueron entrevistados en varios hospitales. Se 
seleccionaron pacientes con cáncer de páncreas y
pacientes control fueron entrevistados que corresponden a los mismos doctores. 
En el artículo señala que por la 
naturaleza de las enfermedades, había una cantidad considerable de pacientes control
con condiciones gastrointestinales.

En este caso, el proceso de asignación de quién toma café y cuánto toma es complicado.
Sabemos sin embargo que:

- Pacientes con problemas gastrointestinales muchas veces tienen dietas restringidas y no se les permite tomar café, o sólo o una cantidad baja de café.
- Las razones para ser seleccionados con más alta probabilidad en el estudio son: tener cáncer de páncreas, o tener otros problemas gastrointestinales. 

Estas tres relaciones causales podemos representarlas como sigue:


```{r}
library(dagitty)
library(ggdag)
dag_cafe <- dagitty('dag{Cafe [exposure,pos="-1,-2"]
  Cancer [outcome,pos="1,-2"]
  Entrevistado [pos="0,-3"]
  Gastro [pos="-1,-2.5"]
  Gastro -> Cafe
  Cancer -> Entrevistado; Gastro  -> Entrevistado; Cafe -> Cancer}')
dag_cafe_tidy <- tidy_dagitty(dag_cafe) |> 
  mutate(tipo = ifelse(name == "Cafe" & to == "Cancer", "dotted", "solid"))
dag_cafe_tidy |>
  ggplot(aes(x = x, y = y, xend = xend, yend = yend, colour = tipo )) + 
  geom_dag_edges(aes(edge_linetype = tipo)) +
  geom_dag_point(colour = "salmon") +
  geom_dag_text(colour = "gray20") +
  theme_dag()
```

Las consecuencias de estas tres relaciones casuales es la siguiente:
si alguien es entrevistado,
puede ser por dos razones diferentes: tiene cáncer, o si no tiene cáncer,
tiene probabilidad alta de tener problemas gastrointestinales. Esto 
último 
implica, por restricciones de dieta, que tienden a tomar menos café. Con esto, hemos
demostrado que con este esquema de selección puede aparecer naturalmente una asociación entre cáncer y consumo de café, **aún cuando no exista una relación causal entre tomar
café y cáncer de páncreas**.

El problema es que la exposición a nuestro "tratamiento" está siendo influida
por una variable que tiene asociación con nuestro "resultado". Esto puede pasar
de diferentes maneras. Quizá en este ejemplo podemos controlar por enfermedad
gastrointestinal, pero no podemos estar seguros que no existan otras dificultades:
por ejemplo, si café estuviera asociado con fumar, entonces esa podría ser
otra razón por la que observaríamos una relación entre cáncer y café aún cuando
no haya relación causal entre estas dos variables.

Sin embargo, si aleatorizamos el tratamiento, la situación se hace mucho más 
simple. Si pudiéramos escoger a un grupo de personas, y asignar un grupo a tomar café y
otro grupo a no tomarlo, tendríamos el diagrama:

```{r}
dag_cafe <- dagitty("dag{Gastro -> Cafe;  Cafe -> Cancer}")
dag_cafe_tidy <- tidy_dagitty(dag_cafe) |> 
  mutate(tipo = ifelse(name == "Cafe" & to == "Cancer", "dotted", "solid"))
dag_cafe_tidy |>
  ggplot(aes(x = x, y = y, xend = xend, yend = yend, colour = tipo )) + 
  geom_dag_edges(aes(edge_linetype = tipo)) +
  geom_dag_point(colour = "salmon") +
  geom_dag_text(colour = "gray20") +
  theme_dag()
```

Y en este caso, podemos ver directamente la relación causal entre café y cáncer,
aún cuando problemas gastrointestinales pueden afectar la asignación del tratamiento.


## Procesos generadores de datos e inferencia a poblaciones

En el siguiente ejemplo, consideramos el problema del Conteo Rápido en 
las elecciones presidenciales de 2018. El Conteo Rápido busca estimar con precisión
los resultados finales de las elecciones en el mismo día que se lleva a cabo
la votación, y se basa en una muestra aleatoria de casillas seleccionadas.

Supongamos que decidimos hacer una estimación con las casillas que han sido 
reportadas a cierta hora de la jornada electoral, que son una fracción de las casillas
totales.

¿Cómo podemos estimar, por ejemplo, la participación ciudadana con estos datos?



El tiempo de arribo de las casillas depende de procesos que no controlamos, como
es el conteo de los votos en esas casillas, eventos metereológicos que dificultan la
transimisión de datos, etc. En algunos casos, quisiéramos reportar resultados aún cuando
no haya llegado la muestra completa.

```{r}
#| warning: false
#| message: false
computos_pres <- read_delim("datos/conteo_rapido/presidencia.csv", 
    skip = 6, delim = "|") |> 
  mutate(lista_nominal = as.numeric(LISTA_NOMINAL_CASILLA)) 

sum(computos_pres$TOTAL_VOTOS_CALCULADOS)  
sum(computos_pres$lista_nominal, na.rm = TRUE)
estratificacion_tbl <-  computos_pres |> 
  select(CLAVE_CASILLA, ID_ESTADO, ID_DISTRITO) |>
  filter(ID_DISTRITO != 0) |> 
  mutate(estrato = interaction(ID_ESTADO, ID_DISTRITO)) |> 
  count(estrato)
```


```{r}
#| warning: false
#| message: false
remesa_tbl <- read_delim("datos/conteo_rapido/REMESAS0100020000.txt", 
  skip = 1, delim = "|") |> 
  mutate(tiempo_llegada = lubridate::ymd_hms(paste(ANIO, MES, DIA, HORA, MINUTOS, SEGUNDOS, sep = "-"),
                             tz = "America/Mexico_City")) |> 
  mutate(estrato = interaction(iD_ESTADO, ID_DISTRITO_FEDERAL)) |> 
  select(estrato, TOTAL, JAMK, RAC, AMLO, tiempo_llegada) |>
  left_join(estratificacion_tbl)
remesa_9_tbl <- filter(remesa_tbl, tiempo_llegada <= lubridate::ymd_hms("2018-07-01-20-00-00", tz = "America/Mexico_City"))
```



```{r}
# extrae muestra bootstrap estratificada
extraer_bootstrap <- function(muestra, var_estrato){
  remuestra <- muestra |> 
    group_by({{ var_estrato }}) |> 
    slice_sample( prop = 1, replace = TRUE) |> 
    ungroup()
  remuestra
}
# cálculo del estimador de razón para una muestra
estimar_razon <- function(muestra, num, denom, var_estrato){
  estimador <- muestra |> 
    group_by({{ var_estrato }}) |> 
    summarise(candidato = mean({{ num }}), total = mean({{ denom }}), n = first(n)) |> 
    mutate(candidato = n * candidato, total = n * total) |> 
    ungroup() |> 
    summarise(prop = sum(candidato) / sum(total))
  estimador$prop
}
```


```{r}
remuestreo_tbl <- map_df(1:500, function(rep){
  remuestra <- extraer_bootstrap(remesa_9_tbl, estrato)
  estimador_rac <- estimar_razon(remuestra, RAC, TOTAL, estrato)
  estimador_amlo <- estimar_razon(remuestra, AMLO, TOTAL, estrato)
  estimador_jamk <- estimar_razon(remuestra, JAMK, TOTAL, estrato)
  tibble(rep = rep, RAC = estimador_rac, AMLO = estimador_amlo,
         JAMK = estimador_jamk)
})
```

```{r}
computos_finales <- tibble(candidato = c("RAC", "JAMK", "AMLO"), prop = c(0.2227, 0.164099, 0.531936))
resumen_1 <- remuestreo_tbl |> summarise(across(RAC:JAMK, quantile, probs = c(0.025, 0.975))) |> 
  mutate(tipo = c("inf", "sup")) |> 
  pivot_longer(RAC:JAMK, names_to = "candidato", values_to = "prop") |> 
  pivot_wider(names_from = tipo, values_from = prop) |> mutate(remesa = "8:30pm")

```

Como vemos, los resultados con esta muestra parcial subestima severamente 
a un candidato, y sobreestima a otro, aún cuando la muestra ha sido 
ponderada para representar los distintos distritos electorales. Sin embargo,
las estimaciones con muestra completa son las siguientes:


```{r}
remuestreo_tbl <- map_df(1:500, function(rep){
  remuestra <- extraer_bootstrap(remesa_tbl, estrato)
  estimador_rac <- estimar_razon(remuestra, RAC, TOTAL, estrato)
  estimador_amlo <- estimar_razon(remuestra, AMLO, TOTAL, estrato)
  estimador_jamk <- estimar_razon(remuestra, JAMK, TOTAL, estrato)
  tibble(rep = rep, RAC = estimador_rac, AMLO = estimador_amlo,
         JAMK = estimador_jamk)
})
```

```{r}
resumen_2 <- remuestreo_tbl |> summarise(across(RAC:JAMK, quantile, probs = c(0.025, 0.975))) |> 
  mutate(tipo = c("inf", "sup")) |> 
  pivot_longer(RAC:JAMK, names_to = "candidato", values_to = "prop") |> 
  pivot_wider(names_from = tipo, values_from = prop) |> 
  mutate(remesa = "11:59")

```



```{r}
resumen <- bind_rows(resumen_1, resumen_2)
ggplot(resumen_1) +
  geom_linerange(aes(x = candidato, ymin = 100 * inf, ymax = 100 * sup)) +
  geom_point(data = computos_finales, aes(x = candidato,  y = 100 * prop), colour = "red", size = 5) + 
  labs(subtitle = "Estimaciones con muestras incompletas") + 
  facet_wrap(~candidato, scales = "free_y")
```

La razón es que aún cuando hagamos esfuerzos por reponderar 




```{r}
library(dagitty)
library(ggdag)
dag_cafe <- dagitty('dag{Cafe [exposure,pos="-1,-2"]
  Cancer [outcome,pos="1,-2"]
  Entrevistado [pos="0,-3"]
  Gastro [pos="-1,-2.5"]
  Gastro -> Cafe
  Cancer -> Entrevistado; Gastro  -> Entrevistado; Cafe -> Cancer}')
dag_cafe_tidy <- tidy_dagitty(dag_cafe) |> 
  mutate(tipo = ifelse(name == "Cafe" & to == "Cancer", "dotted", "solid"))
dag_cafe_tidy |>
  ggplot(aes(x = x, y = y, xend = xend, yend = yend, colour = tipo )) + 
  geom_dag_edges(aes(edge_linetype = tipo)) +
  geom_dag_point(colour = "salmon") +
  geom_dag_text(colour = "gray20") +
  theme_dag()
```









