# Probabilidad condicional e independencia

```{r, message = FALSE, echo = FALSE, include = FALSE}
ggplot2::theme_set(ggplot2::theme_light())
library(tidyverse)
library(patchwork)
library(kableExtra)
```

Uno los conceptos centrales de la probabilidad es el de probabilidad condicional:

1. Muchas veces queremos calcular probabilidades dada cierta información parcial: es decir,
las probabilidades que queremos calcular son *condicionadas* a cierto tipo de información.
2. La probabilidad condicional nos permite modelar con probabilidad sistemas relativamente
complejos a partir de componentes simples.

En particular, si nuestro modelo incluye partes del proceso generador de datos,
nos interesará calcular probabilidades condicionales de eventos *condicionados* 
a que hemos observado ciertos datos.

Muchos de los problemas de esta sección son de (@rossproba).

## Probabilidad condicional en espacios equiprobables.

Supongamos que en un experimento simétro de $n$ posibles resultados,
sabemos que ocurrió el evento $F$, es decir, un conjunto de resultados fijo.
¿Cómo podemos calcular la probabilidad de que ocurra un evento $E$ dado que
sabemos que $F$ ocurrió? Esta probabilidad se escribe

$$P(E|F)$$

### Ejemplo: dos dados

Supongamos que tiramos dos dados, y nos dicen que la suma de los dos datos es igual
a 6. ¿Cuál es la probablidad condicional de haber tirado al menos un cinco dado
que la suma es 6?

Solución: los resultados equiprobables que resultan en un tiro de suma 6
son $F= \{ (5,1),(4,2),(3,3),(2,4),(1,5)\}$, que son 5 posibles resultados. En solamente
2 de ellos tiramos un cinco. Como estos resultados son equiprobables, si $E$ es el
evento "tirar al menos un 5",
$$P(E|F) = 2/5$$
Podemos formalizar de la siguiente manera: para calcular $P(E|F)$ contamos todos
los resultados de $F$ donde también ocurre $E$ y dividimos entre las maneras en que
puede ocurrir $F$:

- En nuestro caso hay muchos resultados posibles donde tiramos al menos un 5, por ejemplo
$(5,1), (5,2), (5,6)$ y así sucesivamente. Sin embargo, solo en 2 de ellos la suma
es 5.

```{block2, type="comentario"}
En un espacio de probabilidad, si $E$ y $F$ son eventos, entonces definimos
$$P(E|F) = \frac{P(E\cap F)}{P(F)}.$$
```

Nótese que otra manera de ver esta definición es como sigue: una vez que sabemos 
que ocurrió $F$, restringimos todo nuestro análisis a resultados dentro de $F$ (normalizamos con la probabilidad de $F$), y proseguimos
como si se tratara de una probabilidad usual.

### Ejemplo: dos volados

Supongamos que tiramos dos volados. Cuál es la probabilidad 
condicional de que los dos
volados sean sol (evento $E$) dado que 1) El primer volado es sol? 
2) Alguno de los dos volados es sol, 3) Los dos volados son águilas? 

Hay 2 resultados donde el primer volado es sol (enuméralos), así que la primer 
probabilidad es $P(E|F_1)=1/2$. Explica por qué la segunda probabilidad condicional
es igual a $P(E|F_2)=1/3$. ¿Cuánto vale $P(E|F_3)$?




## Regla de la multiplicación

A veces nos interesa calcular la probabilidad de que dos eventos ocurran,
y conocemos $P(F)$ y $P(E|F)$. En ese caso podemos usar la definición de
probabilidad condicional para escribir al *regla del producto*:
$$P(EF) = P(F)P(E|F)$$

Por ejemplo, si queremos calcular la probablidad de extraer dos corazones
de una baraja usual, tenemos que $P(C_1) = 13/52 = 1/4$. $P(C_2|C_1)$ es fácil
de calcular, pues si la primera carta que sacamos es un corazón, entonces
para la segunda extracción hay 51 cartas, de las cuales 12 son corazones,
de forma que $P(C_2|C_1) = 12/51$. Usando la regla del producto, quedamos con
$$P(C_1C_2) = P(C_1)P(C_2|C_1) = \frac{13}{52}\frac{12}{51} \approx 0.0588$$

Podemos generalizar esto a

```{block2, type="comentario"}
**Regla del producto**
   
$$P(E_1E_2E_3\cdots E_n) = P(E_1)P(E_2|E_1)P(E_3|E_1E_2)\cdots P(E_n|E_1\cdots E_{n-1}$$
```


## Regla de probablilidad total

Una regla que usaremos varias veces es la regla de probabilidad total, que
establece que 

$$P(E) = P(E|F)P(F) + P(E|F^c)P(F^c)$$
donde el evento $F^c$ significa que $F$ **no** ocurrió.

Esta regla es útil en muchos casos para calcular probabilidades de un evento
dependiendo de la ocurrencia o no de otro.

### Ejemplo {-}

Sacamos dos cartas de una bajara de 52 cartas. Vimos un
ejemplo donde queríamos calcular la probabilidad de $N_2=$ 
la segunda carta que sacamos es negra. Por simetría,
es intuitivamente claro que $P(N_2) = 0.5$.

Si $N_1 =$ la primera carta es negra, entonces
la ley de probabilidad total explica por qué pasa esto tomando en cuenta
el resultado de la primera extracción:

- Tenemos que $P(N_2|N_1) = 25/51$ y $P(N_1) = 1/2$
- Además, $P(N_2|N_1^c) = 26/51$ y $P(N_1^c) = 1/2,$

de forma que

$$P(N_2) = (25/51)(1/2) + (26/51)(1/2) = \frac{(25 + 26)}{51(2)} = 1/2$$

La ley de probabilidades totales consiste de las reglas de ponderación usuales que conocemos.

### Ejemplo {-}

En un país hay 20% de adultos de 20 años o menos, y  80% de adultos de 21 años o
más.
Entre los adultos de 20 años o menos, el 90% solo usa plataformas digitales
para ver televisión. Entre los adultos de 21 años o más, el 15% solo usa plataformas
digitales para ver televisión. Si tomamos un adulto al azar de esta población,
¿cuál es la probabilidad de que solo use digital para ver TV?

La respuesta es 

$$ 0.90(0.20) + 0.15(0.80) = 0.3$$

## Ejercicio: dados y monedas

Supongamos que tiramos un dado. Tiramos tantos volados como el número que salió en la
tirada de dado, y registramos el número de soles. ¿Cuál es la probabilidad de que
obtengamos cero soles?

Sea $X=$ número que obtuvimos en la tirada de dado, y sea
$Y=$ número de soles obtenidos.

Calcular directamente $P(Y=0)$ puede hacerse de manera simple con la ley de probabilidad
total, pues

- $P(Y=0|X=1) = 1/2$, prob de ningún sol en 1 volado
- $P(Y=0|X = 2) = 1/4$ prob de ningún sol en dos volados (suponiendo independencia de los volados)
- $P(Y=0|X=3) = 1/8$, prob de ningún sol en tres volados.

y así sucesivamente. Como $P(X=i)=1/6$ para cualquier número del uno al seis, 
la probabilidad $P(Y=0)$, usando probabilidad total, es

$$(1/6)(1/2) + (1/6)(1/2)^2 +(1/6)(1/2)^3 +(1/6)(1/2)^4 +(1/6)(1/2)^5 +(1/6)(1/2)^6$$

que es igual a

```{r}
probs_x <- rep(1/6, 6)
probs_y_x = 0.5^(1:6)
sum(probs_y_x * probs_x)
```

Checa usando simulación. 

## Ejercicio: dados y monedas (simulación)

Este es un experimento más interesante para simular:

```{r}
simular_soles <- function(){
   dado <- sample(1:6, 1)
   soles <- sample(c("sol", "águila"), dado, replace = TRUE)
   num_soles = sum(as.numeric(soles == "sol"))
   num_soles
}
set.seed(82332)
simular_soles()
```
Si hacemos 10 mil simulaciones:

```{r}
sims <- map_dbl(1:10000, ~ simular_soles())
qplot(sims)
```

La frecuencia relativa de cero soles es:

```{r}
sum(sims==0) / length(sims)
```
Calcula también la probabilidad de obtener 2 soles o más
en este experimento (puedes usar la simulación).



## Regla de Bayes 

La regla de Bayes es una fórmula que se utiliza para invertir probabilidades
condicionales:

$$P(E|F) = \frac{P(F|E)P(E)}{P(F)},$$

que es una consecuencia fácil de la definición de probabilidad condicional. Es útil
conocerla porque facilita resolver varios problemas de probabilidad que en un
principio parecen difíciles.


### Ejemplo (parte 1) {-}

Supongamos que una aseguradora cree que hay dos tipos de personas:
unos con más riesgo de tener accidentes y otros con menos riesgo. 
Los datos muestran que una persona con riesgo alto tendrá un accidente en algún
momento del año con probabilidad 0.04, y esta probabilidad baja a 0.01 para
una persona de riesgo bajo. Si 10% de la población tiene riesgo alto, ¿cuál es 
la probabilidad de que un asegurado nuevo tenga un accidente un año después de
comprar su póliza? (Nota: no sabemos si la persona nueva es de riesgo alto o bajo).

Puedes resolver son simulación, o usar la ley de probabilidad total. Si $A$ 
es el evento de tener un accidente, $R_A$ es el evento de que la persona
es de riesgo alto y $R_B$ es el evento que la persona es de riesgo bajo, entonces

$$P(A) = P(A|R_A)P(R_A) + P(A|R_B)P(R_B)$$

pues $R_A$ y $R_B$ cubren todas las posibilidades. Entonces

$$P(A) = 0.04(0.10) + (0.01)(0.90) = 0.004 + 0.009 = 0.013$$
Es decir, su probabilidad es de 1.3% de tener una accidente en el primer año.

### Ejemplo (parte 2) {-}

Ahora vemos que un cliente tuvo un accidente en su primer año. ¿Cuál es
la probabilidad de que sea un cliente de riesgo alto?

La pregunta es de probabilidad condicional, porque ya tenemos información. Queremos
calcular

$$P(R_A| A)$$

Si usamos la regla de Bayes obtenemos

$$P(R_A|A)= \frac{P(A|R_A)P(R_A)}{P(A)}$$

Sustituimos los datos que tenemos

$$P(R_A|A)= \frac{0.04(0.10)}{P(A)}$$
y $P(A)$ que calculamos en el ejercicio anterior:

$$P(R_A|A)= \frac{0.04(0.10)}{0.013} \approx 0.3077$$

De manera que al principio la probabilidad no condicionada de ser de alto
riesgo era de 10%, y cuando tiene un accidente esta probabilidad se triplica.

### Ejemplo {-}

Supongamos que en un concurso de TV tenemos tres puertas y debemos escoger una.
Atrás de una de ellas hay un premio, y no hay nada detrás de las otras dos.
Escogemos una de las puertas.

Ahora el conductor (que sabe dónde está el premio), abre una puerta vacía, y nos
pregunta si queremos cambiar o no de puerta. ¿Cuál es la mejor estrategia, cambiar
o quedarnos con la que escogimos al principio?

Veamos la estrategia de quedarnos con la puerta que escogimos. Sin perdida de 
generalidad, suponemos que escogemos la puerta 1.

Ahora observamos que el conductor abre la puerta 2.

Sea $E_1=$ el premio está en la puerta 1, y $A_2=$ el conductor abre la puerta 2, donde
no hay premio. Por la regla de bayes:

$$P(E_1 | A_2) = \frac{P(A_2 | E_1) P(E_1)}{P(A_2)}$$

Sabemos que $P(E_1)= 1/3$, y que $P(A_2|E_1)=1/2$ (pues el conductor pudo abrir la puerta 2 o 3). Adicionalmente 

$$P(A_2) = P(A_2|E_1)P(E_1) + P(A_2|E_1^c)P(E_1^c) = (1/2)(1/3) + (1/2) (2/3) = 1/2$$

pues $P(A_2|E_1^c) = 1/2$, es decir, si el premio no está en la puerta 1, la probabilidad
de que abrir la puerta 2 es la probabilidad de que el premio esté en la puerta 2 dado
que no está en la puerta 1

Sustituyendo,

$$P(E_1 | A_2) = \frac{(1/2)(1/3)}{1/2} = 1/3$$

Asi que si cambiamos, la probabilidad de ganar es de 2/3.

Simula para verificar tus resultados. 

## Independencia

Cuando tenemos dos eventos, y tenemos que $P(E|F) > P(E)$ o $P(F|E) > P(F)$ (checa
que una implica la otra), decimos que los eventos tienen dependencia positiva: cuando
sabemos que uno ocurre, la probabiidad del otro aumenta.

En algunos casos $P(E|F) = P(E)$ y $P(F|E) = P(F)$, lo cual sucede cuando
$P(EF)=P(F)P(E)$. En este caso decimos que los eventos $E$ y $F$ son *independientes*.
Nótese que esto no quiere decir que no haya ninguna conexión entre $E$ y $F$ (puede
ser que la ocurrencia de $F$ cambie las maneras en que puede ocurrir $E$), sólo
que la probabilidad de uno no cambia al condicionar al otro.

## Independencia de más de dos eventos

Nótese que cuando los eventos $E$ y $F$ son independientes, por definición

$$P(E \,y\, F) = P(E) P(F)$$

Decimos que los eventos $E$, $F$ y $G$ son independientes cuando

- $P(E \,y \,F \, y \, G) = P(E)P(F)P(G)$
- $P(E \,y \,F ) = P(E)P(F)$
- $P(E \,y \, G) = P(E)P(G)$
- $P(F \, y \, G) = P(F)P(G)$

y así sucesivamente para un número mayor de eventos: si los eventos son independientes, la probabilidad de que ocurran cualquier 
subconjunto de ellos es es el producto de la probabilidades de que cada 
uno de ellos ocurra.

En general, si $E_1, E_2, \ldots, E_n$ son eventos independientes, entonces
$$P(E_1\, y \, E_2 \, y \cdots \,y E_n) = P(E_1)P(E_2)\cdots P(E_n)$$







### Ejercicio {-}

Hacemos un número indefinido de pruebas independientes, y cada
una de ellas puede resultar en éxito con probabilidad $p$ y fracaso con
probabilidad $1-p$. Calcula la probabilidad de que 1) al menos un éxito
suceda en la primeras 20 pruebas. 2) todas las pruebas sean éxito y 3)
 exactamente 5 de las 2o pruebas sean éxito.
 
### Ejemplo: número de seises {-}

Construye un modelo para el número de seises en dos tiradas de dados. Escribimos
$X$= número de seises que obtenemos en dos tiradas de dado.

Los resultados posibles son 0, 1 y 2 seises. Para calcular la probablidad de
tirar dos seises hacemos:

$$P(X=2) = P(S_2\, y \, S_1) = P(S_2 | S_1) P(S_1).$$
ahora, si suponemos que el primer tiro no afecta de ninguna manera el resultado
del segundo tiro, entonces $P(S_2|S_1) = P(S_2)$, y la fórmula es

$$P(X=2) = P(S_2\, y \, S_1) = P(S_2) P(S_1) = (1/6)(1/6) = 1/36.$$
Usando el mismo argumento podemos calcular de la probabilidad de obtener ningún seis
es

$$P(X=0) = P(S_2^c \, y \, S_1^c ) = P(S_2^c)P(S_1^c) = (5/6)(5/6) = 25/36$$

La probabilidad restante se puede calcularse directamente, o notar que
como 0, 1 y 2 son los únicos posibles resultados, entonces

$$P(X=1) = 1- P(X=0) - P(X=2) = 1 - 25/36 - 1/36 = 10/36$$

Checa tus resultados usando simulación.

**Observación**: en muchos casos, **la independencia se construye como un
supuesto para construir modelos más complejos**, cuando este supuesto es adecuado.
Un ejemplo es cuando tomamos muestras de una población: si tomamos cada muestra
independientemente de las otras, analizar los resultados es mucho más fácil que
cuando hay esquemas complejos de dependencias entre los datos que xtraemos.



