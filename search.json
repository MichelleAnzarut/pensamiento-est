[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Pensamiento estadístico",
    "section": "",
    "text": "En casi todas las soluciones basadas en datos, los científicos de datos ejercen el pensamiento estadístico al diseñar estrategias de recopilación de datos, obtener evidencia para la toma de decisiones y construir modelos para predecir tendencias futuras.\nEste curso busca explicar con los principios básicos de la estadística, y su papel en el análisis de datos. Nuestro punto de vista es uno de fundamentos, con menos énfasis en recetas o técnicas particulares.\nEn particular, estudiaremos básicos de probabilidad, métodos basados en remuestreo, y en la parte final la filosofía de la inferencia bayesiana y las técnicas de modelado bayesiano utilizando estudios de casos ilustrativos.\n\n\n\n\n\nLicencia Creative Commons\n\n\nEste trabajo está bajo una licencia: Attribution-NonCommercial 4.0 International\nEres libre de adaptarlo para propósitos no comerciales otorgando el crédito correspondiente."
  },
  {
    "objectID": "basicos-inferencia.html",
    "href": "basicos-inferencia.html",
    "title": "Inferencia estadística",
    "section": "",
    "text": "A grandes rasgos, en la inferencia estadística buscamos hacer afirmaciones acerca de una colección de datos de la cual sólo tenemos información parcial.\nNos concentraremos en dos de las situaciones más comunes:\nPor ejemplo, consideremos esta población de 15 personas:\nPara una muestra de ellos tenemos información acerca de su estatura y peso. ¿Qué podríamos decir acerca de la estatura y el peso de la población general?\nEn este caso, la situación se ve como sigue. Imaginemos que tenemos 15 personas con dolor de cabeza, y obtenemos los siguientes datos:\nNuestra pregunta en este caso es del tipo: ¿ayuda la aspirina a reducir el dolor de cabeza en esta población? ¿qué tanto ayudaa? Igualmente, tenemos información incompleta, en el sentido de que sólo observamos un resultado potencial de cada persona, dependiendo de si tomó aspirina o no. Si supiéramos los dos resultados potenciales de cada persona entonces podríamos contestar la pregunta sin dificultad."
  },
  {
    "objectID": "basicos-inferencia.html#proceso-de-selección-o-asignación",
    "href": "basicos-inferencia.html#proceso-de-selección-o-asignación",
    "title": "Inferencia estadística",
    "section": "Proceso de selección o asignación",
    "text": "Proceso de selección o asignación\nLas preguntas que planteamos arriba son difíciles de contestar cuando no conocemos bien el proceso de selección de individuos en la muestra o no conocemos el proceso de asignación de la aspirina.\nPor ejemplo, llegaríamos a conclusiones muy distintas si nos dijeran que:\n\nEscogimos las 5 personas que usan ropa talla chica.\nEscogimos las 5 personas que llegaron primero en una carrera de 100 metros.\nEscogimos las personas cuyo día de nacimiento era más bajo.\n\nO en el ejemplo de la aspirina,\n\nSólo dimos aspirinas a las personas que reportaron un nivel de dolor de cabeza muy alto.\nSolo dimos aspirina a las personas que llegaron primero en una carrera de 100 metros.\nDimos una aspirina exclusivamente a las personas cuyo día de nacimiento es par.\n\n\n\n\n\n\n\nTip\n\n\n\nDiscute qué conclusiones podrías llegar en cada uno de estos escenarios.\n\n\nLos casos 1 y 2 en ambas poblaciones son en general difíciles de resolver adecuadamente, y explicaremos con más ejemplos. Adicionalmente, es también más difícil cuantificar el nivel de incertidumbre de nuestras respuestas, pues dependen de muchos detalles del proceso de selección o asignación.\n\n\n\n\n\n\nProceso generador de datos\n\n\n\nCuando el proceso de selección de observaciones o asignación tiene relaciones complicadas con las cantidades de interés, puede ser muy difícil dar respuesta a preguntas inferenciales de manera adecuada, y es importante entender el proceso que genera los datos, muchas veces a un nivel muy detallado."
  },
  {
    "objectID": "basicos-inferencia.html#procesos-generadores-de-datos-e-inferencia-causal",
    "href": "basicos-inferencia.html#procesos-generadores-de-datos-e-inferencia-causal",
    "title": "Inferencia estadística",
    "section": "Procesos generadores de datos e inferencia causal",
    "text": "Procesos generadores de datos e inferencia causal\nConsideramos los datos de ENLACE (2011), y en particular los resultados promedio de matemáticas en sexto grado por escuela. ENLACE era una prueba que se aplicaba en todas las escuelas, de forma que tenemos información de la población completa de interés.\nNos interesa saber cómo varían los resultados en función de el tipo de primaria: pública o privada.\nEl rango de la calificación de matemáticas para un alumno es de 0-800, y aproximadamente la mitad de los alumnos califica en el rengo de 450 a 550. Vemos dispersión considerable en las calificaciones de las escuelas, y diferencias considerables entre tipo de escuelas:\n\n\n\n\n\nCódigo\nenlace_tbl <- enlace |> group_by(tipo) |> \n    summarise(n_escuelas = n(),\n              cuantiles = list(cuantil(mate_6, c(0.05, 0.25, 0.5, 0.75, 0.95)))) |> \n    unnest(cols = cuantiles) |> mutate(valor = round(valor)) \nenlace_tbl |> spread(cuantil, valor) |>  formatear_tabla()\n\n\n\n\n \n  \n    tipo \n    n_escuelas \n    0.05 \n    0.25 \n    0.5 \n    0.75 \n    0.95 \n  \n \n\n  \n    Indígena/Conafe \n    13599 \n    304 \n    358 \n    412 \n    478 \n    588 \n  \n  \n    General \n    60166 \n    380 \n    454 \n    502 \n    548 \n    631 \n  \n  \n    Particular \n    6816 \n    479 \n    551 \n    593 \n    634 \n    703 \n  \n\n\n\n\n\nPodemos graficar de varias maneras, por ejemplo, mostrando los cuantiles 0.05, 0.25, 0.5, 0.75 y 0.95:\n\n\n\n\n\nY vemos que las escuelas privadas tienen mejor resultados que las públicas por un margen considerable. Ahora preguntamos: ¿la calidad de las escuelas es lo que causa estos resultados? Por ejemplo, ¿si cambiáramos un niño de una escuela pública a una privada su resultado sería mejor?\nEs dificil contestar esta pregunta, porque no entendemos el proceso generador de datos que asigna niños a escuelas. Una posible hipótesis de cómo se asigna el tratamiento y cómo se relaciona con la calificación en Enlace:\n\n\nCódigo\nlibrary(dagitty)\nlibrary(ggdag)\n\n\n\nAttaching package: 'ggdag'\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\nCódigo\ndag_cafe <- dagitty('dag{\"Escuela\" [exposure,pos=\"-3,3\"]\n  \"Calif\" [outcome,pos=\"3,3\"]\n  \"Marginación\" [pos=\"0,1\"]\n  \"Educación padres\" [pos = \"2,2\"]\n  \"Recursos escolares\" [pos = \"0,4\"]\n  \"Marginación\"  -> \"Escuela\"\n    \"Escuela\" -> \"Calif\"\n    \"Marginación\" -> \"Educación padres\" -> \"Calif\"\n    \"Escuela\" -> \"Recursos escolares\" -> \"Calif\"\n  }')\ndag_cafe_tidy <- tidy_dagitty(dag_cafe) #|> \n  #mutate(tipo = ifelse(name == \"Cafe\" & to == \"Cancer\", \"dotted\", \"solid\"))\ndag_cafe_tidy |>\n  ggplot(aes(x = x, y = y, xend = xend, yend = yend )) + \n  geom_dag_edges() +\n  geom_dag_point(colour = \"salmon\", size = 20) +\n  geom_dag_text(colour = \"gray20\") +\n  theme_dag()\n\n\n\n\n\n\nEl grado de marginación del hogar de un estudiante influye en el tipo de escuela al que asiste.\nPero también influye en la calificación que obtiene el estudiante, por ejemplo actuando mediante el nivel de educación de los padres.\nEsto implica que cuando cruzamos tipo de escuela y calificación obtenida, en parte estamos viendo el efecto que la escuela tiene en los estudiantes, pero también un efecto común de la marginación.\nLa comparación entre tipos de escuelas está sesgada si el propósito es estimar el efecto de tipo de escuela en los resultados de los estudiantes.\n\n\n\nCódigo\nenlace_tbl_marg <- enlace %>% \n    group_by(tipo, marginacion) %>% \n    summarise(n_alumnos = sum(num_evaluados_total),\n              cuantiles = list(cuantil(mate_6, c(0.05, 0.25, 0.5, 0.75, 0.95)))) %>% \n    unnest(cols = cuantiles) %>% mutate(valor = round(valor)) %>% \n    filter( n_alumnos > 20)\n\n\nPodemos considerar el grado de marginación del municipio donde está cada escuela, y vemos la diferencia tan grande se debe en parte a las escuelas privadas tienden estar en municipios de baja marginación. Por ejemplo, los promedios no son tan diferentes para escuelas públicas en zonas de marginación muy baja comparado con escuelas privadas en zonas de marginación alta:\n\n\n\n\n\nEn esta nueva comparación, existen muchos otros factores que probablemente tenemos que pensar, algunos de ellos no estarán disponibles en los datos, y otros puede que se escapen de nuestra consideración.\n\nEl problema central en este análisis es que el proceso generador de datos, en cuanto a quíen le toca ir a cada escuela, es complejo.\nHacer inferencia causal en este caso es retador y depende de varios supuestos que no son estadísticos."
  },
  {
    "objectID": "basicos-inferencia.html#procesos-generadores-de-datos-2-inferencia-causal",
    "href": "basicos-inferencia.html#procesos-generadores-de-datos-2-inferencia-causal",
    "title": "Inferencia estadística",
    "section": "Procesos generadores de datos 2: inferencia causal",
    "text": "Procesos generadores de datos 2: inferencia causal\nEn un estudio de 1981, investigadores reportaron una asociación de cáncer de páncreas con consumo de café. Sus resultados agregados fueron:\n\n\nCódigo\ntab_cafe <- crossing(num_tazas = c(0, 1.5, 3.5, 5), enf_pancreas = c(\"si\", \"no\")) |> \n  mutate(n = c(88, 20, 271, 153, 154, 106, 88, 130))\ntab_cafe |> pivot_wider(names_from = enf_pancreas, values_from = n) |> \n  mutate(prop_si = si / (no + si))\n\n\n# A tibble: 4 × 4\n  num_tazas    no    si prop_si\n      <dbl> <dbl> <dbl>   <dbl>\n1       0      88    20   0.185\n2       1.5   271   153   0.361\n3       3.5   154   106   0.408\n4       5      88   130   0.596\n\n\nLo que indica una asociación fuerte entre consumo de café y proporción de pacientes con cáncer de páncres. Los pacientes fueron entrevistados en varios hospitales. Se seleccionaron pacientes con cáncer de páncreas y pacientes control fueron entrevistados que corresponden a los mismos doctores. En el artículo señala que por la naturaleza de las enfermedades, había una cantidad considerable de pacientes control con condiciones gastrointestinales.\nEn este caso, el proceso de asignación de quién toma café y cuánto toma es complicado. Sabemos sin embargo que:\n\nPacientes con problemas gastrointestinales muchas veces tienen dietas restringidas y no se les permite tomar café, o sólo o una cantidad baja de café.\nLas razones para ser seleccionados con más alta probabilidad en el estudio son: tener cáncer de páncreas, o tener otros problemas gastrointestinales.\n\nEstas tres relaciones causales podemos representarlas como sigue:\n\n\nCódigo\nlibrary(dagitty)\nlibrary(ggdag)\ndag_cafe <- dagitty('dag{Cafe [exposure,pos=\"-1,-2\"]\n  Cancer [outcome,pos=\"1,-2\"]\n  Entrevistado [pos=\"0,-3\"]\n  Gastro [pos=\"-1,-2.5\"]\n  Gastro -> Cafe\n  Cancer -> Entrevistado; Gastro  -> Entrevistado; Cafe -> Cancer}')\ndag_cafe_tidy <- tidy_dagitty(dag_cafe) |> \n  mutate(tipo = ifelse(name == \"Cafe\" & to == \"Cancer\", \"dotted\", \"solid\"))\ndag_cafe_tidy |>\n  ggplot(aes(x = x, y = y, xend = xend, yend = yend, colour = tipo )) + \n  geom_dag_edges(aes(edge_linetype = tipo)) +\n  geom_dag_point(colour = \"salmon\") +\n  geom_dag_text(colour = \"gray20\") +\n  theme_dag()\n\n\n\n\n\nLas consecuencias de estas tres relaciones casuales es la siguiente: si alguien es entrevistado, puede ser por dos razones diferentes: tiene cáncer, o si no tiene cáncer, tiene probabilidad alta de tener problemas gastrointestinales. Esto último implica, por restricciones de dieta, que tienden a tomar menos café. Con esto, hemos demostrado que con este esquema de selección puede aparecer naturalmente una asociación entre cáncer y consumo de café, aún cuando no exista una relación causal entre tomar café y cáncer de páncreas.\nEl problema es que la exposición a nuestro “tratamiento” está siendo influida por una variable que tiene asociación con nuestro “resultado”. Esto puede pasar de diferentes maneras. Quizá en este ejemplo podemos controlar por enfermedad gastrointestinal, pero no podemos estar seguros que no existan otras dificultades: por ejemplo, si café estuviera asociado con fumar, entonces esa podría ser otra razón por la que observaríamos una relación entre cáncer y café aún cuando no haya relación causal entre estas dos variables.\nSin embargo, si aleatorizamos el tratamiento, la situación se hace mucho más simple. Si pudiéramos escoger a un grupo de personas, y asignar un grupo a tomar café y otro grupo a no tomarlo, tendríamos el diagrama:\n\n\nCódigo\ndag_cafe <- dagitty(\"dag{Gastro -> Cafe;  Cafe -> Cancer}\")\ndag_cafe_tidy <- tidy_dagitty(dag_cafe) |> \n  mutate(tipo = ifelse(name == \"Cafe\" & to == \"Cancer\", \"dotted\", \"solid\"))\ndag_cafe_tidy |>\n  ggplot(aes(x = x, y = y, xend = xend, yend = yend, colour = tipo )) + \n  geom_dag_edges(aes(edge_linetype = tipo)) +\n  geom_dag_point(colour = \"salmon\") +\n  geom_dag_text(colour = \"gray20\") +\n  theme_dag()\n\n\n\n\n\nY en este caso, podemos ver directamente la relación causal entre café y cáncer, aún cuando problemas gastrointestinales pueden afectar la asignación del tratamiento."
  },
  {
    "objectID": "basicos-inferencia.html#procesos-generadores-de-datos-e-inferencia-a-poblaciones",
    "href": "basicos-inferencia.html#procesos-generadores-de-datos-e-inferencia-a-poblaciones",
    "title": "Inferencia estadística",
    "section": "Procesos generadores de datos e inferencia a poblaciones",
    "text": "Procesos generadores de datos e inferencia a poblaciones\nEn el siguiente ejemplo, consideramos el problema del Conteo Rápido en las elecciones presidenciales de 2018. El Conteo Rápido busca estimar con precisión los resultados finales de las elecciones en el mismo día que se lleva a cabo la votación."
  },
  {
    "objectID": "pruebas-hipotesis.html",
    "href": "pruebas-hipotesis.html",
    "title": "1  Pruebas de hipótesis",
    "section": "",
    "text": "Las primeras técnicas que veremos intentan contestar la siguiente pregunta:\nPor ejemplo:"
  },
  {
    "objectID": "pruebas-hipotesis.html#comparación-con-poblaciones-de-referencia",
    "href": "pruebas-hipotesis.html#comparación-con-poblaciones-de-referencia",
    "title": "1  Pruebas de hipótesis",
    "section": "Comparación con poblaciones de referencia",
    "text": "Comparación con poblaciones de referencia\nEn las prueba de hipótesis, tratamos de construir distribuciones de referencia para comparar resultados que obtengamos con un “estándar” de variación, y juzgar si nuestros resultados son consistentes con la referencia o no (Box et al. (1978)).\nEn algunos casos, ese estándar de variación puede construirse con datos históricos.\n\nEjemplo\nSupongamos que estamos considerando cambios rápidos en una serie de tiempo de alta frecuencia. Hemos observado la serie en su estado “normal” durante un tiempo considerable, y cuando observamos nuevos datos quisiéramos juzgar si hay indicaciones o evidencia en contra de que el sistema sigue funcionando de manera similar.\nDigamos que monitoreamos ventanas de tiempo de tamaño 20 y necesitamos tomar una decisión. Abajo mostramos cinco ejemplos donde el sistema opera normalmente, que muestra la variabilidad en el tiempo en ventanas cortas del sistema.\nAhora suponemos que obtenemos una nueva ventana de datos. ¿Hay evidencia en contra de que el sistema sigue funcionando de manera similar?\nNuestra primera inclinación debe ser comparar: en este caso, compararamos ventanas históricas con nuestra nueva serie:\n\n\n\n\n\nCódigo\n# usamos datos simulados para este ejemplo\nset.seed(8812)\nhistoricos <- simular_serie(2000)\n\n\n\n\n\n\n\n¿Vemos algo diferente en los datos nuevos (el panel de color diferente)?\nIndpendientemente de la respuesta, vemos que hacer este análisis de manera tan simple no es siempre útil: seguramente podemos encontrar maneras en que la nueva muestra (4) es diferente a muestras históricas. Por ejemplo, ninguna de muestras tiene un “forma de montaña” tan clara.\nNos preguntamos si no estamos sobreinterpretando variaciones que son parte normal del proceso.\nPodemos hacer un mejor análisis si extraemos varias muestras del comportamiento usual del sistema, graficamos junto a la nueva muestra, y revolvemos las gráficas para que no sepamos cuál es cuál. Entonces la pregunta es:\n\n¿Podemos detectar donde están los datos nuevos?\n\nEsta se llama una prueba de lineup, o una prueba de ronda de sospechosos (Hadley Wickham et al. (2010)). En la siguiente gráfica, en uno de los páneles están los datos recientemente observados. ¿Hay algo en los datos que distinga al patrón nuevo?\n\n\nCódigo\n# nuevos datos\nobs <- simular_serie(500, x_inicial = last(obs$obs))\n# muestrear datos históricos\nprueba_tbl <- muestrear_ventanas(historicos, obs[1:20, ], n_ventana = 20)\n# gráfica de pequeños múltiplos\nggplot(prueba_tbl$lineup, aes(x = t_0, y = obs)) + geom_line() + \n     facet_wrap(~rep, nrow = 4) + scale_y_log10()\n\n\n\n\n\nEjercicio: ¿cuáles son los datos nuevos (solo hay un panel con los nuevos datos)? ¿Qué implica que la gráfica que escogamos como “más diferente” no sean los datos nuevos? ¿Qué implica que le “atinemos” a la gráfica de los datos nuevos?\nAhora observamos al sistema en otro momento y repetimos la comparación. En el siguiente caso obtenemos:\n\n\n\n\n\nAunque es imposible estar seguros de que ha ocurrido un cambio, la diferencia de una de las series es muy considerable. Si identificamos los datos correctos, la probabilidad de que hayamos señalado la nueva serie “sobreinterpretando” fluctuaciones en un proceso que sigue comportándose normalente es 0.05 - relativamente baja. Detectar los datos diferentes es evidencia en contra de que el sistema sigue funcionando de la misma manera que antes.\nObservaciones y terminología:\n\nLlamamos hipótesis nula a la hipótesis de que los nuevos datos son producidos bajo las mismas condiciones que los datos de control o de referencia.\nSi no escogemos la gráfica de los nuevos datos, nuestra conclusión es que la prueba no aporta evidencia en contra de la hipótesis nula.\nSi escogemos la gráfica correcta, nuestra conclusión es que la prueba aporta evidencia en contra de la hipótesis nula.\n\n¿Qué tan fuerte es la evidencia, en caso de que descubrimos los datos no nulos?\n\nCuando el número de paneles es más grande y detectamos los datos, la evidencia es más alta en contra de la nula. Decimos que el nivel de significancia de la prueba es la probabilidad de seleccionar a los datos correctos cuando la hipótesis nula es cierta (el sistema no ha cambiado). En el caso de 20 paneles, la significancia es de 1/20 = 0.05. Cuando detectamos los datos nuevos, niveles de significancia más bajos implican más evidencia en contra de la nula.\nSi acertamos, y la diferencia es más notoria y fue muy fácil detectar la gráfica diferente (pues sus diferencias son más extremas), esto también sugiere más evidencia en contra de la hipótesis nula.\nFinalmente, esta prueba rara vez (o nunca) nos da seguridad completa acerca de ninguna conclusión, aún cuando hiciéramos muchos páneles."
  },
  {
    "objectID": "pruebas-hipotesis.html#comparando-distribuciones",
    "href": "pruebas-hipotesis.html#comparando-distribuciones",
    "title": "1  Pruebas de hipótesis",
    "section": "Comparando distribuciones",
    "text": "Comparando distribuciones\nAhora intentamos un ejemplo más típico.\nSupongamos tenemos muestras para tres grupos a, b y c, que quiere decir que dentro de cada grupo, el proceso e selección de los elementos se hace de manera al azar y de manera simétrica (por ejemplo cada elemento tiene a misma probabiidad de ser seleccionado, y las extracciones se hacen de manera independiente.)\nQueremos comparar las distribuciones de los datos obtenidos para cada grupo. Quizá la pregunta detrás de esta comparación es: el grupo de clientes b recibió una promoción especial. ¿Están gastando más? La medición que comparamos es el gasto de los clientes.\n\n\n\n\n\nEn la muestra observamos diferencias entre los grupos. Pero notamos adicionalmente que hay mucha variación dentro de cada grupo. Nos podríamos preguntar entonces si las diferencias que observamos se deben variación muestral, por ejemplo.\nPodemos construir ahora una hipótesis nula, que establece que las observaciones provienen de una población similar:\n\nLas tres poblaciones (a, b, c) son prácticamente indistiguibles. En este caso, la variación que observamos se debería a que tenemos información incompleta.\n\nComo en el ejemplo anterior necesitamos construir o obtener una distribución de referencia para comparar qué tan extremos o diferentes son los datos que observamos. Esa distribución de referencia debería estar basada en el supuesto de que los grupos producen datos de distribuciones similares.\nSi tuvieramos mediciones similares históricas de estos tres grupos, quizá podríamos extraer datos de referencia y comparar, como hicimos en el ejempo anterior. Pero esto es menos común en este tipo de ejemplos."
  },
  {
    "objectID": "pruebas-hipotesis.html#permutaciones-y-el-lineup",
    "href": "pruebas-hipotesis.html#permutaciones-y-el-lineup",
    "title": "1  Pruebas de hipótesis",
    "section": "Permutaciones y el lineup",
    "text": "Permutaciones y el lineup\nPara abordar este problema podemos pensar en usar permutaciones de los grupos de la siguiente forma (Box et al. (1978), Hesterberg (2015)):\n\nSi los grupos producen datos bajo procesos idénticos, entonces los grupos a, b, c solo son etiquetas que no contienen información.\nPodríamos permutar al azar las etiquetas y observar nuevamente la gráfica de caja y brazos por grupos.\nSi la hipótesis nula es cierta (grupos idénticos), esta es una muestra tan verosímil como la que obtuvimos.\nAsí que podemos construir datos de referencia permutando las etiquetas de los grupos al azar, y observando la variación que ocurre.\nSi la hipótesis nula es cercana a ser cierta, no deberíamos de poder distinguir fácilmente los datos observados de los producidos con las permutaciones al azar.\n\nVamos a intentar esto, por ejemplo usando una gráfica de cuantiles simplificada. Hacemos un lineup, o una rueda de sospechosos (usamos el paquete H. Wickham, Chowdhury, y Cook (2012), ver Hadley Wickham et al. (2010)), donde 19 de los acusados son generados mediante permutaciones al azar de la variable del grupo, y el culpable (los verdaderos datos) están en una posición escogida al azar. ¿Podemos identificar los datos verdaderos? Para evitar sesgarnos, también ocultamos la etiqueta verdadera\nUsamos una gráfica que muestra los cuantes 0.10, 0.50, 0.90:\n\n\nCódigo\nset.seed(88)\nreps <- lineup(null_permute(\"grupo\"), muestra_tab, n = 20)\n\n\ndecrypt(\"FV8G 3ARA 9Y PqS9R9qY aO\")\n\n\nCódigo\nreps_mezcla <- reps |>  mutate(grupo_1 = factor(digest::digest2int(grupo) %% 177))\ngrafica_cuantiles(reps_mezcla, grupo_1, x) + \n    facet_wrap(~.sample, ncol = 5) + ylab(\"x\") + \n    labs(caption = \"Mediana y percentiles 10% y 90%\")+ geom_point(aes(colour = grupo_1))\n\n\n`summarise()` has grouped output by 'grupo_1'. You can override using the\n`.groups` argument.\n\n\n\n\n\nY la pregunta que hacemos es podemos distinguir nuestra muestra entre todas las replicaciones producidas con permutaciones?\nEjercicio: ¿dónde están los datos observados? Según tu elección, ¿qué tan diferentes son los datos observados de los datos nulos?\nEn este ejemplo, es difícil indicar cuáles son los datos. Los grupos tienen distribuciones similares y es factible que las diferencias que observamos se deban a variación muestral.\n\nSi la persona escoge los verdaderos datos, encontramos evidencia en contra de la hipótesis nula (los tres grupos son equivalentes). En algunos contextos, se dice que los datos son significativamente diferentes al nivel 0.05. Esto es evidencia en contra de que los datos se producen de manera homogénea, independientemente del grupo.\nSi la persona escoge uno de los datos permutados, no encontramos evidencia en contra de que los tres grupos producen datos con distribuciones similares."
  },
  {
    "objectID": "pruebas-hipotesis.html#comparaciones-con-lineup-2",
    "href": "pruebas-hipotesis.html#comparaciones-con-lineup-2",
    "title": "1  Pruebas de hipótesis",
    "section": "Comparaciones con lineup 2",
    "text": "Comparaciones con lineup 2\nRepitimos el ejemplo para otra muestra (en este ejemplo el proceso generador de datos es diferente para el grupo b):\n\n\n\n\n\nHacemos primero la prueba del lineup:\n\n\nCódigo\nset.seed(121)\nreps <- lineup(null_permute(\"grupo\"), muestra_tab, n = 20)\n\n\ndecrypt(\"FV8G 3ARA 9Y PqS9R9qY ai\")\n\n\nCódigo\ngrafica_cuantiles(reps |>  mutate(grupo_escondido = factor(digest::digest2int(grupo) %% 177)), \n                             grupo_escondido, x) + facet_wrap(~.sample) + ylab(\"x\") +\n    coord_flip() + geom_point(aes(colour = grupo_escondido))\n\n\n`summarise()` has grouped output by 'grupo_escondido'. You can override using\nthe `.groups` argument.\n\n\n\n\n\nPodemos distinguir más o menos claramente que está localizada en valores más altos y tiene mayor dispersión. En este caso, como en general podemos identificar los datos, obtenemos evidencia en contra de que los tres grupos tienen distribuciones iguales."
  },
  {
    "objectID": "pruebas-hipotesis.html#prueba-de-permutaciones-para-proporciones",
    "href": "pruebas-hipotesis.html#prueba-de-permutaciones-para-proporciones",
    "title": "1  Pruebas de hipótesis",
    "section": "Prueba de permutaciones para proporciones",
    "text": "Prueba de permutaciones para proporciones\nVeremos otro ejemplo donde podemos hacer más concreta la idea de distribución nula o de referencia usando pruebas de permutaciones. Supongamos que con nuestra muestra de tomadores de té, queremos probar la siguiente hipótesis nula:\n\nLos tomadores de té en bolsas exclusivamente usan azúcar más a tasas simillares que los tomadores de té suelto (que pueden o no también tomar té en bolsita).\n\nLos datos que obtuvimos en nuestra encuesta, en conteos, son:\n\n\n\n\n\nCódigo\nte_azucar <- tea |> select(how, sugar) |> \n  mutate(how = ifelse(how == \"tea bag\", \"bolsa_exclusivo\", \"suelto o bolsa\"))\nte_azucar |> group_by(how, sugar) |> tally() |> \n  spread(how, n) |> \n  formatear_tabla()\n\n\n\n\n \n  \n    sugar \n    bolsa_exclusivo \n    suelto o bolsa \n  \n \n\n  \n    No.sugar \n    81 \n    74 \n  \n  \n    sugar \n    89 \n    56 \n  \n\n\n\n\n\nY en proporciones tenemos que:\n\n\n\n\n \n  \n    how \n    prop_azucar \n    n \n  \n \n\n  \n    bolsa_exclusivo \n    0.52 \n    170 \n  \n  \n    suelto o bolsa \n    0.43 \n    130 \n  \n\n\n\n\n\nPero distintas muestras podrían haber dado distintos resultados. Nos preguntamos que tan fuerte es la evidencia en contra de que en realidad los dos grupos de personas usan azúcar en proporciones similares, y la diferencia que vemos se puede atribuir a variación muestral.\nEn este ejemplo, podemos usar una estádistica de prueba numérica, por ejemplo, la diferencia entre las dos proporciones:\n\\[p_1 - p_2\\].\n(tomadores de en bolsa solamente vs. suelto y bolsa). El proceso sería entonces:\n\nLa hipótesis nula es que los dos grupos tienen distribuciones iguales, que este caso quiere decir que en la población, tomadores de té solo en bolsa usan azúcar a las mismas tasas que tomadores de suelto o bolsas.\nBajo nuestra hipótesis nula (proporciones iguales), producimos una cantidad grande (por ejemplo 10 mil o más) de muestras permutando las etiquetas de los grupos.\nEvaluamos nuestra estadística de prueba en cada una de las muestras permutadas.\nEl conjunto de valores obtenidos nos da nuestra distribución de referencia (ya no estamos limitados a 20 replicaciones como en las pruebas gráficas).\nY la pregunta clave es: ¿el valor de la estadística en nuestra muestra es extrema en comparación a la distribución de referencia?\n\n\n\nCódigo\n# ESta función calcula la diferencia entre grupos de interés\ncalc_diferencia <- function(datos){\n  datos |>\n    mutate(usa_azucar = as.numeric(sugar == \"sugar\")) |> \n    group_by(how) |> \n    summarise(prop_azucar = mean(usa_azucar)) |> \n    spread(how, prop_azucar) |> \n    mutate(diferencia_prop = bolsa_exclusivo - `suelto o bolsa`) |> pull(diferencia_prop)\n}\n# esta función hace permutaciones y calcula la diferencia para cada una\npermutaciones_est <- function(datos, variable, calc_diferencia, n = 1000){\n  # calcular estadística para cada grupo\n  permutar <- function(variable){\n    sample(variable, length(variable))\n  }\n  tbl_perms <- tibble(.sample = seq(1, n-1, 1)) |>\n    mutate(diferencia = map_dbl(.sample, \n              ~ datos |> mutate({{variable}}:= permutar({{variable}})) |> calc_diferencia()))\n  bind_rows(tbl_perms, tibble(.sample = n, diferencia = calc_diferencia(datos)))\n}\n\n\nLa diferencia observada es:\n\n\nCódigo\ndif_obs <- calc_diferencia(te_azucar)\ndif_obs |> round(3)\n\n\n[1] 0.093\n\n\nAhora construimos nuestra distribución nula o de referencia:\n\n\nCódigo\nvalores_ref <- permutaciones_est(te_azucar, how, calc_diferencia, n = 10000)\n\n\nY graficamos nuestros resultados (con un histograma y una gráfica de cuantiles, por ejemplo). la estadística evaluada un cada una de nuestras muestras permutadas:\n\n\nCódigo\ng_1 <- ggplot(valores_ref, aes(sample = diferencia)) + geom_qq(distribution = stats::qunif)  +\n    xlab(\"f\") + ylab(\"diferencia\") + labs(subtitle = \"Distribución nula o de referencia\")\ng_2 <- ggplot(valores_ref, aes(x = diferencia)) + geom_histogram(binwidth = 0.04) + \n    coord_flip() + xlab(\"\") + labs(subtitle = \" \")\ngridExtra::grid.arrange(g_1, g_2, ncol = 2) \n\n\n\n\n\nEste es el rango de fluctuación usual para nuestra estadística *bajo la hipótesis de que los dos grupos de tomadores de té consumen té a la misma tasa.\nEl valor que obtuvimos en nuestros datos es 0.0927602, que no es un valor extremo en la distribución de referencia que vimos arriba: esta muestra no aporta mucha evidencia en contra de que los grupos tienen distribuciones similares.\nPodemos graficar otra vez marcando el valor de referencia:\n\n\nCódigo\n# Función de distribución acumulada (inverso de función de cuantiles)\ndist_perm <- ecdf(valores_ref$diferencia)\n# Calculamos el percentil del valor observado\npercentil_obs <- dist_perm(dif_obs)\n\n\n\n\nCódigo\ng_1 <- ggplot(valores_ref, aes(sample = diferencia)) + geom_qq(distribution = stats::qunif)  +\n    xlab(\"f\") + ylab(\"diferencia\") + labs(subtitle = \"Distribución nula o de referencia\") +\n    geom_hline(yintercept = dif_obs, colour = \"red\") +\n    annotate(\"text\", x = 0.3, y = dif_obs - 0.05, label = \"diferencia observada\", colour = \"red\")\ng_2 <- ggplot(valores_ref, aes(x = diferencia)) + geom_histogram(binwidth = 0.04) + \n    coord_flip() + xlab(\"\") + labs(subtitle = \" \") +\n    geom_vline(xintercept = dif_obs, colour = \"red\") +\n    annotate(\"text\", x = dif_obs, y = 2000, label = percentil_obs,vjust = -0.2, colour = \"red\")\ngridExtra::grid.arrange(g_1, g_2, ncol = 2) \n\n\n\n\n\nY vemos que es un valor algo (pero no muy) extremo en la distribución de referencia que vimos arriba: esta muestra no aporta una gran cantidad de evidencia en contra de que los grupos tienen distribuciones similares, que en este caso significa que los dos grupos usan azúcar a tasas similares.\n\nValor p\nNótese que calculamos una cantidad adicional, que es el percentil donde nuestra observación cae en la distribución generada por las permutación. Esta cantidad puede usarse para calcular un valor p. Podemos calcular, por ejemplo:\n\nValor p de dos colas: Si la hipótesis nula es cierta, ¿cuál es la probabilidad de observar una diferencia tan extrema o más extrema de lo que observamos?\n\nConsiderando en este caso interpretamos extrema como que cae lejos de donde a mayoría de la distribución se concentra, podemos calcular el valor p como sigue. A partir de el valor observado, consideramos cuál dato es menor: la probabilidad bajo lo hipótesis nula de observar una diferencia mayor de a que observamos, o la probabilidad de observar una diferencia menor a la que observamos. Tomamos el mínimo y multiplicamos por dos (Hesterberg (2015)):\n\n\nCódigo\n2 * min(dist_perm(dif_obs), (1 - dist_perm(dif_obs)))\n\n\n[1] 0.085\n\n\nEste valor p se considera como evidencia “moderada” en contra de la hipótesis nula. Valores p más chicos (observaciones más extremas en comparación con la referencia) aportan más evidencia en contra de la hipótesis de que los grupos de tomadores de té , y valores más grandes aportan menos evidencia."
  },
  {
    "objectID": "pruebas-hipotesis.html#tomadores-de-té-2",
    "href": "pruebas-hipotesis.html#tomadores-de-té-2",
    "title": "1  Pruebas de hipótesis",
    "section": "Tomadores de té 2",
    "text": "Tomadores de té 2\nAhora hacemos una prueba de permutaciones otro par de proporciones con el mismo método. La hipótesis nula ahora es:\n\nLos tomadores de té Earl Gray usan azúcar a una tasa similar a los tomadores de té negro\n\nLos datos que obtuvimos en nuestra encuesta, en conteos, son: ::: {.cell} ::: {.cell-output-display}\n\n\n \n  \n    sugar \n    black \n    Earl Grey \n  \n \n\n  \n    No.sugar \n    51 \n    84 \n  \n  \n    sugar \n    23 \n    109 \n  \n\n\n\n::: :::\nY en porcentajes tenemos que:\n\n\nCódigo\nprop_azucar <- te_azucar |> group_by(Tea, sugar) |> tally() |> \n  group_by(Tea) |> mutate(prop = 100 * n / sum(n), n = sum(n)) |> \n  filter(sugar == \"sugar\") |> select(Tea, prop_azucar = prop, n) |> \n  mutate('% usa azúcar' = round(prop_azucar)) |> select(-prop_azucar)\nprop_azucar |> formatear_tabla()\n\n\n\n\n \n  \n    Tea \n    n \n    % usa azúcar \n  \n \n\n  \n    black \n    74 \n    31 \n  \n  \n    Earl Grey \n    193 \n    56 \n  \n\n\n\n\n\nPero distintas muestras podrían haber dado distintos resultados. Nos preguntamos que tan fuerte es la evidencia en contra de que en realidad los dos grupos de personas usan azúcar en proporciones similares, y la diferencia que vemos se puede atribuir a variación muestral.\nEscribimos la función que calcula diferencias para cada muestra:\n\n\nCódigo\ncalc_diferencia_2 <- function(datos){\n  datos |>\n    mutate(usa_azucar = as.numeric(sugar == \"sugar\")) |> \n    group_by(Tea) |> \n    summarise(prop_azucar = mean(usa_azucar)) |> \n    spread(Tea, prop_azucar) |> \n    mutate(diferencia_prop = `Earl Grey` - black) |> pull(diferencia_prop)\n}\n\n\nLa diferencia observada es:\n\n\n[1] 0.254\n\n\nAhora construimos nuestra distribución nula o de referencia:\n\n\nCódigo\nset.seed(2)\nvalores_ref <- permutaciones_est(te_azucar, Tea, calc_diferencia_2, n = 10000)\n\n\nY podemos graficar la distribución de referencia otra vez marcando el valor observado\n\n\n\n\n\n\n\n\nEn este caso, la evidencia es muy fuerte en contra de la hipótesis nula, pues el resultado que obtuvimos es muy extremo en relación a la distribución de referencia. El valor p es cercano a 0."
  },
  {
    "objectID": "pruebas-hipotesis.html#ejemplo-tiempos-de-fusión",
    "href": "pruebas-hipotesis.html#ejemplo-tiempos-de-fusión",
    "title": "1  Pruebas de hipótesis",
    "section": "Ejemplo: tiempos de fusión",
    "text": "Ejemplo: tiempos de fusión\nConsideremos el ejemplo de fusión de estereogramas que vimos anteriormente. Una pregunta que podríamos hacer es: considerando que hay mucha variación en el tiempo de fusión dentro de cada tratamiento, necesitamos calificar la evidencia de nuestra conclusión (el tiempo de fusión se reduce con información verbal).\nPodemos usar una prueba de permutaciones, esta vez justificándola por el hecho de que los tratamientos se asignan al azar: si los tratamientos son indistinguibles, entonces las etiquetas de los grupos son solo etiquetas, y permutarlas daría muestras igualmente verosímiles.\nEn este caso, compararemos gráficas de cuantiles de los datos con los producidos por permutaciones:\n\n\n\n── Column specification ────────────────────────────────────────────────────────\ncols(\n  n = col_double(),\n  time = col_double(),\n  nv.vv = col_character()\n)\n\n\ndecrypt(\"FV8G 3ARA 9Y PqS9R9qY aa\")\n\n\n\n\n\nEjercicio: ¿Podemos identificar los datos? En general, muy frecuentemente las personas identifican los datos correctamente, lo que muestra evidencia considerable de que la instrucción verbal altera los tiempos de respuesta de los partipantes, y en este caso ayuda a reducir el tiempo de fusión de los estereogramas."
  },
  {
    "objectID": "pruebas-hipotesis.html#ejemplo-tiempos-de-fusión-2",
    "href": "pruebas-hipotesis.html#ejemplo-tiempos-de-fusión-2",
    "title": "1  Pruebas de hipótesis",
    "section": "Ejemplo: tiempos de fusión 2",
    "text": "Ejemplo: tiempos de fusión 2\nPodemos usar las pruebas de permutaciones para distintos de tipos de estadísticas: medianas, medias, comparar dispersión usando rangos intercuartiles o varianzas, etc.\nRegresamos a los tiempos de fusión. Podemos hacer una prueba de permutaciones para la diferencia de las medias o medianas, por ejemplo. En este ejemplo usaremos una medida de centralidad un poco diferente, como ilustración: el promedio de los cuartiles superior e inferior de las dos distribuciones. Usaremos el cociente de estas dos cantidades para medir su diferencia\n\n\nCódigo\nstat_fusion <- function(x){\n    (quantile(x, 0.75) + quantile(x, 0.25))/2\n}\ncalc_fusion <- function(stat_fusion){\n  fun <- function(datos){\n    datos |> \n      group_by(nv.vv) |> \n      summarise(est = stat_fusion(time)) |> \n      spread(nv.vv, est) |> mutate(dif = VV / NV ) |> pull(dif)\n  }\n  fun\n}\n\n\n\n\nCódigo\ncalc_cociente <- calc_fusion(stat_fusion)\ndif_obs <- calc_cociente(fusion)\n# permutar\nvalores_ref <- permutaciones_est(fusion, nv.vv, calc_cociente, n = 10000)\ndist_perm_nv <- ecdf(valores_ref$diferencia) \ncuantil_obs <- dist_perm_nv(dif_obs)\n\n\n\n\n\n\n\nY el valor p de dos colas es\n\n\nCódigo\ndist_perm_nv <- ecdf(valores_ref$diferencia)\n2 * min(dist_perm_nv(dif_obs), 1- dist_perm_nv(dif_obs))\n\n\n[1] 0.0354\n\n\nLo que muestra evidencia considerable, aunque no muy fuerte, de que la instrucción verbal ayuda a reducir el tiempo de fusión de los estereogramas: la caja del diagrama de caja y brazos para el grupo VV está encogida por un factor menor a 1."
  },
  {
    "objectID": "pruebas-hipotesis.html#ojo-otros-tipos-de-hipótesis-nulas",
    "href": "pruebas-hipotesis.html#ojo-otros-tipos-de-hipótesis-nulas",
    "title": "1  Pruebas de hipótesis",
    "section": "Ojo: otros tipos de hipótesis nulas",
    "text": "Ojo: otros tipos de hipótesis nulas\nLa pruebas de permutaciones son más útiles cuando nuestra hipótesis nula se refiere que la distribución de los grupos son muy similares, o la independencia entre observaciones y grupo. Esto también aplica cuando queremos probar por ejemplo, que una variable numérica Y es independiente de X.\n\nHay algunas hipótesis que no se pueden probar con este método, como por ejemplo, las que se refieren a una sola muestra: ¿los datos son consistentes con que su media es igual a 5?\nAdicionalmente, en algunas ocasiones queremos probar aspectos más específicos de las diferencias: como ¿son iguales las medias o medianas de dos grupos de datos? ¿Tienen dispersión similar?\n\nLas pruebas de permutaciones no están tan perfectamente adaptadas a este problema, pues prueban todos los aspectos de las distribuciones que se comparan, aún cuando escogamos una estadística particular que pretende medir, por ejemplo, diferencia de medias. Eso quiere decir que podemos rechazar igualdad de medias, por ejemplo, cuando en realidad otra característica de las distribuciones es la que difiere mucho en las poblaciones\nEn algunas referencias (ver (chitim?), Efron y Tibshirani (1993)) se argumenta que de todas formas las pruebas de permutaciones son relativamente robustas a esta desadaptación. Un caso excepcional, por ejemplo, es cuando las poblaciones que comparamos resultan tener dispersión extremadamente distinta, y adicionalmente los tamaños de muestra de los grupos son muy desiguales (otra vez, ver ejemplos en (chitim?))."
  },
  {
    "objectID": "pruebas-hipotesis.html#separación-de-grupos",
    "href": "pruebas-hipotesis.html#separación-de-grupos",
    "title": "1  Pruebas de hipótesis",
    "section": "Separación de grupos",
    "text": "Separación de grupos\nEste ejemplo tomado de Chowdhury et al. (2015) (tanto la idea como el código). La pregunta que se aborda en ese estudio es:\n\nExisten métodos de clasificación (supervisados o no supervisados) para formar grupos en términos de variables que describen a los individuos\nEstos métodos (análisis discriminante, o k-means, por ejemplo), pretenden formar grupos compactos, bien separados entre ellos. Cuando aplicamos el método, obtenemos clasificadores basados en las variables de entrada.\nLa pregunta es: ¿los grupos resultantes son producto de patrones que se generalizan a la población, o capitalizaron en variación aleatoria para formarse?\nEspecialmente cuando tenemos muchas mediciones de los individuos, y una muestra relativamente chica, Es relativamente fácil encontrar combinaciones de variables que separan los grupos, aunque estas combinaciones y diferencias están basadas en ruido y no generalizan a la población.\n\nComo muestran en Chowdhury et al. (2015), el lineup es útil para juzgar si tenemos evidencia en contra de que los grupos en realidad son iguales, y usamos variación muestral para separarlos.\n\nAvispas (opcional)\nEn el siguiente ejemplo, tenemos 4 grupos de avispas (50 individuos en total), y para cada individuo se miden expresiones de 42 genes distintos. La pregunta es: ¿Podemos separar a los grupos de avispas dependiendo de sus mediciones?\nEn este se usó análisis discriminante para buscar proyecciones de los datos en dimensión baja de forma que los grupos sean lo más compactos y separados posibles.\nPara probar qué tan bien funciona este método, podemos hacer una prueba de permutación, aplicamos LDA y observamos los resultados.\n\n\n\n\n\nY vemos que incluso permutando los grupos, es generalmente posible separarlos en grupos bien definidos: la búsqueda es suficientemente agresiva para encontrar combinaciones lineales que los separan. Que no podamos distinguir los datos verdaderos de las replicaciones nulas indica que este método difícilmente puede servir para separar los grupos claramente.\nOtro enfoque sería separar los datos en una muestra de entrenamiento y una de prueba (que discutiremos en la última sesión). Aplicamos el procedimiento a la muestra de entrenamiento y luego vemos qué pasa con los datos de prueba:\n\n\nCódigo\nset.seed(8)\nwasps_1 <- wasps |> mutate(u = runif(nrow(wasps), 0, 1))\nwasps_entrena <- wasps_1 |> filter(u <= 0.8)\nwasps_prueba <- wasps_1 |> filter(u > 0.8)                            \n                            \nwasp.lda <- MASS::lda(Group ~ ., data=wasps_entrena[,-1])\nwasp_ld_entrena <- predict(wasp.lda,  dimen=2)$x |> \n    as_tibble(.name_repair = \"universal\") |>\n     mutate(tipo = \"entrenamiento\") |> \n    mutate(grupo = wasps_entrena$Group)\nwasp_ld_prueba <- predict(wasp.lda, newdata = wasps_prueba, dimen=2)$x  |> \n    as_tibble(.name_repair = \"universal\") |>\n    mutate(tipo = \"prueba\")|> \n    mutate(grupo = wasps_prueba$Group)\nwasp_lda <- bind_rows(wasp_ld_entrena, wasp_ld_prueba)\nggplot(wasp_lda, aes(x = LD1, y = LD2, colour = grupo)) + geom_point(size = 3) +\n    facet_wrap(~tipo) + scale_color_colorblind()\n\n\n\n\n\nAunque esta separación de datos es menos efectiva en este ejemplo por la muestra chica, podemos ver que la separación lograda en los datos de entrenamiento probablemente se debe a variación muestral."
  },
  {
    "objectID": "pruebas-hipotesis.html#la-crisis-de-replicabilidad",
    "href": "pruebas-hipotesis.html#la-crisis-de-replicabilidad",
    "title": "1  Pruebas de hipótesis",
    "section": "La “crisis de replicabilidad”",
    "text": "La “crisis de replicabilidad”\nRecientemente (Ioannidis (2005)) se ha reconocido en campos como la sicología la crisis de replicabilidad. Varios estudios que recibieron mucha publicidad inicialmente no han podido ser replicados posteriormente por otros investigadores. Por ejemplo:\n\nHacer poses poderosas produce cambios fisiológicos que mejoran nuestro desempeño en ciertas tareas\nMostrar palabras relacionadas con “viejo” hacen que las personas caminen más lento (efectos de priming)\n\nEn todos estos casos, el argumento de la evidencia de estos efectos fue respaldada por una prueba de hipótesis nula con un valor p menor a 0.05. La razón es que ese es el estándar de publicación seguido por varias áreas y revistas. La tasa de no replicabilidad parece ser mucho más alta (al menos la mitad o más según algunas fuentes, como la señalada arriba) que lo sugeriría la tasa de falsos positivos (menos de 5%)\nEste problema de replicabilidad parece ser más frecuente cuando:\n\nSe trata de estudios de potencia baja: mediciones ruidosas y tamaños de muestra chicos.\nEl plan de análisis no está claramente definido desde un principio (lo cual es difícil cuando se están investigando “fenómenos no estudiados antes”)\n\n¿A qué se atribuye esta crisis de replicabilidad?"
  },
  {
    "objectID": "pruebas-hipotesis.html#el-jardín-de-los-senderos-que-se-bifurcan",
    "href": "pruebas-hipotesis.html#el-jardín-de-los-senderos-que-se-bifurcan",
    "title": "1  Pruebas de hipótesis",
    "section": "El jardín de los senderos que se bifurcan",
    "text": "El jardín de los senderos que se bifurcan\nAunque haya algunos ejemplos de manipulaciones conscientes –e incluso, en menos casos, malintencionadas– para obtener resultados publicables o significativos (p-hacking), como vimos en ejemplos anteriores, hay varias decisiones, todas razonables, que podemos tomar cuando estamos buscando las comparaciones correctas. Algunas pueden ser:\n\nTransformar los datos (tomar o no logaritmos, u otra transformación)\nEditar datos atípicos (razonable si los equipos pueden fallar, o hay errores de captura, por ejemplo)\nDistintas maneras de interpretar los criterios de inclusión de un estudio (por ejemplo, algunos participantes mostraron tener gripa, o revelaron que durmieron muy poco la noche anterior, etc. ¿los dejamos o los quitamos?)\n\nDado un conjunto de datos, las justificaciones de las decisiones que se toman en cada paso son razonables, pero con datos distintos las decisiones podrían ser diferentes. Este es el jardín de los senderos que se bifurcan Gelman, que invalida en parte el uso valores p como criterio de evidencia contra la hipótesis nula.\nEsto es exacerbado por:\n\nTamaños de muestra chicos y efectos “inestables” que se quieren medir (por ejemplo en sicología)\nEl hecho de que el criterio de publicación es obtener un valor p < 0.05, y la presión fuerte sobre los investigadores para producir resultados publicables (p < 0.05)\nEl que estudios o resultados similares que no obtuvieron valores \\(p\\) por debajo del umbral no son publicados o reportados.\n\nVer por ejemplo el comunicado de la ASA.\nOjo: esas presiones de publicación no sólo ocurre para investigadores en sicología. Cuando trabajamos en problemas de análisis de datos en problemas que son de importancia, es común que existan intereses de algunas partes o personas involucradas por algunos resultados u otros (por ejemplo, nuestros clientes de consultoría o clientes internos). Eso puede dañar nuestro trabajo como analistas, y el avance de nuestro equipo. Aunque esas presiones son inevitables, se vuelven manejables cuando hay una relación de confianza entre las partes involucradas."
  },
  {
    "objectID": "pruebas-hipotesis.html#ejemplo-decisiones-de-análisis-y-valores-p",
    "href": "pruebas-hipotesis.html#ejemplo-decisiones-de-análisis-y-valores-p",
    "title": "1  Pruebas de hipótesis",
    "section": "Ejemplo: decisiones de análisis y valores p",
    "text": "Ejemplo: decisiones de análisis y valores p\nEn el ejemplo de datos de fusión, decidimos probar, por ejemplo, el promedio de los cuartiles inferior y superior, lo cual no es una decisión típica pero usamos como ilustración. Ahora intentamos usar distintas mediciones de la diferencia entre los grupos, usando distintas medidas resumen y transformaciones (por ejemplo, con o sin logaritmo). Aquí hay unas 12 combinaciones distintas para hacer el análisis (multiplicadas por criterios de “aceptación de datos en la muestra”, que simulamos tomando una submuestra al azar):\n\n\nCódigo\ncalc_fusion <- function(stat_fusion, trans, comparacion){\n  fun <- function(datos){\n    datos |> \n      group_by(nv.vv) |> \n      summarise(est = stat_fusion({{ trans }}(time))) |> \n      spread(nv.vv, est) |> mutate(dif = {{ comparacion }}) |> pull(dif)\n  }\n  fun\n}\nvalor_p <- function(datos, variable, calc_diferencia, n = 1000){\n  # calcular estadística para cada grupo\n  permutar <- function(variable){\n    sample(variable, length(variable))\n  }\n  tbl_perms <- tibble(.sample = seq(1, n-1, 1)) |>\n    mutate(diferencia = map_dbl(.sample, \n              ~ datos |> mutate({{variable}} := permutar({{variable}})) |> calc_diferencia()))\n  perms <- bind_rows(tbl_perms, tibble(.sample = n, diferencia = calc_diferencia(datos)))\n  perms_ecdf <- ecdf(perms$diferencia)\n  dif <- calc_diferencia(datos)\n  2 * min(perms_ecdf(dif), 1- perms_ecdf(dif))\n}\n\n\n\n\nCódigo\nset.seed(7272)\nmedia_cuartiles <- function(x){\n    (quantile(x, 0.75) + quantile(x, 0.25))/2\n}\n# nota: usar n=10000 o más, esto solo es para demostración:\ncalc_dif <- calc_fusion(mean, identity, VV - NV)\nvalor_p(fusion |> sample_frac(0.95), nv.vv, calc_dif, n = 1000)\n\n\n[1] 0.072\n\n\nCódigo\ncalc_dif <- calc_fusion(mean, log, VV - NV)\nvalor_p(fusion |> sample_frac(0.95), nv.vv, calc_dif, n = 1000)\n\n\n[1] 0.024\n\n\nCódigo\ncalc_dif <- calc_fusion(median, identity, VV / NV)\nvalor_p(fusion |> sample_frac(0.95), nv.vv, calc_dif, n = 1000)\n\n\n[1] 0.016\n\n\nCódigo\ncalc_dif <- calc_fusion(media_cuartiles, identity, VV / NV)\nvalor_p(fusion |> sample_frac(0.95), nv.vv, calc_dif, n = 1000)\n\n\n[1] 0.026\n\n\nSi existen grados de libertad - muchas veces necesarios para hacer un análisis exitoso-, entonces los valores p pueden tener poco significado."
  },
  {
    "objectID": "pruebas-hipotesis.html#alternativas-o-soluciones",
    "href": "pruebas-hipotesis.html#alternativas-o-soluciones",
    "title": "1  Pruebas de hipótesis",
    "section": "Alternativas o soluciones",
    "text": "Alternativas o soluciones\nEl primer punto importante es reconocer que la mayor parte de nuestro trabajo es exploratorio (recordemos el proceso complicado del análisis de datos de refinamiento de preguntas). En este tipo de trabajo, reportar valores p puede tener poco sentido, y mucho menos tiene sentido aceptar algo “verdadero” cuando pasa un umbral de significancia dado.\nNuestro interés principal al hacer análisis es expresar correctamente y de manera útil la incertidumbre asociada a las conclusiones o patrones que mostramos (asociada a variación muestral, por ejemplo) para que el proceso de toma de decisiones sea informado. Un resumen de un número (valor p, o el que sea) no puede ser tomado como criterio para tomar una decisión que generalmente es compleja. En la siguiente sección veremos cómo podemos mostrar parte de esa incertidumbre de manera más útil.\nPor otra parte, los estudios confirmatorios (donde se reportan valores p) también tienen un lugar. En áreas como la sicología, existen ahora movimientos fuertes en favor de la repetición de estudios prometedores pero donde hay sospecha de grados de libertad del investigador. Este movimiento sugiere dar valor a los estudios exploratorios que no reportan valor p, y posteriormente, si el estudio es de interés, puede intentarse una replicación confirmatoria, con potencia más alta y con planes de análisis predefinidos.\n\n\n\n\nBox, George EP, William H Hunter, Stuart Hunter, et al. 1978. Statistics for experimenters. Vol. 664. John Wiley; sons New York.\n\n\nChowdhury, Niladri Roy, Dianne Cook, Heike Hofmann, Mahbubul Majumder, Eun-Kyung Lee, y Amy L Toth. 2015. «Using visual statistical inference to better understand random class separations in high dimension, low sample size data». Computational Statistics 30 (2): 293-316.\n\n\nEfron, B., y R. Tibshirani. 1993. «An Introduction to the Bootstrap». Miscellaneous. Macmillan Publishers Limited. All rights reserved.\n\n\nHesterberg, Tim C. 2015. «What teachers should know about the bootstrap: Resampling in the undergraduate statistics curriculum». The American Statistician 69 (4): 371-86.\n\n\nIoannidis, John PA. 2005. «Why most published research findings are false». PLoS medicine 2 (8): e124.\n\n\nWickham, Hadley, Dianne Cook, Heike Hofmann, y Andreas Buja. 2010. «Graphical inference for infovis». IEEE Transactions on Visualization and Computer Graphics 16 (6): 973-79.\n\n\nWickham, H, NR Chowdhury, y D Cook. 2012. «nullabor: Tools for graphical inference». R package version 0.2 1: 213."
  },
  {
    "objectID": "remuestreo-bootstrap.html#ejemplo-estimación-e-intervalos-de-confianza",
    "href": "remuestreo-bootstrap.html#ejemplo-estimación-e-intervalos-de-confianza",
    "title": "2  Remuestreo: el bootstrap",
    "section": "Ejemplo: estimación e intervalos de confianza",
    "text": "Ejemplo: estimación e intervalos de confianza\nRegresamos a nuestro ejemplo anterior donde muestreamos 3 grupos, y nos preguntábamos acerca de la diferencia de sus medianas. En lugar de hacer pruebas de permutaciones (con gráficas o numéricas), podríamos considerar qué tan precisa es cada una de nuestras estimacione para las medianas de los grupos, por ejemplo.\nNuestros resultados podríamos presentarlos como sigue:\n\n\n\n\n\nDonde en rojo está nuestro estimador puntual de la mediana de cada grupo (la mediana muestral), y las rectas mustran un intervalo de 95% para nuestra estimación de la mediana: esto quiere decir que los valores poblacionales tienen probabilidad aproximada de 95% de estar dentro del intervalo.\nEste análisis comunica correctamente que tenemos incertidumbre alta acerca de nuestras estimaciones (especialmente grupos b y c), y que no tenemos mucha evidencia de que el grupo b tenga una mediana poblacional considerablemente más alta que a o c."
  },
  {
    "objectID": "remuestreo-bootstrap.html#interpretación-de-intervalos-de-confianza",
    "href": "remuestreo-bootstrap.html#interpretación-de-intervalos-de-confianza",
    "title": "2  Remuestreo: el bootstrap",
    "section": "Interpretación de intervalos de confianza",
    "text": "Interpretación de intervalos de confianza\nGeneralmente, “intervalo de confianza” (de 90% de confianza, por ejemplo) significa, desde el punto de vista frecuentista:\n\nCada muestra produce un intervalo distinto. Para el 90% de las muestras posibles, el intervalo cubre al valor poblacional.\nAsí que con alta probabilidad, el valor poblacional está dentro del intervalo.\nIntervalos más anchos nos dan más incertidumbre acerca de dónde está el verdadero valor poblacional (y al revés para intervalos más angostos)\n\nExisten también “intervalos creíbles” (de 90% de probabilidad, por ejemplo), que se interpetan de forma bayesiana:\n\nCon alta probabilidad, creemos que el valor poblacional está dentro del intervalo creíble.\n\nLa técnica que veremos a continuación (bootstrap) se puede interpretar de las dos maneras.\n\nLa interpretación bayesiana puede ser más natural\nLa interpretación frecuentista nos da maneras empíricas de probar si los intervalos de confianza están bien calibrados o no: es un mínimo que “intervalos del 90%” debería satisfacer.\n\nAsí que tomamos el punto de vista bayesiano en la intepretación, pero buscamos que nuestros intervalos cumplan o aproximen bien garantías frecuentistas (discutimos esto más adelante)."
  },
  {
    "objectID": "remuestreo-bootstrap.html#cómo-producir-intervalos-para-estimación",
    "href": "remuestreo-bootstrap.html#cómo-producir-intervalos-para-estimación",
    "title": "2  Remuestreo: el bootstrap",
    "section": "Cómo producir intervalos para estimación",
    "text": "Cómo producir intervalos para estimación\nExisten muchas técnicas para construir estos intervalos que muestran la incertidumbre en nuestras estimaciones: métodos basados en distribuciones estándar, métodos paramétricos y no paramétricos, distintos métodos bayesianos (entonces se llaman intervalos creíbles o de probabilidad), etc.\nEn este curso, como ejemplo, y también por ser una técnica versátil, presentaremos el bootstrap no paramétrico (ver Efron y Tibshirani (1993)), donde utilizaremos simulación (y poder de cómputo) para producir este tipo de intervalos, bajo ciertas condiciones de extracción de la muestra que discutiremos más adelante."
  },
  {
    "objectID": "remuestreo-bootstrap.html#distribución-de-muestreo",
    "href": "remuestreo-bootstrap.html#distribución-de-muestreo",
    "title": "2  Remuestreo: el bootstrap",
    "section": "Distribución de Muestreo",
    "text": "Distribución de Muestreo\nSupongamos que consideramos la población de casas de nuestro ejemplo anterior\n\n\nCódigo\ncasas_pob <- casas |> select(id, precio_miles, nombre_zona)\ncasas_pob |> sample_n(20) |> formatear_tabla()\n\n\n\n\n \n  \n    id \n    precio_miles \n    nombre_zona \n  \n \n\n  \n    721 \n    275.0 \n    StoneBr \n  \n  \n    237 \n    185.5 \n    CollgCr \n  \n  \n    270 \n    148.0 \n    Edwards \n  \n  \n    269 \n    120.5 \n    IDOTRR \n  \n  \n    362 \n    145.0 \n    BrkSide \n  \n  \n    1152 \n    149.9 \n    Edwards \n  \n  \n    973 \n    99.5 \n    SawyerW \n  \n  \n    1037 \n    315.5 \n    Timber \n  \n  \n    1092 \n    160.0 \n    Somerst \n  \n  \n    1286 \n    132.5 \n    BrkSide \n  \n  \n    1208 \n    200.0 \n    CollgCr \n  \n  \n    540 \n    272.0 \n    CollgCr \n  \n  \n    367 \n    159.0 \n    NAmes \n  \n  \n    283 \n    207.5 \n    NridgHt \n  \n  \n    52 \n    114.5 \n    BrkSide \n  \n  \n    761 \n    127.5 \n    NAmes \n  \n  \n    1297 \n    155.0 \n    NAmes \n  \n  \n    822 \n    93.0 \n    OldTown \n  \n  \n    956 \n    145.0 \n    Crawfor \n  \n  \n    790 \n    187.5 \n    ClearCr \n  \n\n\n\n\n\nY nos interesa saber, para la población, cuál es la mediana de los precios de casas. Suponemos que no tenemos acceso a los datos poblacionales, y decidimos diseñar una encuesta para tomar una muestra de 50 casas que fueron vendidas en cierto periodo. Suponemos una muestra aleatoria simple con reemplazo (la población es grande y no hay mucha diferencia entre hacerlo con o sin reemplazo) de tamaño fijo, por ejemplo \\(n = 50\\)\nBuscamos estimar la mediana poblacional con la mediana de nuestra muestra:\n\n\nCódigo\nfun_muestra <- function(x){\n    median(x)\n}\n\n\nComo es de esperarse, distintas muestras dan distintas estimaciones de la mediana\n\n\nCódigo\ncasas_pob |> sample_n(50, replace = T) |> summarise(mediana = fun_muestra(precio_miles))\n\n\n# A tibble: 1 × 1\n  mediana\n    <dbl>\n1     156\n\n\nCódigo\ncasas_pob |> sample_n(50, replace = T) |> summarise(mediana = fun_muestra(precio_miles))\n\n\n# A tibble: 1 × 1\n  mediana\n    <dbl>\n1     145\n\n\nEn estimación, uno de los conceptos básicos el de la distribución de muestreo. La distribución de muestreo son los valores que puede tomar nuestro estimador bajo todas las posibles muestras que pudiéramos obtener.\n¿Por qué es importante este concepto? La distribución de muestreo del estimador nos indica qué tan lejos o cerca vamos a caer del verdadero valor poblacional que queremos estimar. No sabemos qué muestra vamos a obtener, pero con la distribución de muestreo podemos saber qué tan mal o bien nos puede ir y con qué probabilidades."
  },
  {
    "objectID": "remuestreo-bootstrap.html#aproximando-la-distribución-de-muestreo",
    "href": "remuestreo-bootstrap.html#aproximando-la-distribución-de-muestreo",
    "title": "2  Remuestreo: el bootstrap",
    "section": "Aproximando la distribución de muestreo",
    "text": "Aproximando la distribución de muestreo\nEn nuestro ejemplo tenemos la población (esto normalmente no es cierto) y podemos extraer un número muy grande de muestras de tamaño 50. Calculamos el estimador para cada una de esas muestras. El código es simple:\n\n\nCódigo\n# Repetir 5000 veces\nmediana_muestras <- map_dbl(1:5000, ~ casas_pob |> \n    sample_n(50, replace = T) |>  # muestra de 50\n    summarise(mediana_precio = fun_muestra(precio_miles)) |> pull(mediana_precio)) # calcular mediana de la muestra\n\n\nAhora examinamos la distribución de los valores que obtuvimos:\n\n\nCódigo\nsims_dm <- tibble(muestra = 1:length(mediana_muestras), mediana_precio = mediana_muestras)\nvalor_poblacional <- median(casas$precio_miles) \nggplot(sims_dm, aes(sample = mediana_muestras)) + geom_qq(distribution = stats::qunif) +\n    ylab(\"Mediana muestral\") + xlab(\"f\") + labs(subtitle = \"Distribución de muestreo para mediana (n = 50)\") +\n    geom_hline(yintercept = valor_poblacional, colour = \"red\") +\n    annotate(\"text\", x = 0.2, y = valor_poblacional+5, label = \"Mediana poblacional\", colour = \"red\")\n\n\n\n\n\n\nCon esta gráfica podemos juzgar qué tan lejos puede caer nuestra estimación muestral del valor poblacional. Cuanto más concentrada esté alrededor del valor poblacional, la probabilidad es más alta de que obtengamos una estimación precisa cuando tomemos una muestra particular. Podemos hacer un histograma también:\n\n\n\n\n\n\nLos cuantiles que cubren a un 95% de las muestras son:\n\n\nCódigo\nquantile(mediana_muestras - valor_poblacional , c(0.025, 0.975)) |> round(1)\n\n\n 2.5% 97.5% \n-21.5  21.9 \n\n\n\nEsto quiere decir que si estimamos con una muestra el valor poblacional, esperamos con 95% de probabilidad que el error sea menos de unas 20 unidades. *Esta es la precisión de nuestro estimador.\n\nSi usamos una muestra más grande (n = 200, por ejemplo) podemos obtener un resultado más preciso:\n\n\n\n\n\nY como es de esperarse, vemos que muestras más grandes resultan en menos variablidad, y menor error de estimación.\n\nMejores distribuciones de muestreo: más concentradas alrededor del verdadero valor poblacional"
  },
  {
    "objectID": "remuestreo-bootstrap.html#distribución-de-muestreo-y-distribución-poblacional",
    "href": "remuestreo-bootstrap.html#distribución-de-muestreo-y-distribución-poblacional",
    "title": "2  Remuestreo: el bootstrap",
    "section": "Distribución de muestreo y distribución poblacional",
    "text": "Distribución de muestreo y distribución poblacional\nUna confusión inicial que es común es entre la distribución de muestreo y la distribución poblacional. La poblacional muestra cómo se distribuyen los valores de la variable de interés:\n\n\nCódigo\nggplot(casas_pob, aes(x = precio_miles)) + geom_histogram() +\n    geom_vline(xintercept = valor_poblacional)\n\n\n\n\n\nQue es muy diferente que las distribuciones de muestreo de nuestros dos estimadores:\n\n\nCódigo\ng_dist_muestreo"
  },
  {
    "objectID": "remuestreo-bootstrap.html#el-mundo-bootstrap",
    "href": "remuestreo-bootstrap.html#el-mundo-bootstrap",
    "title": "2  Remuestreo: el bootstrap",
    "section": "El mundo bootstrap",
    "text": "El mundo bootstrap\nEl problema que tenemos ahora es que normalmente sólo tenemos una muestra, así que no es posible calcular las distribuciones de muestreo como hicimos arriba. Sin embargo, podemos hacer lo siguiente:\n\nSi tuviéramos la distribución poblacional, simulamos muestras para aproximar la distribución de muestreo de nuestro estimador, y así entender su variabilidad.\nPero no tenemos la distribución poblacional\nSin embargo, podemos estimar la distribución poblacional con nuestros valores muestrales\n\nMundo bootstrap\n\nSi usamos la estimación del inciso anterior, entonces usando 1 podríamos tomar muestras de nuestros datos muestrales, como si fueran de la población, y usando el mismo tamaño de muestra. El muestreo lo hacemos con reemplazo, como la muestra original.\nA la distribución resultante le llamamos distribución bootstrap de la muestra\nUsamos la distribución bootstrap de la muestra para estimar la variabilidad en nuestra estimación con la muestra original.\n\nVeamos que sucede para un ejemplo concreto. Primero extraemos nuestra muestra:\n\n\nCódigo\nset.seed(2112)\nmuestra <- sample_n(casas_pob, 150, replace = T)\n\n\nEsta muestra nos da nuestro estimador de la distribución poblacional:\n\n\nCódigo\nbind_rows(muestra |> mutate(tipo = \"muestra\"),\n    casas_pob |> mutate(tipo = \"población\")) |> \nggplot(aes(sample = precio_miles, colour = tipo, group = tipo)) + \n    geom_qq(distribution = stats::qunif, alpha = 0.7, size = 2) + \n    scale_color_colorblind()\n\n\n\n\n\nY vemos que la aproximación es razonable, especialmente en las partes centrales de la distribución. Usamos nuestra muestra para estimar la población.\nPara evaluar ahora la variabilidad de nuestro estimador, podemos extraer un número grande de muestras con reemplazo de tamaño 150 de la muestra - estamos en el mundo Bootstrap!\n\n\nCódigo\nmediana_muestras <- map_dbl(1:5000, ~ muestra |>  \n    sample_n(150, replace = T) |>\n    summarise(mediana_precio = fun_muestra(precio_miles)) |> pull(mediana_precio)) \n\n\nY nuestra estimación de la distribución de muestreo es entonces:\n\n\nCódigo\nbootstrap <- tibble(mediana = mediana_muestras)\nggplot(bootstrap, aes(sample = mediana)) + geom_qq(distribution = stats::qunif)\n\n\n\n\n\nY podemos calcular ahora un intervalo de confianza del 90% simplemente calculando los cuantiles de esta distribución (no son los cuantiles de la muestra original!):\n\n\nCódigo\nlimites_ic <- quantile(mediana_muestras, c(0.05,  0.95)) |> round()\nlimites_ic\n\n\n 5% 95% \n154 173 \n\n\nPresentaríamos nuestro resultado como sigue: nuestra estimación puntual de la mediana es 165, con un intervalo de confianza del 90% de (154, 173)"
  },
  {
    "objectID": "remuestreo-bootstrap.html#experimento-de-simulación",
    "href": "remuestreo-bootstrap.html#experimento-de-simulación",
    "title": "2  Remuestreo: el bootstrap",
    "section": "Experimento de simulación",
    "text": "Experimento de simulación\nEn nuestro ejemplo, podemos ver varias muestras (por ejemplo 20) de tamaño 100, y vemos cómo se ve la aproximación a la distribución de la población:\n\n\n\n\n\nPodemos calcular las distribuciones de remuestreo para cada muestra bootstrap, y compararlas con la distribución de muestreo real."
  },
  {
    "objectID": "remuestreo-bootstrap.html#cobertura-nominal-y-cobertura-real",
    "href": "remuestreo-bootstrap.html#cobertura-nominal-y-cobertura-real",
    "title": "2  Remuestreo: el bootstrap",
    "section": "Cobertura nominal y cobertura real",
    "text": "Cobertura nominal y cobertura real\n¿Cómo sabemos que la cobertura nominal del 90% es cercana a la realidad? Sería muy malo que los intervalos fueran demasiado anchos (exageramos la variabilidad) o demasiado angostos (damos la idea de que nuestra estimación es más precisa de lo que realmente es). Que esto se cumpla depende de:\n\nCuál es la estadística de interés\nCómo es la población\nEl tamaño de muestra y otros aspectos del muestreo\n\nVarias observaciones útiles se pueden consultar en Hesterberg (2015) y en Efron y Tibshirani (1993) (por ejemplo, el bootstrap no funciona bien para estadísticas como el mínimo o el máximo). En estas referencias también pueden consultarse recomendaciones de cómo mejorar intervalos basados en boostrap - los que vimos se llaman intervalos de percentiles, pero hay más opciones simples que se desempeñan mejor en ciertos casos.\nY siempre podemos hacer ejercicios de simulación bajo ciertos supuestos acerca de la población para una estadística dada, y estimar empíricamente si la cobertura es adecuada. \n\nEjemplo\nConstruimos para nuestra población varias muestras bootstrap con sus respectivos intervalos de cuantiles. ¿Qué porcentaje de veces cubrimos al verdadero valor?\n\n\n\n\n\nCódigo\n#rep_remuestreo <- map(1:200, ~ muestras_boot(.x, B = 2000, fun_muestra = fun_muestra)) |> bind_rows()\nrep_remuestreo <- read_csv(\"./datos/bootstrap_reps.csv\")\n\n\nCon nuestras muestras, checamos ahora nuestros intervalos y su cobertura\n\n\nCódigo\nintervalos <- rep_remuestreo |> \n    group_by(n, rep) |> \n    summarise(inf =  quantile(mediana, 0.05), sup = quantile(mediana, 0.95)) |> \n    mutate(valor_poblacional = median(casas_pob$precio_miles))\n\n\n`summarise()` has grouped output by 'n'. You can override using the `.groups`\nargument.\n\n\nCódigo\nggplot(intervalos, aes(x = rep, ymin = inf, ymax = sup)) + \n    geom_hline(yintercept = median(casas_pob$precio_miles), colour = \"salmon\") +\n    geom_linerange(alpha = 0.7) +\n    facet_wrap(~n) \n\n\n\n\n\nLa cobertura para nuestros intervalos es:\n\n\nCódigo\nintervalos |> mutate(cubre = valor_poblacional > inf & valor_poblacional < sup) |> \n     group_by(n) |> summarise(cobertura = mean(cubre), \n                               ee_cobertura = (sd(cubre) /sqrt(n())) |> round(3)) \n\n\n# A tibble: 2 × 3\n      n cobertura ee_cobertura\n  <dbl>     <dbl>        <dbl>\n1    50     0.895        0.022\n2   150     0.915        0.02 \n\n\nPara este número de repeticiones, estos números son consistentes con la cobertura nominal de 90%."
  },
  {
    "objectID": "remuestreo-bootstrap.html#ejemplo-estereogramas",
    "href": "remuestreo-bootstrap.html#ejemplo-estereogramas",
    "title": "2  Remuestreo: el bootstrap",
    "section": "Ejemplo: estereogramas",
    "text": "Ejemplo: estereogramas\nEn este caso, queremos hacer inferencia sobre la diferencia de tiempo de reconocimiento de los grupos. Como discutimos antes, preferimos hacer comparaciones multiplicativas. En este caso particular, compararemos el cociente de las medias:\nPodemos adaptar el bootstrap en este caso para dos grupos: hacemos remuestreo de cada grupo, comparamos diferencias, y repetimos\n\n\nCódigo\nfusion <- read_table(\"./datos/fusion_time.txt\")\nmuestra_boot <- function(datos, grupo, medicion, fun_muestra, comparacion){\n    est_boot <- datos |> group_by({{ grupo }}) |> \n      sample_n(n(), replace = T) |> \n      summarise(est = fun_muestra( {{ medicion }})) |> \n      spread(nv.vv, est) |> \n      mutate(comp = {{ comparacion }}) |> \n      pull(comp)\n    est_boot\n}\nmuestra_boot(fusion, nv.vv, time, median, VV / NV) |> round(2)\n\n\n[1] 0.59\n\n\nLa distribución de remuestreo es:\n\n\nCódigo\nreps_boot <- map_dbl(1:2000, ~ muestra_boot(fusion, nv.vv, time, mean, VV / NV))\nggplot(tibble(cociente_boot = reps_boot), aes(sample = reps_boot)) +\n  geom_qq(distribution = stats::qunif) + xlab(\"f\") + ylab(\"Cociente\")\n\n\n\n\n\ny un intervalo de 90% sería:\n\n\nCódigo\nquantile(reps_boot, c(0.05, 0.95)) |> round(2)\n\n\n  5%  95% \n0.46 0.91 \n\n\nY esta sería una forma de presentar nuestros resultados: hay probabilidad considerable de que el efecto de este tratamiento sea marginal (una reducción de 10%), aunque lo más probables es que tenga un efecto consdierable (reducción alrededor de 60% del tiempo de fusión)."
  },
  {
    "objectID": "remuestreo-bootstrap.html#ventajas-y-desventajas-del-bootstrap",
    "href": "remuestreo-bootstrap.html#ventajas-y-desventajas-del-bootstrap",
    "title": "2  Remuestreo: el bootstrap",
    "section": "Ventajas y desventajas del bootstrap",
    "text": "Ventajas y desventajas del bootstrap\n\nEl bootstrap es una técnica versátil generalmente fácil de implementar (ventaja) - especialmente cuando a algún nivel podemos suponer que las muestras son idependientes e idénticamente distribuidas (desventaja).\n\nPor ejemplo: en muestreo estratificado, podemos hacer bootstrap sobre cada estrato por separado. En muestreo complejo, podemos hacer bootstrap de unidades primarias de muestreo, etc.\n\nRequiere más cómputo que fórmulas estándar (desventaja), pero tenemos flexibilidad (ventaja) para aplicar en estadísticas diferentes de manera muchas veces trivial (ventaja).\nEs una técnica estándar en el análisis de datos que se usa en un rango grande de aplicaciones (ventaja).\nEn el caso de muestras chicas y ciertas distribuciones poblacionales, los intervalos bootstrap de percentiles que vimos aquí pueden ser un poco angostos y no cumplir la cobertura nominal por ejemplo, si la muestra es de tamaño < 40. la cobertura puede ser de 90% en lugar de 95% en algunos casos (población normal, o de 80% en lugar de 95% en una poblacion exponencial), ver Hesterberg (2015)). Hay mejores opciones en estos casos (por ejempo, intervalos bootstrap-t, que se calculan fácilmente también).\nFinalmente, en casos donde tenemos la población total, o el supuesto de muestras aleatorias es dudoso, lo podemos utilizar más informalmente como un análisis de sensibilidad de nuestros resultados. Es una perturbación a los datos (que podemos combinar con otros tipos de perturbaciones) para juzgar qué tan fuertemente depende nuestro análisis de los datos que tenemos a mano."
  },
  {
    "objectID": "remuestreo-bootstrap.html#sesgo",
    "href": "remuestreo-bootstrap.html#sesgo",
    "title": "2  Remuestreo: el bootstrap",
    "section": "Sesgo",
    "text": "Sesgo\nAlgunos estimadores comunes (por ejemplo, cociente de dos cantidades aleatorias) pueden sufrir de **sesgo* grande, especialmente en el caso de muestras chicas. Esto afecta la cobertura, pues es posible que nuestros intervalos no tengan “cobertura simétrica”, por ejemplo. Para muchos estimadores, y muestras no muy chicas, esté sesgo tiende a ser poco importante y no es necesario hacer correcciones.\nPodemos evaluar el sesgo comparando la media de nuestras replicaciones bootstrap con el valor muestral que obtuvimos (para estadísticas funcionales, ver Hesterberg (2015)). Si el tamaño del sesgo es chico comparado con la dispersión de la distribución bootstrap (por ejemplo, menos de 20% de la desviación estándar, Efron y Tibshirani (1993)), no es muy importante hacer correcciones.\nEn caso de que esta cantidad sea relativamente grande en relación a la dispersión de la distribución bootstrap, hay variantes los intervalos bootstrap de percentiles que mejoran esta situación (Efron y Tibshirani (1993))."
  },
  {
    "objectID": "remuestreo-bootstrap.html#bootstrap-y-estimadores-complejos-suavizadores",
    "href": "remuestreo-bootstrap.html#bootstrap-y-estimadores-complejos-suavizadores",
    "title": "2  Remuestreo: el bootstrap",
    "section": "Bootstrap y estimadores complejos: suavizadores",
    "text": "Bootstrap y estimadores complejos: suavizadores\nEl bootstrap es una técnica versátil. Por ejemplo, podemos usarlo para juzgar la variabilidad de un suavizador:\n\n\nCódigo\ngraf_casas <- function(data){\n    ggplot(data |> filter(calidad_gral < 7), \n        aes(x = area_habitable_sup_m2)) + \n        geom_point(aes(y = precio_m2_miles), alpha = 0.75) +\n        geom_smooth(aes(y = precio_m2_miles), method = \"loess\", span = 0.7, \n                se = FALSE, method.args = list(degree = 1, family = \"symmetric\"))     \n}\nset.seed(250)\ncasas_muestra <- sample_frac(casas, 0.2)\ngraf_casas(casas_muestra)\n\n\n\n\n\nPodemos hacer bootstrap para juzgar la estabilidad del suavizador:\n\n\nCódigo\nsuaviza_boot <- function(x, data){\n    # remuestreo\n    muestra_boot <- sample_n(data, nrow(data), replace = T)\n    ajuste <- loess(precio_m2_miles ~ area_habitable_sup_m2, data = muestra_boot, \n                    degree = 1, span = 0.7, family = \"symmetric\")\n    datos_grafica <- tibble(area_habitable_sup_m2 = seq(25, 250, 5))\n    ajustados <- predict(ajuste, newdata = datos_grafica)\n    datos_grafica |> mutate(ajustados = ajustados) |> \n        mutate(rep = x)\n}\nreps <- map(1:10, ~ suaviza_boot(.x, casas_muestra |> filter(calidad_gral < 7))) |> \n    bind_rows()\n\n\n\n\nCódigo\n# ojo: la rutina loess no tienen soporte para extrapolación\ngraf_casas(casas_muestra) + \n    geom_line(data = reps, aes(y = ajustados, group = rep), alpha = 1, colour = \"red\") \n\n\n\n\n\nDonde vemos que algunas cambios de pendiente del suavizador original no son muy interpretables (por ejemplo, para áreas chicas) y alta variabilidad en general en los extremos. Podemos hacer más iteraciones para calcular bandas de confianza:\n\n\nCódigo\nreps <- map(1:200, ~ suaviza_boot(.x, casas_muestra |> filter(calidad_gral < 7))) |> \n    bind_rows()\n# ojo: la rutina loess no tienen soporte para extrapolación\ngraf_casas(casas_muestra) + \n    geom_line(data = reps, aes(y = ajustados, group = rep), alpha = 0.2, colour = \"red\")"
  },
  {
    "objectID": "remuestreo-bootstrap.html#bootstrap-y-estimadores-complejos-tablas-de-perfiles",
    "href": "remuestreo-bootstrap.html#bootstrap-y-estimadores-complejos-tablas-de-perfiles",
    "title": "2  Remuestreo: el bootstrap",
    "section": "Bootstrap y estimadores complejos: tablas de perfiles",
    "text": "Bootstrap y estimadores complejos: tablas de perfiles\nPodemos regresar al ejemplo de la primera sesión donde calculamos perfiles de los tomadores de distintos tés: en bolsa, suelto, o combinados:\n\n\n\n\n\n\n\n\n\n\n \n  \n    price \n    tea bag \n    tea bag+unpackaged \n    unpackaged \n    promedio \n  \n \n\n  \n    p_upscale \n    -0.71 \n    -0.28 \n    0.98 \n    28 \n  \n  \n    p_variable \n    -0.12 \n    0.44 \n    -0.31 \n    36 \n  \n  \n    p_cheap \n    0.3 \n    -0.53 \n    0.23 \n    2 \n  \n  \n    p_branded \n    0.62 \n    -0.16 \n    -0.45 \n    25 \n  \n  \n    p_private label \n    0.72 \n    -0.22 \n    -0.49 \n    5 \n  \n  \n    p_unknown \n    1.58 \n    -0.58 \n    -1 \n    3 \n  \n\n\n\n\n\n\n\n\n\n\nHacemos bootstrap sobre toda la muestra, y repetimos exactamente el mismo proceso de construción de perfiles:\n\n\nCódigo\nboot_perfiles <- map(1:1000, function(x){\n    te_boot <- te |> sample_n(nrow(te), replace = TRUE)\n    calcular_perfiles(te_boot) |> mutate(rep = x)\n}) |> bind_rows()\n\n\nAhora resumimos y graficamos, esta vez de manera distinta:\n\n\nCódigo\nresumen_perfiles <- boot_perfiles |> group_by(how, price) |> \n    summarise(perfil_media = mean(perfil), ymax = quantile(perfil, 0.9), ymin = quantile(perfil, 0.10)) \n\n\n`summarise()` has grouped output by 'how'. You can override using the `.groups`\nargument.\n\n\nCódigo\nresumen_bolsa <- resumen_perfiles |> ungroup() |> \n    filter(how == \"tea bag\") |> select(price, perfil_bolsa = perfil_media)\nresumen_perfiles <- resumen_perfiles |> left_join(resumen_bolsa) |> \n    ungroup() |> \n    mutate(price = fct_reorder(price, perfil_bolsa))\n\n\nJoining, by = \"price\"\n\n\nCódigo\nggplot(resumen_perfiles, aes(x = price, y = perfil_media, ymax = ymax, ymin = ymin)) + \n    geom_point(colour = \"red\") + geom_linerange() +\n    facet_wrap(~how) + coord_flip() +\n    geom_hline(yintercept = 0, colour = \"gray\") + ylab(\"Perfil\") + xlab(\"Precio\")\n\n\n\n\n\nNótese una deficiencia clara del bootstrap: para los que compran té suelto, en la muestra no existen personas que desconocen de dónde provienen su té (No sabe/No contestó). Esto produce un intervalo colapsado en 0 que no es razonable.\nPodemos remediar esto de varias maneras: quitando del análisis los que no sabe o no contestaron, agrupando en otra categoría, usando un modelo, o regularizar usando proporciones calculadas con conteos modificados: por ejemplo, agregando un caso de cada combinación (agregaría 18 personas “falsas” a una muestra de 290 personas).\n\n\n\n\nEfron, B., y R. Tibshirani. 1993. «An Introduction to the Bootstrap». Miscellaneous. Macmillan Publishers Limited. All rights reserved.\n\n\nHesterberg, Tim C. 2015. «What teachers should know about the bootstrap: Resampling in the undergraduate statistics curriculum». The American Statistician 69 (4): 371-86."
  },
  {
    "objectID": "probabilidad.html",
    "href": "probabilidad.html",
    "title": "Introducción a teoría de probabilidades",
    "section": "",
    "text": "Introducción"
  },
  {
    "objectID": "modelo-prob.html",
    "href": "modelo-prob.html",
    "title": "3  Básicos de probabilidad y simulación",
    "section": "",
    "text": "En esta parte comenzaremos a tratar el concepto de probabilidad de ocurrencia de eventos acerca de los que tenemos incertidumbre. Veremos que:"
  },
  {
    "objectID": "modelo-prob.html#equiprobabilidad-y-simetría",
    "href": "modelo-prob.html#equiprobabilidad-y-simetría",
    "title": "3  Básicos de probabilidad y simulación",
    "section": "3.1 Equiprobabilidad y simetría",
    "text": "3.1 Equiprobabilidad y simetría\nHistóricamente, el concepto de probabilidad nació en el contexto de juegos de azar, y cómo definir apuestas ajustas o equitativas. Por ejemplo:\n\nSupongamos que nos cuesta 1 peso entrar a un juego de dados, y que ganamos si tiramos un 3. ¿Cuánto dinero deberíamos ganar si sale un 3 para que el costo de entrada sea justo?\n\nEl argumento iría como sigue: existen 6 posibles resultados, y como el dado se tira bien y está bien hecho, entonces sería lo mismo apostar a cualquier número. Entonces, si seis personas entran al juego apostando a distintos números, cada uno pagando 1 peso, sería justo que el ganador se llevara 6 pesos.\n\nEn este caso, definimos la probabilidad de obtener un 3 (o cualquier otro número) como 1/6, que es cociente entre la apuesta inicial entre la cantidad recibida si ganamos la apuesta justa.\n\nNótese que el criterio de “justicia” proviene de simetrías del experimento: si el dado no fuera simétrico, por ejemplo, esta sería una manera mala de definir probabilidades.\nEn general, una manera de difinir probabilidad es la siguiente:\n\n\n\nEspacios equiprobables\nSi un evento \\(A\\) puede ocurrir de \\(k\\) maneras de \\(n\\) posibles, y es indiferente apostar a cualquiera de los \\(n\\) posibles resultados, entonces\n\\[P(A) = \\frac{k}{n}\\]\n\n\nCon este enfoque podemos resolver diversos problemas de probabilidad, por ejemplo:"
  },
  {
    "objectID": "modelo-prob.html#ejemplo-dados",
    "href": "modelo-prob.html#ejemplo-dados",
    "title": "3  Básicos de probabilidad y simulación",
    "section": "Ejemplo: dados",
    "text": "Ejemplo: dados\n¿Cuál es la probabilidad de que tiremos una suma de 9 con dos dados de seis lados?\nEn este caso, los resultados son pares \\((x, y)\\) donde \\(x\\) es el resultado del dado 1 y \\(y\\) es el resultado del dado 2. Existen 36 pares, y todos ellos son equivalentes. Para tirar un 9, tenemos que lograr alguna de las siguientes tiradas:\n\\[(3, 6), (4, 5), (5, 4), (6, 3)\\]\nDe modo que la probabilidad de tirar una suma de 9 , que escribimos como \\(S=9\\), es\n\\[P(S = 9) = 4/36 = 1/9\\]"
  },
  {
    "objectID": "modelo-prob.html#ejemplo-cartas",
    "href": "modelo-prob.html#ejemplo-cartas",
    "title": "3  Básicos de probabilidad y simulación",
    "section": "Ejemplo: cartas",
    "text": "Ejemplo: cartas\nSacamos dos cartas sucesivamente de una baraja de 52 cartas, donde 26 son negras y 26 rojas. ¿Cuál es la probabilidad de que la segunda carta que saquemos sea negra? Podemos denotar como \\(N_2\\) el evento que sucede cuando la segunda carta que sacamos es negra. La segunda carta que sacamos puede ser cualquiera de las 52, y somos indiferentes en apostar a cualqueira de las cartas para salir en segundo lugar, así que\n\\[P(N_2) = 26 / 52 = 1/2\\]\nEstos espacios equiprobables nos dan nuestros modelos probabilísticos más simples. Están basados en simetrías del espacio de resultados."
  },
  {
    "objectID": "modelo-prob.html#probabilidad-y-frecuencias-relativas",
    "href": "modelo-prob.html#probabilidad-y-frecuencias-relativas",
    "title": "3  Básicos de probabilidad y simulación",
    "section": "3.2 Probabilidad y frecuencias relativas",
    "text": "3.2 Probabilidad y frecuencias relativas\nLa conexión entre experimentos reales y modelos de probabilidad, está en que si repetimos muchas veces el experimento, entonces las frecuencias relativas de ocurrencia de los eventos aproxima a las probabilidades teóricas. Por ejemplo, si tiramos muchos volados con una moneda bien balanceada, esperamos obtener alrededor de 1/2 de soles y 1/2 de águilas, y si tiramos un dado muchas veces esperamos obtener alrededor de 1/6 de las tiradas un 5, por ejemplo (bajo los modelos de resultados equiprobables correspondientes).\nEn realidad, esta es otra definición de probabilidad en términos de repeticiones de experimentos.\n\n\n\nProbabilidades y frecuencias\nSupongamos que repetimos una gran cantidad \\(n\\) de veces un experimento, y que registramos \\(k_n\\) = cuántas veces ocurre un evento \\(A\\). La probabilidad de que ocurra \\(A\\) es\n\\[\\lim_{n\\to\\infty} \\frac{k_n}{n} \\to P(A), \\]\nes decir, \\(P(A)\\) el la frecuencia al largo plazo de ocurrencia de \\(A\\).\n\n\nAunque podríamos hacer algunos experimentos físicos más reales, para este curso podemos hacer simulaciones de computadora del experimento que nos interesa."
  },
  {
    "objectID": "modelo-prob.html#ejemplo-simulación-de-un-dado",
    "href": "modelo-prob.html#ejemplo-simulación-de-un-dado",
    "title": "3  Básicos de probabilidad y simulación",
    "section": "Ejemplo: simulación de un dado",
    "text": "Ejemplo: simulación de un dado\nPrimero hacemos un dado. Podemos simular una tirada de dado como:\n\n\nCódigo\nsimular_dado <- function(caras = 1:6){\n   sample(caras, 1)\n}\nsimular_dado()\n\n\n[1] 4\n\n\nAhora simulamos una gran cantidad de tiradas de dado:\n\n\nCódigo\nset.seed(199213)\nn <- 5000\nsims_dado <- map_df(1:n, ~ c(n_sim = .x, resultado = simular_dado()))\nhead(sims_dado) \n\n\n# A tibble: 6 × 2\n  n_sim resultado\n  <int>     <int>\n1     1         3\n2     2         6\n3     3         3\n4     4         3\n5     5         6\n6     6         3\n\n\nEsta es una variable numérica, pero como toma valores enteros del uno al seis, podemos resumir con frecuencias, como si fuera categórica:\n\n\nCódigo\nsims_dado %>% \n   count(resultado) %>% \n   mutate(frec_relativa = n / sum(n))\n\n\n# A tibble: 6 × 3\n  resultado     n frec_relativa\n      <int> <int>         <dbl>\n1         1   806         0.161\n2         2   814         0.163\n3         3   857         0.171\n4         4   898         0.180\n5         5   856         0.171\n6         6   769         0.154\n\n\nY nuestro modelo teórico (resultados equiprobables) coincide razonablemente bien con las frecuencias observadas a largo plazo. Podemos ver cómo convergen las frecuencias relativas por ejemplo del resultado 1:\n\n\nCódigo\nsims_dado %>% \n   mutate(no_unos = cumsum(resultado == 1)) %>% \n   mutate(frec_uno = no_unos / n_sim) %>%\n   filter(n_sim < 5000) %>% \nggplot(aes(x = n_sim, y = frec_uno)) +\n   geom_hline(yintercept = 1/6, colour = \"red\") +\n   geom_line() + ylab(\"Frecuencia relativa de unos\")\n\n\n\n\n\nNótese que cuando hay pocas repeticiones podemos ver fluctuaciones considerablemente grandes de la frecuencia relativa observada de unos. Sin embargo, conforme aumentamos el tamaño de la meustra observada, esas fluctuaciones son más chicas.\nVeamos otra simulación:\n\n\nCódigo\nsims_dado <- map_df(1:n, ~ c(n_sim = .x, resultado = simular_dado()))\nsims_dado %>% \n   mutate(no_unos = cumsum(resultado == 1)) %>% \n   mutate(frec_uno = no_unos / n_sim) %>%\n   filter(n_sim < 5000) %>% \nggplot(aes(x = n_sim, y = frec_uno)) +\n   geom_hline(yintercept = 1/6, colour = \"red\") +\n   geom_line() + ylab(\"Frecuencia relativa de unos\")"
  },
  {
    "objectID": "modelo-prob.html#datos-y-modelos-de-probabilidad",
    "href": "modelo-prob.html#datos-y-modelos-de-probabilidad",
    "title": "3  Básicos de probabilidad y simulación",
    "section": "3.3 Datos y modelos de probabilidad",
    "text": "3.3 Datos y modelos de probabilidad\n¿Cómo podemos usar modelos de probablidad para describir datos observados? La idea (simplificada) es la siguiente:\n\nHacemos una hipótesis acerca de cómo es el modelo de probabilidad asociado a un fenómeno\nObservamos una muestra de datos del fenómeno que nos interesa\nEvaluamos si las fluctuaciones observadas debidas a la información limitada que tenemos (una muestra) son consistentes con el modelo de probabilidad\n\nConsideremos el ejemplo de los dados. Supongamos que lanzamos el dado un número no muy grande de veces, y observamos:\n\n\nCódigo\nfrecs_obs <- tibble(resultado = 1:6,\n                    n = c(5, 7, 5, 10, 8, 5)) %>% \n   mutate(frec = n / sum(n))\nfrecs_obs %>% kable(digits = 2)\n\n\n\n\n \n  \n    resultado \n    n \n    frec \n  \n \n\n  \n    1 \n    5 \n    0.12 \n  \n  \n    2 \n    7 \n    0.17 \n  \n  \n    3 \n    5 \n    0.12 \n  \n  \n    4 \n    10 \n    0.25 \n  \n  \n    5 \n    8 \n    0.20 \n  \n  \n    6 \n    5 \n    0.12 \n  \n\n\n\n\n\nY nos preguntamos si este resultado podría ser observado bajo los supuestos de nuestro modelo de probabilidad, que en este caso, es el de resultados equiprobables. Podemos por ejemplo graficar los datos junto con simulaciones del modelo, en búsqueda de desajustes:\n\n\nCódigo\nset.seed(8834)\n# una vez\nsim_exp <- map_df(1:40, ~ c(id = .x, resultado = simular_dado()))\n# 19 veces\nsims_exp <- map_df(1:19, function(x){\n         sims <- map_df(1:40, ~ c(id = .x, resultado = simular_dado()) )\n         sims$rep <- x\n         sims\n         })\n\n\n\n\nCódigo\nfrec_sims <- sims_exp %>% \n   group_by(rep, resultado) %>% \n   summarise(n = n()) %>% \n   mutate(frec = n / sum(n))\n\n\n`summarise()` has grouped output by 'rep'. You can override using the `.groups`\nargument.\n\n\nCódigo\nobs_sims_tbl <- bind_rows(frec_sims, frecs_obs %>% mutate(rep = 20))\nggplot(obs_sims_tbl, aes(x = resultado, y = frec)) +\n   geom_col() +\n   facet_wrap(~rep)\n\n\n\n\n\nEn este caso, no vemos ninguna característica de los datos observados que no sea consistente las fluctuaciones esperadas para un tamaño de muestra de \\(n=40\\).\nPregunta: ¿qué defecto le ves a esta gráfica que tiene los datos en la posición 20? ¿Cómo podríamos hacer una evaluación más apropiada de la calidad del ajuste?\nObservación: como veremos, muchas veces proponemos modelos que tienen parámetros que deben ser estimados con la muestra. Este caso más común es más complejo que el explicado arriba, pero el proceso es similar."
  },
  {
    "objectID": "modelo-prob.html#espacios-no-equiprobables",
    "href": "modelo-prob.html#espacios-no-equiprobables",
    "title": "3  Básicos de probabilidad y simulación",
    "section": "3.4 Espacios no equiprobables",
    "text": "3.4 Espacios no equiprobables\nDepende cómo planteemos nuestro experimento aleatorio, puede ser o no apropiado el modelo equiprobable. Veremos ahora algunos ejemplos donde construimos modelos no equiprobables"
  },
  {
    "objectID": "modelo-prob.html#ejemplo-dos-dados",
    "href": "modelo-prob.html#ejemplo-dos-dados",
    "title": "3  Básicos de probabilidad y simulación",
    "section": "Ejemplo: dos dados",
    "text": "Ejemplo: dos dados\nSupongamos que nos interesa la suma de dos tiradas de dados. Comenzamos con un modelo equiprobable sobre los resultados de cada tirada, que denotamos como \\((x,y)\\). Cada resultado tiene probabilidad 1/36.\nSin embargo, sólo nos interesa la suma. Contando posibles resultados podemos dar la probabilidad de cada resultado:\n\n\n\nSuma\nResultados\nProb\n\n\n\n\n2\n(1,1)\n1/36\n\n\n3\n(1,2),(2,1)\n2/36\n\n\n4\n(1,3),(2,2),(3,1)\n3/36\n\n\n5\n(1,4),(2,3),(3,2),(4,1)\n4/36\n\n\n6\n(1,5),(2,4),(3,3),(4,2),(5,1)\n5/36\n\n\n7\n(1,6),(2,5),(3,4),(4,3),(5,2),(6,1)\n6/36\n\n\n8\n(2,6),(3,5),(4,4),(5,3),(6,2)\n5/35\n\n\n9\n(3,6),(4,5),(5,4),(6,3)\n4/36\n\n\n10\n(4,6),(5,5),(6,4)\n3/36\n\n\n11\n(5,6), (6,5)\n2/36\n\n\n12\n(6,6)\n1/36\n\n\n\nY entonces terminamos con la siguiente distribución no equiprobable sobre las posibles sumas:\n\n\nCódigo\nprobs_suma <- tibble(suma = 2:12) %>% \n   mutate(prob = (6 - abs(suma - 7)) / 36)\nprobs_suma %>% kable(digits = 3)\n\n\n\n\n \n  \n    suma \n    prob \n  \n \n\n  \n    2 \n    0.028 \n  \n  \n    3 \n    0.056 \n  \n  \n    4 \n    0.083 \n  \n  \n    5 \n    0.111 \n  \n  \n    6 \n    0.139 \n  \n  \n    7 \n    0.167 \n  \n  \n    8 \n    0.139 \n  \n  \n    9 \n    0.111 \n  \n  \n    10 \n    0.083 \n  \n  \n    11 \n    0.056 \n  \n  \n    12 \n    0.028 \n  \n\n\n\n\n\nEsta distribución la podemos graficar como sigue:\n\n\nCódigo\ng_teorica <- ggplot(probs_suma, aes(x = suma, y = prob)) +\n   geom_col() +\n   scale_x_continuous(breaks = 2:12)\ng_teorica\n\n\n\n\n\nPodríamos tirar dos dado un gran número de veces para verificar si este modelo da las probabilidades correctas (o más propiamente dicho, si estas observaciones son consistentes con el modelo de probabilidad mostrado arriba)."
  },
  {
    "objectID": "modelo-prob.html#reglas-básicas-de-probabilidad",
    "href": "modelo-prob.html#reglas-básicas-de-probabilidad",
    "title": "3  Básicos de probabilidad y simulación",
    "section": "3.5 Reglas básicas de probabilidad",
    "text": "3.5 Reglas básicas de probabilidad\nTanto modelos equiprobables como la interpretación frecuentista de la probabilidad resultan en un conjunto de reglas útiles para operar con probabilidades. Estas son reglas generales que aplican independientemente de la interpretación particular de la probabilidad que utilicemos.\n\nLa probabilidad del evento cierto es 1 Si \\(A\\) es el evento que cubre todos los posibles resultados, entonces \\(P(A) = 1\\).\n\nAsegúrate que puedes demostrar esto para un espacio equiprobable, por ejemplo.\n\nLa probabilidad de que un evento \\(A\\) no ocurra es \\(1- P(A)\\).\n\n¿Por qué es cierto esto en espacios equiprobables? ¿Y según la definición frecuentista? Usa esta regla y el ejemplo anterior para calcular la probabilidad de tirar una suma menor a 12 cuando tiramos dos dados.\nEsto normalmente lo escribimos como \\(P(A^c) = 1 - P(A)\\).\nDecimos que dos eventos \\(A\\) y \\(B\\) son disjuntos cuando no pueden ocurrir simultánemente, o en otras palabras, el conjunto de resultados donde ocurre \\(A\\) tiene intersección vacía con el conjunto de resultados donde ocurre \\(B\\).\n\nLa probabilidad de que ocurra un resultado dentro de un conjunto de eventos disjuntos es igual a la suma de las probabilidades de dichos eventos\n\nEsto lo podemos escribir como sigue: si \\(A_1, A_2, \\dots, A_n\\) son eventos disjuntos, entonces\n\\[P(A_1\\cup A_2\\cup \\cdots \\cup A_n) = P(A_1) + P(A_2) + \\cdots + P(A_n)\\]\nUtiliza esta regla para\n\nCalcula la probabilidad de tirar una suma mayor a 9 en dos tiradas de dados.\nCalcula la probabilidad de obtener un par al sacar dos cartas de una baraja usual de póquer.\nMás difícil: hay una caja con \\(100\\) pelotas, y una de ellas es dorada. Si sacamos al azar \\(20\\) pelotas, una a la vez, ¿cuál es la probabilidad de que nos salga la pelota dorada? ¿ y si sacamos 57 pelotas?\n\nSoluciones:\n\nPara tirar más de 9, podemos tirar 10, 11 o 12, así que \\(P(A) = P(A_{10}\\cup A_{11} \\cup A_{12})\\). Estos útlimos tres eventos son mutuamente excluyentes, así que por la regla de la suma,\n\n\\[P(A) = P(A_{10}) + P(A_{11}) + P(A_{12})\\] y consultando nuestra tabla de arriba,\n\\[P(A) = \\frac{3}{36} + \\frac{2}{36} + \\frac{1}{36} = 1/6\\]\n\nPodemos sacar \\(52(51)\\) pares distintos. Ahora calculamos la probabidad de sacar un par particular, por ejemplo de ases. Hay \\(4(3)=12\\) distintos pares de ases (en el orden que los sacamos). Lo mismo podemos decir de pares de 2, 3, etc. Así que sumando sobre cada una de estas posibilidades obtenemos:\n\n\\[P(A) = 13\\frac{4(3)}{52(51)} \\approx 0.0588\\]\nTambién podríamos calcular de la siguiente forma: sacamos la primera carta y la vemos. La siguiente carta puede ser una de 51 restantes, y solo con tres de ellas completamos un par, de forma que\n\\[P(A) = 3 / 51 \\approx 0.0588\\]\n\nSea \\(D\\) el evento donde en el proceso sacamos la pelota dorada, y sea \\(D_1\\) el evento donde sacamos la pelota dorada en nuestra primera extracción, \\(D_2\\) si la sacamos en la segunda, etc. Tenemos que\n\n\\[D =D_1 \\cup D_2 \\cup\\cdots \\cup D_{20}\\]\n(sacamos la dorada si y sólo si la sacamos en la extracción 1, 2 , etc. hasta 20) Además, solo hay una pelota dorada, de manera que \\(D_i\\cap D_j= \\emptyset\\), es decir, no pueden ocurrir juntos \\(D_1\\) y \\(D_2\\), \\(D_5\\) y \\(D_11\\), etc., así que por la regla de la suma\n\\[P(D) = P(D_1) + P(D_2) + \\dots + P(D_{20})\\]\nFinalmente, \\(P(D_1)= 1/100\\), pues hay 100 pelotas y todas tienen igual probabilidad de aparecen en la primera extracción. Pero también \\(P(D_2) = 1/100\\), pues todas las pelotas tienen la misma probabilidad de aparecer en la segunda extracción. Se sigue entonces que, haciendo la suma de arriba, que: \\(P(D) = 20(\\frac{1}{100}) = 0.20\\)"
  },
  {
    "objectID": "modelo-prob.html#simulación-y-probabilidad",
    "href": "modelo-prob.html#simulación-y-probabilidad",
    "title": "3  Básicos de probabilidad y simulación",
    "section": "3.6 Simulación y probabilidad",
    "text": "3.6 Simulación y probabilidad\nUsando la interpetación frecuentista, también es posible resolver una variedad de problemas de probabilidad usando simulación. La idea es, si queremos aproximar la probabilidad \\(P(E)\\) de un evento es:\n\nDefinimos el espacio de resultados del experimento aleatorio.\nSimulamos el experimento aleatorio un número grande de veces.\nCalculamos para cuáles de esas simulaciones se cumple el evento \\(E\\)\nEstimamos la frecuencia relativa de ocurrencia de \\(E\\) a lo largo de todas las simulaciones.\n\n\nEjemplo: simulando dos dados\nPara dos dados, el espacio de resultados podemos escribirlo como los resultados conjunto de dos tiradas: \\((x,y)\\). Cada dado se tira de forma separada, y los resultados son equiprobables. Definimos entonces:\n\n\nCódigo\nsim_dados <- function(num_dados = 2, num_caras = 6){\n   resultado <- sample(1:num_caras, num_dados, replace = TRUE)\n   names(resultado) <- paste0(\"dado_\", 1:num_dados)\n   resultado\n}\nsim_dados()\n\n\ndado_1 dado_2 \n     5      3 \n\n\nAhora simulamos un número grande de veces el experimento:\n\n\nCódigo\nset.seed(2323)\nsims <- map_df(1:10000, ~ sim_dados())\nsims\n\n\n# A tibble: 10,000 × 2\n   dado_1 dado_2\n    <int>  <int>\n 1      5      6\n 2      3      3\n 3      2      5\n 4      3      5\n 5      6      4\n 6      2      2\n 7      3      6\n 8      6      5\n 9      3      4\n10      1      1\n# … with 9,990 more rows\n\n\nAhora que tenemos estas simulaciones, podemos estimar por ejemplo la probabilidad de tirar más de nueve con dos dados. Primero calculamos en qué simulaciones ocurre \\(E\\):\n\n\nCódigo\nsims_e <- \n   sims %>% \n   mutate(suma = dado_1 + dado_2) %>% \n   mutate(evento_E = (suma > 9)) \nsims_e\n\n\n# A tibble: 10,000 × 4\n   dado_1 dado_2  suma evento_E\n    <int>  <int> <int> <lgl>   \n 1      5      6    11 TRUE    \n 2      3      3     6 FALSE   \n 3      2      5     7 FALSE   \n 4      3      5     8 FALSE   \n 5      6      4    10 TRUE    \n 6      2      2     4 FALSE   \n 7      3      6     9 FALSE   \n 8      6      5    11 TRUE    \n 9      3      4     7 FALSE   \n10      1      1     2 FALSE   \n# … with 9,990 more rows\n\n\nY ahora calculamos la frecuencia relativa de ocurrencia de \\(E\\)\n\n\nCódigo\nsims_e %>% \n   summarise(frec_e = mean(evento_E))\n\n\n# A tibble: 1 × 1\n  frec_e\n   <dbl>\n1  0.169\n\n\nQue confirma a dos decimales el resultado que obtuvimos arriba usando la regla de la suma (o contando resultados).\n\n\nEjemplo: problema de pelotas\nExtraemos al azar\n\n\nCódigo\nset.seed(232)\npelotas <- c(\"dorada\", rep(\"otra\", 99))\nsim_extraccion <- function(){\n    sample(pelotas, 20, replace = FALSE)\n}\nsim_extraccion()\n\n\n [1] \"otra\" \"otra\" \"otra\" \"otra\" \"otra\" \"otra\" \"otra\" \"otra\" \"otra\" \"otra\"\n[11] \"otra\" \"otra\" \"otra\" \"otra\" \"otra\" \"otra\" \"otra\" \"otra\" \"otra\" \"otra\"\n\n\nSimulamos el experimento aleatorio:\n\n\nCódigo\nsims_pelotas <- map(1:10000, ~ sim_extraccion())\nsims_pelotas[1:2]\n\n\n[[1]]\n [1] \"otra\"   \"otra\"   \"otra\"   \"otra\"   \"otra\"   \"otra\"   \"otra\"   \"otra\"  \n [9] \"dorada\" \"otra\"   \"otra\"   \"otra\"   \"otra\"   \"otra\"   \"otra\"   \"otra\"  \n[17] \"otra\"   \"otra\"   \"otra\"   \"otra\"  \n\n[[2]]\n [1] \"otra\" \"otra\" \"otra\" \"otra\" \"otra\" \"otra\" \"otra\" \"otra\" \"otra\" \"otra\"\n[11] \"otra\" \"otra\" \"otra\" \"otra\" \"otra\" \"otra\" \"otra\" \"otra\" \"otra\" \"otra\"\n\n\nChecamos si ocurre o no el evento se extrajo la pelota dorada:\n\n\nCódigo\nevento_dorada <- map_lgl(sims_pelotas, ~ any(str_detect(.x, \"dorada\")))\nevento_dorada[1:10]                   \n\n\n [1]  TRUE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE  TRUE\n\n\nY calculamos la frecuencia relativa de ocurrencia del evento:\n\n\nCódigo\nmean(evento_dorada)\n\n\n[1] 0.2007\n\n\nQue es consistente con el resultado que obtuvimos arriba haciendo cálculos.\n\n\n\nPara estimar probabilidades de ocurrencia de un evento usualmente es posible hacer simulaciones por computadora. Esto es especialmente importante cuando el experimento y evento que consideramos hace difícil (a veces imposible) hacer cálculos analíticos.\nEste tipo de métodos basados en simulación se llaman en general métodos de Monte Carlo.\n\n\n\n\n3.6.1 Ejemplo:\nSupongamos que ponemos 15 puntos igualmente espaciados en una circunferencia. Si escogemos tres puntos al azar, ¿cuál es la probabilidad de que formen un triángulo equilátero? Este problema se puede resolver contando los posibles resultados donde se forma un triángulo equilátero, pero no es trivial. Veamos cómo la haríamos simulando:\n\n\nCódigo\nsimular_3_puntos <- function(){\n   puntos_angulo <- 0:14 * (2  *pi / 15)\n   sample(puntos_angulo, 3)\n}\nsimular_3_puntos()\n\n\n[1] 3.769911 3.351032 1.675516\n\n\nCalcular dado el resultado requiere algo de consideración, pero finalmente terminamos con (¿qué otra manera se te ocurre?):\n\n\nCódigo\nes_equilatero <- function(tres_puntos){\n   tol <- 10^(-6)\n   puntos_ord <- sort(tres_puntos)\n   dif_1 <- puntos_ord[3] - puntos_ord[2]\n   dif_2 <- puntos_ord[2] - puntos_ord[1]\n   dif_3 <- 2*pi + puntos_ord[1] - puntos_ord[3]\n   if(abs(dif_1 - dif_2) < tol & abs(dif_2 - dif_3) < tol){\n      equilatero <- TRUE\n   } else {\n      equilatero <- FALSE\n   }\n   equilatero\n}\n\n\nSimulamos:\n\n\nCódigo\nsims_puntos <- map(1:50000, ~ simular_3_puntos())\n\n\nCalculamos la ocurrencia del evento de interés:\n\n\nCódigo\nevento <- map_lgl(sims_puntos, ~ es_equilatero(.x))\n\n\nY al frecuencia relativa es:\n\n\nCódigo\nmean(evento)\n\n\n[1] 0.01168\n\n\n¿Puedes resolver este problema contando los posibles triángulos, y cuáles de ellos son equiláteros?"
  },
  {
    "objectID": "modelo-prob.html#probabilidad-subjetiva",
    "href": "modelo-prob.html#probabilidad-subjetiva",
    "title": "3  Básicos de probabilidad y simulación",
    "section": "3.7 Probabilidad subjetiva",
    "text": "3.7 Probabilidad subjetiva\nExiste otra manera más flexible de interpretar la probabilidad que tiene que ver con un “grado de creencia” en que un evento va a ocurrir. Por ejemplo, el evento \\(A\\) podría ser “va a llover mañana”, y según mi conocimiento establezco que \\[P(A) = 0.25\\]\nEsta es una probablidad subjetiva pero no arbitraria. Para entender por qué es eso, pensemos en un juego de azar que consiste jugar una lotería de 100 boletos, donde podemos jugar con un número de boletos dado. Comparamos entonces dos alternativas:\n\nSi \\(A\\) ocurre, es decir, llueve mañana, entonces gano 1000 pesos.\nLa lotería de 100 boletos tiene un único premio de 1000 pesos.\n\nEntonces me puedo preguntar:\n\n¿Qué prefiero, jugar 1 o jugar 2 con 5 boletos?\n\nSi prefiero 1, entonces creo que \\(P(A)>0.05\\). Ahora puedo preguntarme:\n\n¿Qué prefiero, jugar 1 o jugar 2 con 20 boletos?\n\nSi prefiero 1, entonces creo que \\(P(A)>0.20\\) Sin embargo, probablemente si me pregunto si prefiero jugar 1 o jugar 2 con 90 boletos, prefería jugar la lotería, de modo yo creo que \\(P(A)<0.90.\\)\nCon estos ejercicios de preferencias sobre apuestas comparando con juegos de azar simples, puedo ver cuál es la probabilidad que yo le asigno a cualquier evento. Es posible demostrar que una probabilidad definida de esta manera cumple todas las reglas de probabilidad que mostramos arriba (si mis decisiones son racionales). Es posible definir modelos de probabilidad con este enfoque subjetivo, y es posible operar con ellos de manera usual con la maquinaria matemática.\nLo poderoso de este enfoque es que nos permite atacar problemas que 1) no está claro cómo podrían derivarse a partir de modelos equiprobables, y 2) no está claro que sea posible reproducir el experimento muchas veces para ver cual es la frecuencia relativa de ocurrencia del evento. Por ejemplo:\n\n¿Cuál es la probabilidad de que esta persona X contraiga una enfermedad particular?\n¿Cuál es la probabilidad de que un candidato Y gane una elección?\n¿Qué tan probable es que el próximo año el crecimiento del PIB sea mayor a 1%?\n\nEn todos estos casos importantes donde tenemos que tomar decisiones, la única alternativa real es pensar en términos de probabilidad subjetiva.\nEn la práctica, este tipo de enfoque se utiliza para poner probabilidades sobre cantidades o aspectos difíciles de medir directamente pero que son relativamente simples, y luego se utilizan modelos y reglas de probabilidad para producir otras probabilidades de interés más complicadas."
  },
  {
    "objectID": "modelo-prob.html#probabilidad-subjetiva-y-calibración-frecuentista",
    "href": "modelo-prob.html#probabilidad-subjetiva-y-calibración-frecuentista",
    "title": "3  Básicos de probabilidad y simulación",
    "section": "3.8 Probabilidad subjetiva y calibración frecuentista",
    "text": "3.8 Probabilidad subjetiva y calibración frecuentista\nComo podemos imaginarnos, para muchas decisiones importantes, el enfoque subjetivo por sí solo puede no ser suficiente. Por ejemplo, imaginemos que trabajamos en INEGI queremos estimar el ingreso total de los hogares en México. Sería difícil proponer para esta tarea un enfoque puramente subjetivo.\nEn estos caso, podemos usar un enfoque donde utilizamos las probabilidades de manera subjetiva (por ejemplo elicitadas de un pánel de expertos), pero demostramos también que nuestro método tiene propiedades frecuentistas apropiadas: por ejemplo, que nuestros intervalos de 95% de estimación son realmente de 95%. Esto normalmente se cumple 1) Checando supuestos de nuestro modelo 2) Sometiendo nuestro método a distintos escenarios de estimación, y checando que se cumplen estimaciones frecuentistas apropiadas. En realidad, usualmente estos dos últimos pasos, 1 y 2, deben ser llevados a cabo no importa el enfoque de interpretación que utilicemos, pues cualquier método, frecuentista o subjetivo, tiene condiciones bajo las que puede fallar."
  },
  {
    "objectID": "prob-condicional.html",
    "href": "prob-condicional.html",
    "title": "4  Probabilidad condicional e independencia",
    "section": "",
    "text": "Uno los conceptos centrales de la probabilidad es el de probabilidad condicional:\nMuchos de los problemas de esta sección son de (Ross (1998))."
  },
  {
    "objectID": "prob-condicional.html#probabilidad-condicional-en-espacios-equiprobables.",
    "href": "prob-condicional.html#probabilidad-condicional-en-espacios-equiprobables.",
    "title": "4  Probabilidad condicional e independencia",
    "section": "4.1 Probabilidad condicional en espacios equiprobables.",
    "text": "4.1 Probabilidad condicional en espacios equiprobables.\nSupongamos que en un experimento simétro de \\(n\\) posibles resultados, sabemos que ocurrió el evento \\(F\\), es decir, un conjunto de resultados fijo. ¿Cómo podemos calcular la probabilidad de que ocurra un evento \\(E\\) dado que sabemos que \\(F\\) ocurrió? Esta probabilidad se escribe\n\\[P(E|F)\\]\n\n4.1.1 Ejemplo: dos dados\nSupongamos que tiramos dos dados, y nos dicen que la suma de los dos datos es igual a 6. ¿Cuál es la probablidad condicional de haber tirado al menos un cinco dado que la suma es 6?\nSolución: los resultados equiprobables que resultan en un tiro de suma 6 son \\(F= \\{ (5,1),(4,2),(3,3),(2,4),(1,5)\\}\\), que son 5 posibles resultados. En solamente 2 de ellos tiramos un cinco. Como estos resultados son equiprobables, si \\(E\\) es el evento “tirar al menos un 5”,\n\\[P(E|F) = 2/5\\]\nPodemos formalizar de la siguiente manera: para calcular \\(P(E|F)\\) contamos todos los resultados de \\(F\\) donde también ocurre \\(E\\) y dividimos entre las maneras en que puede ocurrir \\(F\\):\n\nEn nuestro caso hay muchos resultados posibles donde tiramos al menos un 5, por ejemplo \\((5,1), (5,2), (5,6)\\) y así sucesivamente. Sin embargo, solo en 2 de ellos la suma es 5.\n\n\n\n\nEn un espacio de resultados equiprobables, si \\(E\\) y \\(F\\) son eventos, entonces\n\\[P(E|F) = \\frac{n(E\\cap F)}{n(F)},\\]\nes decir, dividimos el número de maneras en que pueden ocurrir \\(E\\) y \\(F\\) simultáneamente entre el número de maneras en que puede ocurrir \\(F\\).\n\n\nNótese que otra manera de ver esta definición es como sigue: una vez que sabemos que ocurrió \\(F\\), restringimos todo nuestro análisis a resultados dentro de \\(F\\), y proseguimos como si se tratara de una probabilidad usual.\n\n\n4.1.2 Ejemplo: dos volados\nSupongamos que tiramos dos volados. Cuál es la probabilidad condicional de que los dos volados sean sol (evento \\(E\\)) dado que 1) El primer volado es sol? 2) Alguno de los dos volados es sol, 3) Los dos volados son águilas?\nHay 2 resultados donde el primer volado es sol (enuméralos), así que la primer probabilidad es \\(P(E|F_1)=1/2\\). Explica por qué la segunda probabilidad condicional es igual a \\(P(E|F_2)=1/3\\). ¿Cuánto vale \\(P(E|F_3)\\)?\n\n\n4.1.3 Ejemplo: tres cartas\nSupongamos que extraemos tres cartas al azar de una baraja de 52 cartas (13 son corazones). Nos muestran que la segunda y la tercera carta son corazones. ¿Cuál es la probabilidad condicional de que la primera sea un corazón?\nSolución: como resultados para las primeras tres cartas seleccionadas tenemos \\((x_1,x_2,x_3)\\). Nos interesan solamente los resultados \\((x_1, corazon_1, corazon_2)\\). Existen \\(13*12*11 + 39*13*12 = 7800\\) resultados posibles (primero contamos los que tienen un corazón al principio, y luego los que no tienen un corazón al principio, de modo que la probabilidad que buscamos es\n\\[\\frac{13(12)(11)}{13(12)(11) + 39(13)(12)} = \\frac{11}{11 + 39} = 0.22\\]\nInterpreta la simplificación de arriba para describir una manera más simple de calcular esta probabilidad condicional."
  },
  {
    "objectID": "prob-condicional.html#simulación-y-probabilidad-condicional",
    "href": "prob-condicional.html#simulación-y-probabilidad-condicional",
    "title": "4  Probabilidad condicional e independencia",
    "section": "4.2 Simulación y probabilidad condicional",
    "text": "4.2 Simulación y probabilidad condicional\nUna manera de aproximar probabilidades condicionales es simulando el experimento que nos interesa, y calculando frecuencias relativas solamente sobre la información que sabemos que ocurrió: es decir, filtramos las simulaciones escogiendo sólo las que son consistentes con la información dada.\n\nEjemplo: simulación tres cartas\n\n\nCódigo\nbaraja <- tibble(numero = 1:13) %>% \n   crossing(tibble(figura = c(\"C\", \"D\", \"T\", \"P\"))) %>% \n   mutate(carta = paste(numero, figura))\nnrow(baraja)\n\n\n[1] 52\n\n\nCódigo\nbaraja\n\n\n# A tibble: 52 × 3\n   numero figura carta\n    <int> <chr>  <chr>\n 1      1 C      1 C  \n 2      1 D      1 D  \n 3      1 P      1 P  \n 4      1 T      1 T  \n 5      2 C      2 C  \n 6      2 D      2 D  \n 7      2 P      2 P  \n 8      2 T      2 T  \n 9      3 C      3 C  \n10      3 D      3 D  \n# … with 42 more rows\n\n\n\n\nCódigo\ncartas <- baraja$carta\nexp_3_cartas <- function(cartas){\n   sample(cartas, 3) \n}\nset.seed(132185)\nexp_3_cartas(cartas)\n\n\n[1] \"7 C\"  \"8 P\"  \"13 T\"\n\n\nSimulamos el experimento\n\n\nCódigo\nsims <- map(1:20000, ~ exp_3_cartas(cartas))\nsims[1:5]\n\n\n[[1]]\n[1] \"4 C\"  \"8 T\"  \"12 D\"\n\n[[2]]\n[1] \"11 D\" \"6 P\"  \"7 C\" \n\n[[3]]\n[1] \"12 C\" \"1 D\"  \"5 C\" \n\n[[4]]\n[1] \"12 D\" \"9 D\"  \"13 T\"\n\n[[5]]\n[1] \"7 T\"  \"13 D\" \"13 T\"\n\n\nSin más información, la probabilidad de corazón en la primera extracción es:\n\n\nCódigo\nsims %>% \n   map_lgl(~ str_detect(.x[1], \"C\")) %>% \n   mean()\n\n\n[1] 0.2474\n\n\nQue debe estar alrededor de 1/4. Ahora condicionamos a que las cartas 2 y 3 son corazones:\n\n\nCódigo\nsims_F <- sims %>%\n   keep(~ str_detect(.x[2], \"C\") & str_detect(.x[3], \"C\"))\nlength(sims_F)\n\n\n[1] 1203\n\n\nCódigo\nsims_F[1:5]\n\n\n[[1]]\n[1] \"9 T\"  \"3 C\"  \"12 C\"\n\n[[2]]\n[1] \"5 D\"  \"2 C\"  \"13 C\"\n\n[[3]]\n[1] \"5 C\"  \"10 C\" \"1 C\" \n\n[[4]]\n[1] \"4 P\" \"6 C\" \"1 C\"\n\n[[5]]\n[1] \"8 C\"  \"13 C\" \"11 C\"\n\n\nY sobre estas simulaciones hacemos el mismo cálculo de arriba:\n\n\nCódigo\nsims_F  %>% \n   map_lgl(~ str_detect(.x[1], \"C\")) %>% \n   mean()\n\n\n[1] 0.2236076\n\n\nEsto nos da una aproximación de \\(P(E|F)\\). Nótese que si \\(F\\) es un evento con probabilidad baja, entonces será necesario correr más veces el experimento, pues el número de veces que ocurre \\(F\\) es relativamente bajo.\nPodemos definir también la probabilidad condicional en general, para cualquier probabilidad \\(P\\) no necesariamente resultante de un modelo equiprobable:\n\n\n\nLa **probabilidad condicional* del evento \\(E\\) dado que ocurrió el evento \\(F\\) se define como\n\\[P(E|F) = \\frac{P(E y F)}{P(F)}\\]"
  },
  {
    "objectID": "prob-condicional.html#regla-de-la-multiplicación",
    "href": "prob-condicional.html#regla-de-la-multiplicación",
    "title": "4  Probabilidad condicional e independencia",
    "section": "4.3 Regla de la multiplicación",
    "text": "4.3 Regla de la multiplicación\nA veces nos interesa calcular la probabilidad de que dos eventos ocurran, y conocemos \\(P(F)\\) y \\(P(E|F)\\). En ese caso podemos usar la definición de probabilidad condicional para escribir al regla del producto:\n\\[P(EF) = P(F)P(E|F)\\]\nPor ejemplo, si queremos calcular la probablidad de extraer dos corazones de una baraja usual, tenemos que \\(P(C_1) = 13/52 = 1/4\\). \\(P(C_2|C_1)\\) es fácil de calcular, pues si la primera carta que sacamos es un corazón, entonces para la segunda extracción hay 51 cartas, de las cuales 12 son corazones, de forma que \\(P(C_2|C_1) = 12/51\\). Usando la regla del producto, quedamos con\n\\[P(C_1C_2) = P(C_1)P(C_2|C_1) = \\frac{13}{52}\\frac{12}{51} \\approx 0.0588\\]\nPodemos generalizar esto a\n\n\n\nRegla del producto\n\\[P(E_1E_2E_3\\cdots E_n) = P(E_1)P(E_2|E_1)P(E_3|E_1E_2)\\cdots P(E_n|E_1\\cdots E_{n-1}\\]\n\n\n\nEjercicio\nSe divide al azar una baraja de 52 de cartas en 4 pilas iguales. Calcula la probabilidad de cada pila tenga exactamente un as.\nPodemos hacer el evento \\(E_1\\) que el as de corazones y el de diamantes están en diferentes pilas, \\(E_2\\) el evento de que el as de corazones, el de diamantes, y el de tréboles están en diferentes pilas, y finalmente \\(E_3\\) el evento de que todos los ases están en diferentes pilas. Nótese que buscamos la probabilidad \\(P(E_3)\\), pero será más fácil si escribimos:\n\\[P(E_3) = P(E_3E_2E_1) = P(E_1)P(E_2|E_1)P(E_3|E_1E_2)\\]\nPrimero, el as de corazones está en alguna de las pilas. La probabilidad de el as de diamantes no esté en esa pila es \\(P(E_1) = 1 - 12/51 = 39/51\\) (¿por qué?), pues la pila que tiene el as de corazones tiene otras 12 cartas de las 51 disponibles. La probabilidad de que el as de diamantes sea una de esas 12 cartas es entonces 12/51.\nSi se cumple \\(E_1\\), entonces el as de corazones y de diamantes están en pilas distintas. Entonces la probabilidad de que el as de tréboles caiga en una de esas dos pilas es \\(24/50\\), así que\n\\[P(E_2|E_1) = 1 -24/50 = 25/50\\]\nFinalmente, si el as de corazones, diamantes y tréboles están en distintas pilas, entonces la probabilidad de que el de espadas caiga en la una de esas pilas es \\(36/49\\), de modo que\n\\[P(E_3|E_2E_1) = 1 - 36/49 = 13/49\\].\nUsando la reglal producto,\n\\[P(E_1E_2E_3) = \\frac{39(26)(13)}{51(50)(49)} \\approx 0.105\\]"
  },
  {
    "objectID": "prob-condicional.html#nota-falacias-probabilísticas",
    "href": "prob-condicional.html#nota-falacias-probabilísticas",
    "title": "4  Probabilidad condicional e independencia",
    "section": "4.4 Nota: falacias probabilísticas",
    "text": "4.4 Nota: falacias probabilísticas\nUna de las razones por las que es importante usar la teoría de probabilidad para manipular probabilidades es que las personas, naturalmente, tienden a hacer “cálculos mentales probabilísticos” incorrectos, lo cual a fin de cuentas lleva a decisiones mal informadas. Existe amplia evidencia de esto, ver por ejemplo el trabajo de: Kahneman y Tversky\n“Before their work, economists had gotten far in their analyses of decision making under uncertainty by assuming that people correctly estimate probabilities of various outcomes or, at least, do not estimate these probabilities in a biased way […]. But Kahneman and Tversky found that this is not true: the vast majority of people misestimate probabilities in predictable ways.”\nAhora podemos descutir una de ellas, la falacia de conjunción. Consideremos la siguiente pregunta:\n\nLinda is 31 years old, single, outspoken, and very bright. She majored in philosophy. As a student, she was deeply concerned with issues of discrimination and social justice, and also participated in anti-nuclear demonstrations.\n\n¿Qué es más probable?\n\nLinda is a bank teller.\nLinda is a bank teller and is active in the feminist movement.\n\n¿Qué crees que tiende a escoger la mayoria de las personas como la más probable? ¿Qué regla de probabilidad puedes usar para demostrar que esto es una falacia?"
  },
  {
    "objectID": "prob-condicional.html#regla-de-probablilidad-total",
    "href": "prob-condicional.html#regla-de-probablilidad-total",
    "title": "4  Probabilidad condicional e independencia",
    "section": "4.5 Regla de probablilidad total",
    "text": "4.5 Regla de probablilidad total\nUna regla que usaremos varias veces es la regla de probabilidad total, que establece que\n\\[P(E) = P(E|F)P(F) + P(E|F^c)P(F^c)\\]\ndonde el evento \\(F^c\\) significa que \\(F\\) no ocurrió.\nEsta regla es útil en muchos casos para calcular probabilidades de un evento dependiendo de la ocurrencia o no de otro.\n\nEjemplo\nSacamos dos cartas de una bajara de 52 cartas. Vimos un ejemplo donde queríamos calcular la probabilidad de \\(N_2=\\) la segunda carta que sacamos es negra. Argumentamos usando espacio equiprobables que \\(P(N_2) = 0.5\\).\nSi \\(N_1 =\\) la primera carta es negra, entonces la ley de probabilidad total explica por qué pasa esto tomando en cuenta el resultado de la primera extracción:\n\nTenemos que \\(P(N_2|N_1) = 25/51\\) y \\(P(N_1) = 1/2\\)\nAdemás, \\(P(N_2|N_1^c) = 26/51\\) y \\(P(N_1^c) = 1/2,\\)\n\nde forma que\n\\[P(N_2) = (25/51)(1/2) + (26/51)(1/2) = \\frac{(25 + 26)}{51(2)} = /2\\]\nLa ley de probabilidades totales consiste de las reglas de ponderación usuales que conocemos.\n\n\nEjemplo\nEn un país hay 20% de adultos de 20 años o menos, y 80% de adultos de 21 años o más. Entre los adultos de 20 años o menos, el 90% solo usa plataformas digitales para ver televisión. Entre los adultos de 21 años o más, el 15% solo usa plataformas digitales para ver televisión. Si tomamos un adulto al azar de esta población, ¿cuál es la probabilidad de que solo use digital para ver TV?\nLa respuesta es\n\\[ 0.90(0.20) + 0.15(0.80) = 0.3\\]"
  },
  {
    "objectID": "prob-condicional.html#ejercicio-dados-y-monedas",
    "href": "prob-condicional.html#ejercicio-dados-y-monedas",
    "title": "4  Probabilidad condicional e independencia",
    "section": "4.6 Ejercicio: dados y monedas",
    "text": "4.6 Ejercicio: dados y monedas\nSupongamos que tiramos un dado. Tiramos tantos volados como el número que salió en la tirada de dado, y registramos el número de soles. ¿Cuál es la probabilidad de que obtengamos cero soles?\nSea \\(X=\\) número que obtuvimos en la tirada de dado, y sea \\(Y=\\) número de soles obtenidos.\nCalcular directamente \\(P(Y=0)\\) puede hacerse de manera simple con la ley de probabilidad total, pues\n\n\\(P(Y=0|X=1) = 1/2\\), prob de ningún sol en 1 volado\n\\(P(Y=0|X = 2) = 1/4\\) prob de ningún sol en dos volados (suponiendo independencia de los volados)\n\\(P(Y=0|X=3) = 1/8\\), prob de ningún sol en tres volados.\n\ny así sucesivamente. Como \\(P(X=i)=1/6\\) para cualquier número del uno al seis, la probabilidad \\(P(Y=0)\\), usando probabilidad total, es\n\\[(1/6)(1/2) + (1/6)(1/2)^2 +(1/6)(1/2)^3 +(1/6)(1/2)^4 +(1/6)(1/2)^5 +(1/6)(1/2)^6\\]\nque es igual a\n\n\nCódigo\nprobs_x <- rep(1/6, 6)\nprobs_y_x = 0.5^(1:6)\nsum(probs_y_x * probs_x)\n\n\n[1] 0.1640625\n\n\nCheca usando simulación."
  },
  {
    "objectID": "prob-condicional.html#ejercicio-dados-y-monedas-simulación",
    "href": "prob-condicional.html#ejercicio-dados-y-monedas-simulación",
    "title": "4  Probabilidad condicional e independencia",
    "section": "4.7 Ejercicio: dados y monedas (simulación)",
    "text": "4.7 Ejercicio: dados y monedas (simulación)\nEste es un experimento más interesante para simular:\n\n\nCódigo\nsimular_soles <- function(){\n   dado <- sample(1:6, 1)\n   soles <- sample(c(\"sol\", \"águila\"), dado, replace = TRUE)\n   num_soles = sum(as.numeric(soles == \"sol\"))\n   num_soles\n}\nset.seed(82332)\nsimular_soles()\n\n\n[1] 3\n\n\nSi hacemos 10 mil simulaciones:\n\n\nCódigo\nsims <- map_dbl(1:10000, ~ simular_soles())\nqplot(sims)\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nLa frecuencia relativa de cero soles es:\n\n\nCódigo\nsum(sims==0) / length(sims)\n\n\n[1] 0.1655\n\n\nCalcula también la probabilidad de obtener 2 soles o más en este experimento (puedes usar la simulación)."
  },
  {
    "objectID": "prob-condicional.html#regla-de-bayes",
    "href": "prob-condicional.html#regla-de-bayes",
    "title": "4  Probabilidad condicional e independencia",
    "section": "4.8 Regla de Bayes",
    "text": "4.8 Regla de Bayes\nLa regla de Bayes es una fórmula que se utiliza para invertir probabilidades condicionales:\n\\[P(E|F) = \\frac{P(F|E)P(E)}{P(F)},\\]\nque es una consecuencia fácil de la definición de probabilidad condicional. Es útil conocerla porque facilita resolver varios problemas de probabilidad que en un principio parecen difíciles.\n\nEjemplo\nSupongamos que tenemos una baraja de 8 cartas, 4 negras y 4 blancas. Extraemos sucesivamente dos cartas a azar. Sea \\(N_1=\\) la primera carta es negra y \\(B_2=\\) la segunda carta es blanca. ¿Cuál es la probabilidad condicional de que la primera carta haya sido negra si nos dicen que la segunda fue blanca?\nAunque ya resolvimos problemas como este, parece confuso en un principio. Sin embargo, podemos calcular:\n\\[P(N_1|B_2) = \\frac{P(B_2|N_1)P(N_1)}{P(B_2)}\\]\nSabemos que \\(P(B_2|N_1) = 4/7\\), y que \\(P(N_1)=1/2\\) y \\(P(B_2) = 1/2\\), de modo que\n\\[P(N_1|B_2) = 4/7 > 1/2\\]\nes decir, si sabemos que la segunda carta fue blanca, eso hace más probable que la primera carta haya sido negra.\n\n\nEjemplo (parte 1)\nSupongamos que una aseguradora cree que hay dos tipos de personas: unos con más riesgo de tener accidentes y otros con menos riesgo. Los datos muestran que una persona con riesgo alto tendrá un accidente en algún momento del año con probabilidad 0.04, y esta probabilidad baja a 0.01 para una persona de riesgo bajo. Si 10% de la población tiene riesgo alto, ¿cuál es la probabilidad de que un asegurado nuevo tenga un accidente un año después de comprar su póliza? (Nota: no sabemos si la persona nueva es de riesgo alto o bajo).\nPuedes resolver son simulación, o usar la ley de probabilidad total. Si \\(A\\) es el evento de tener un accidente, \\(R_A\\) es el evento de que la persona es de riesgo alto y \\(R_B\\) es el evento que la persona es de riesgo bajo, entonces\n\\[P(A) = P(A|R_A)P(R_A) + P(A|R_B)P(R_B)\\]\npues \\(R_A\\) y \\(R_B\\) cubren todas las posibilidades. Entonces\n\\[P(A) = 0.04(0.10) + (0.01)(0.90) = 0.004 + 0.009 = 0.013\\]\nEs decir, su probabilidad es de 1.3% de tener una accidente en el primer año.\n\n\nEjemplo (parte 2)\nAhora vemos que un cliente tuvo un accidente en su primer año. ¿Cuál es la probabilidad de que sea un cliente de riesgo alto?\nLa pregunta es de probabilidad condicional, porque ya tenemos información. Queremos calcular\n\\[P(R_A| A)\\]\nSi usamos la regla de Bayes obtenemos\n\\[P(R_A|A)= \\frac{P(A|R_A)P(R_A)}{P(A)}\\]\nSustituimos los datos que tenemos\n\\[P(R_A|A)= \\frac{0.04(0.10)}{P(A)}\\]\ny \\(P(A)\\) que calculamos en el ejercicio anterior:\n\\[P(R_A|A)= \\frac{0.04(0.10)}{0.013} \\approx 0.3077\\]\nDe manera que al principio la probabilidad no condicionada de ser de alto riesgo era de 10%, y cuando tiene un accidente esta probabilidad se triplica.\n\n\nEjemplo\nSupongamos que en un concurso de TV tenemos tres puertas y debemos escoger una. Atrás de una de ellas hay un premio, y no hay nada detrás de las otras dos. Escogemos una de las puertas.\nAhora el conductor (que sabe dónde está el premio), abre una puerta vacía, y nos pregunta si queremos cambiar o no de puerta. ¿Cuál es la mejor estrategia, cambiar o quedarnos con la que escogimos al principio?\nVeamos la estrategia de quedarnos con la puerta que escogimos. Sin perdida de generalidad, suponemos que escogemos la puerta 1.\nAhora observamos que el conductor abre la puerta 2.\nSea \\(E_1=\\) el premio está en la puerta 1, y \\(A_2=\\) el conductor abre la puerta 2, donde no hay premio. Por la regla de bayes:\n\\[P(E_1 | A_2) = \\frac{P(A_2 | E_1) P(E_1)}{P(A_2)}\\]\nSabemos que \\(P(E_1)= 1/3\\), y que \\(P(A_2|E_1)=1/2\\) (pues el conductor pudo abrir la puerta 2 o 3). Adicionalmente\n\\[P(A_2) = P(A_2|E_1)P(E_1) + P(A_2|E_1^c)P(E_1^c) = (1/2)(1/3) + (1/2) (2/3) = 1/2\\]\npues \\(P(A_2|E_1^c) = 1/2\\), es decir, si el premio no está en la puerta 1, la probabilidad de que abrir la puerta 2 es la probabilidad de que el premio esté en la puerta 2 dado que no está en la puerta 1\nSustituyendo,\n\\[P(E_1 | A_2) = \\frac{(1/2)(1/3)}{1/2} = 1/3\\]\nAsi que si cambiamos, la probabilidad de ganar es de 2/3.\nSimula para verificar tus resultados."
  },
  {
    "objectID": "prob-condicional.html#independencia",
    "href": "prob-condicional.html#independencia",
    "title": "4  Probabilidad condicional e independencia",
    "section": "4.9 Independencia",
    "text": "4.9 Independencia\nCuando tenemos dos eventos, y tenemos que \\(P(E|F) > P(E)\\) o \\(P(F|E) > P(F)\\) (checa que una implica la otra), decimos que los eventos tienen dependencia positiva: cuando sabemos que uno ocurre, la probabiidad del otro aumenta.\nEn algunos casos \\(P(E|F) = P(E)\\) y \\(P(F|E) = P(F)\\), lo cual sucede cuando \\(P(EF)=P(F)P(E)\\). En este caso decimos que los eventos \\(E\\) y \\(F\\) son independientes. Nótese que esto no quiere decir que no haya ninguna conexión entre \\(E\\) y \\(F\\) (puede ser que la ocurrencia de \\(F\\) cambie las maneras en que puede ocurrir \\(E\\)), sólo que la probabilidad de uno no cambia al condicionar al otro.\n\nEjemplos\n\nMuestra que si sabemos que sacar un corazón de una baraja de 52 cartas es independiente de sacar un as\nMuestra que en nuestro modelo equiprobable de dos volados, el resultado de un volado es independiente del resultado del otro.\nEl evento “la suma de la tirada de dos dados” es independiente del resultado del primer dado."
  },
  {
    "objectID": "prob-condicional.html#independencia-de-más-de-dos-eventos",
    "href": "prob-condicional.html#independencia-de-más-de-dos-eventos",
    "title": "4  Probabilidad condicional e independencia",
    "section": "4.10 Independencia de más de dos eventos",
    "text": "4.10 Independencia de más de dos eventos\nNótese que cuando los eventos \\(E\\) y \\(F\\) son indpendientes, por definición\n\\[P(E \\,y\\, F) = P(E) P(F)\\]\nDecimos que los eventos \\(E\\), \\(F\\) y \\(G\\) son independientes cuando\n\n\\(P(E \\,y \\,F \\, y \\, G) = P(E)P(F)P(G)\\)\n\\(P(E \\,y \\,F ) = P(E)P(F)\\)\n\\(P(E \\,y \\, G) = P(E)P(G)\\)\n\\(P(F \\, y \\, G) = P(F)P(G)\\)\n\ny así sucesivamente para un número mayor de eventos: si los eventos son independientes, la probabilidad de que ocurran cualquier subconjunto de ellos es es el producto de la probabilidades de que cada uno de ellos ocurra.\nEn general, si \\(E_1, E_2, \\ldots, E_n\\) son eventos independientes, entonces\n\\[P(E_1\\, y \\, E_2 \\, y \\cdots \\,y E_n) = P(E_1)P(E_2)\\cdots P(E_n)\\]\n\nEjercicio\nHacemos un número indefinido de pruebas independientes, y cada una de ellas puede resultar en éxito con probabilidad \\(p\\) y fracaso con probabilidad \\(1-p\\). Calcula la probabilidad de que 1) al menos un éxito suceda en la primeras 20 pruebas. 2) todas las pruebas sean éxito y 3) exactamente 5 de las 2o pruebas sean éxito.\n\n\nEjemplo: número de seises\nConstruye un modelo para el número de seises en dos tiradas de dados. Escribimos \\(X\\)= número de seises que obtenemos en dos tiradas de dado.\nLos resultados posibles son 0, 1 y 2 seises. Para calcular la probablidad de tirar dos seises hacemos:\n\\[P(X=2) = P(S_2\\, y \\, S_1) = P(S_2 | S_1) P(S_1).\\]\nahora, si suponemos que el primer tiro no afecta de ninguna manera el resultado del segundo tiro, entonces \\(P(S_2|S_1) = P(S_2)\\), y la fórmula es\n\\[P(X=2) = P(S_2\\, y \\, S_1) = P(S_2) P(S_1) = (1/6)(1/6) = 1/36.\\]\nUsando el mismo argumento podemos calcular de la probabilidad de obtener ningún seis es\n\\[P(X=0) = P(S_2^c \\, y \\, S_1^c ) = P(S_2^c)P(S_1^c) = (5/6)(5/6) = 25/36\\]\nLa probabilidad restante se puede calcularse directamente, o notar que como 0, 1 y 2 son los únicos posibles resultados, entonces\n\\[P(X=1) = 1- P(X=0) - P(X=2) = 1 - 25/36 - 1/36 = 10/36\\]\nCheca tus resultados usando simulación.\nObservación: en muchos casos, la independencia se construye como un supuesto para construir modelos más complejos, cuando este supuesto es adecuado. Un ejemplo es cuando tomamos muestras de una población: si tomamos cada muestra independientemente de las otras, analizar los resultados es mucho más fácil que cuando hay esquemas complejos de dependencias entre los datos que xtraemos."
  },
  {
    "objectID": "prob-condicional.html#intro-a-estimación-por-máxima-verosimilitud",
    "href": "prob-condicional.html#intro-a-estimación-por-máxima-verosimilitud",
    "title": "4  Probabilidad condicional e independencia",
    "section": "4.11 Intro a estimación por máxima verosimilitud",
    "text": "4.11 Intro a estimación por máxima verosimilitud\nUno de los procedimientos más estándar para estimar cantidades desconocidas es el método de máxima verosimilitud. Los estimadores de máxima verosimilitud tienen propiedades convenientes, y dan en general resultados razonables siempre y cuando los supuestos sean razonables.\nMáxima verosimilitud es un proceso intuitivo, y consiste en aprender o estimar valores de parámetros desconocidos suponiendo para los datos su explicación más probable. Para esto, usando supuestos y modelos requeriremos calcular la probabilidad de un conjunto de observaciones.\n\nEjemplo 1\nSupongamos que una máquina produce dos tipos de bolsas de 25 galletas: la mitad de las veces produce una bolsa con 5 galletas de avena y 20 de chispas de chocolate, y la otra mitad produce galletas con 23 galletas de avena y 2 de chispas de chocolate.\nTomamos una bolsa, y no sabemos qué tipo de bolsa es (parámetro desconocido). Extraemos al azar una de las galletas, y es de chispas de chocolate (observación).\nPor máxima verosimilitud, inferimos que la bolsa que estamos considerando tiene 5 galletas de avena. Esto es porque es más probable observar una galleta de chispas en las bolsas que contienen 5 galletas de avena que en las bolsas que contienen 23 galletas de avena. Podemos cuantificar la probabilidad que “acertemos” en nuestra inferencia.\n\nCómo se aprecia en el ejemplo anterior, el esquema general es:\n\nExiste un proceso del que podemos obtener observaciones de algún sistema o población real.\nTenemos un modelo probabilístico que dice cómo se producen esas observaciones a partir del sistema o población real.\nUsualmente este modelo tiene algunas cantidades que no conocemos, que rigen el proceso y cómo se relaciona el proceso con las observaciones.\n\nNuestro propósito es:\n\nExtraemos observaciones del proceso:\n\n\\[x_1, x_2, \\ldots, x_n\\]\n\nQueremos aprender de los parámetros desconocidos del proceso para calcular cantidades de interés acerca del sistema o población real\n\nEn principio, los modelos que consideramos pueden ser complicados y tener varias partes o parámetros. Veamos primero un ejemplo clásico con un solo parámetro, y cómo lo resolveríamos usando máxima verosimilitud.\nNota: Cuando decimos muestra en general nos referimos a observaciones independientes obtenidas del mismo proceso (ver la sección anterior para ver qué significa que sea independientes). Este esquema es un supuesto que simplifica mucho los cálculos, como discutimos antes. Muchas veces este supuesto sale del diseño de la muestra o del estudio, pero en todo caso es importante considerar si es razonable o no para nuestro problema particular.\n\n\nEjemplo\nSupongamos que queremos saber qué proporción de registros de una base de datos tiene algún error menor de captura. No podemos revisar todos los registros, así que tomamos una muestra de 8 registros, escogiendo uno por uno al azar de manera independiente. Revisamos los 8 registros, y obtenemos los siguientes datos:\n\\[x_1 = 0, x_2 = 1, x_3 = 0, x_4 = 0, x_5 =1, x_6 =0, x_7 =0, x_8 =0\\]\ndonde 1 indica un error menor. Encontramos dos errores menores. ¿Cómo estimamos el número de registros con errores leves en la base de datos?\nYa sabemos una respuesta razonable para nuestro estimador puntual, que sería \\(\\hat{p}=2/8=0.25\\). Veamos cómo se obtendría por máxima verosimilitud.\nSegún el proceso con el que se construyó la muestra, debemos dar una probabilidad de observar los 2 errores en 8 registros. Supongamos que en realidad existe una proporción \\(p\\) de que un registro tenga un error. Entonces calculamos\nProbabilidad de observar la muestra:\n\\[P(X_1 = 0, X_2 = 1, X_3 = 0, X_4 = 0, X_5 =1, X_6 =0, X_7 =0, X_8 =0)\\]\nes igual a\n\\[P(X_1 = 0)P(X_2 = 1)P(X_3 = 0)P( X_4 = 0)P(X_5 =1)P(X_6 =0)P(X_7 =0)P(X_8 =0)\\]\npues la probabilidad de que cada observación sea 0 o 1 no depende de las observaciones restantes (la muestra se extrajo de manera independiente).\nEsta ultima cantidad tiene un parámetro que no conocemos: la proporcion \\(p\\) de registros con errores. Así que lo denotamos como una cantidad desconocida \\(p\\). Nótese entonces que \\(P(X_2=1) = p\\), \\(P(X_3=0) = 1-p\\) y así sucesivamente, así que la cantidad de arriba es igual a\n\\[p(1-p)p(1-p)(1-p)p(1-p)(1-p)(1-p) \\]\nque se simplifica a\n\\[ L(p) = p^2(1-p)^6\\]\nAhora la idea es encontrar la p que maximiza la probabilidad de lo que observamos. En este caso se puede hacer con cálculo, pero vamos a ver una gráfica de esta función y cómo resolverla de manera numérica.\n\n\nCódigo\nverosimilitud <- function(p){\n  p^2 * (1-p)^6\n}\ndat_verosim <- tibble(x = seq(0,1, 0.001)) %>% mutate(prob = map_dbl(x, verosimilitud))\nggplot(dat_verosim, aes(x = x, y = prob)) + geom_line() +\n  geom_vline(xintercept = 0.25, color = \"red\") +\n  xlab(\"p\")\n\n\n\n\n\nNótese que esta gráfica:\n\nDepende de los datos, que pensamos fijos.\nCuando cambiamos la \\(p\\), la probabilidad de observar la muestra cambia. Nos interesa ver las regiones donde la probabilidad es relativamente alta.\nEl máximo está en 0.25.\nAsí que el estimador de máxima verosimilitud es \\(\\hat{p} = 0.25\\)\n\n\nObsérvese que para hacer esto usamos:\n\nUn modelo teórico de cómo es la población con parámetros y\nInformación de como se extrajo la muestra,\n\ny resolvimos el problema de estimación convirtiéndolo en uno de optimización.\nProbamos esta idea con un proceso más complejo:\n\n\n4.11.1 Ejemplo 2\nSupongamos que una máquina puede estar funcionando correctamente o no en cada corrida. Cada corrida se producen 500 productos, y se muestrean 10 para detectar defectos. Cuando la máquina funciona correctamente, la tasa de defectos es de 3%. Cuando la máquina no está funcionando correctamente la tasa de defectos es de 10%\nSupongamos que escogemos al azar 11 corridas, y obervamos los siguientes datos de número de defectuosos:\n\\[1, 0, 0, 3 ,0, 0, 0, 2, 1, 0, 0\\]\nLa pregunta es: ¿qué porcentaje del tiempo la máquina está funcionando correctamente?\nPrimero pensemos en una corrida. La probabilidad de observar una sucesión particular de \\(r\\) defectos es\n\\[0.03^r(0.97)^{(10-r)}\\]\ncuando la máquina está funcionando correctamente.\nSi la máquina está fallando, la misma probabilidad es\n\\[0.2^r(0.8)^{(10-r)}\\]\nAhora supongamos que la máquina trabaja correctamente en una proporción \\(p\\) de las corridas. Entonces la probabilidad de observar \\(r\\) fallas se calcula promediando (probabilidad total) sobre las probabilidades de que la máquina esté funcionando bien o no:\n\\[0.03^r(0.97)^{(10-r)}p + 0.2^r(0.8)^{(10-r)}(1-p)\\]\nY esta es nuestra función de verosimilitud para una observación.\nSuponemos que las \\(r_1,r_2, \\ldots, r_{11}\\) observaciones son independientes (por ejemplo, después de cada corrida la máquina se prepara de una manera estándar, y es como si el proceso comenzara otra vez). Entonces tenemos que multiplicar estas probabilidades para cada observación \\(r_1\\):\n\n\nCódigo\ncalc_verosim <- function(r){\n  q_func <- 0.03^r*(0.97)^(10-r)\n  q_falla <- 0.2^r*(0.8)^(10-r)\n  function(p){\n    #nota: esta no es la mejor manera de calcularlo, hay \n    # que usar logaritmos.\n    prod(p*q_func + (1-p)*q_falla)\n  }\n}\nverosim <- calc_verosim(c(1, 0, 0, 3, 0, 0, 0, 2, 1, 0, 0))\nverosim(0.1)\n\n\n[1] 2.692087e-14\n\n\n\n\nCódigo\ndat_verosim <- tibble(x = seq(0,1, 0.001)) %>% mutate(prob = map_dbl(x, verosim))\nggplot(dat_verosim, aes(x = x, y = prob)) + geom_line() +\n  geom_vline(xintercept = 0.8, color = \"red\") +\n  xlab(\"prop funcionado\")\n\n\n\n\n\nY nuestra estimación puntual sería de alrededor de 80%.\n\n\nAspectos numéricos\nCuando calculamos la verosimilitud arriba, nótese que estamos multiplicando números que pueden ser muy chicos (por ejemplo \\(p^6\\), etc). Esto puede producir desbordes numéricos fácilmente. Por ejemplo para un tamaño de muestra de 1000, podríamos tener que calcular\n\n\nCódigo\np <- 0.1\nproba <- (p ^ 800)*(1-p)^200\nproba\n\n\n[1] 0\n\n\nEn estos casos, es mejor hacer los cálculos en la escala logarítmica. El logaritmo convierte productos en sumas, y baja exponentes multiplicando. Si calculamos en escala logaritmica la cantidad de arriba, no tenemos problema:\n\n\nCódigo\nlog_proba <- 800 * log(p) + 200 * log(1-p)\nlog_proba\n\n\n[1] -1863.14\n\n\nAhora notemos que\n\nMaximizar la verosimilitud es lo mismo que maximizar la log-verosimilitud, pues el logaritmo es una función creciente. Si \\(x_{max}\\) es el máximo de \\(f\\), tenemos que \\(f(x_{max})>f(x)\\) para cualquier \\(x\\), entonces tomando logaritmo, \\[log(f(x_{max}))>log(f(x))\\] para cualquier \\(x\\), pues el logaritmo respeta la desigualdad por ser creciente.\nUsualmente usamos la log verosimilitud para encontrar estimador de máxima verosimilitud\nHay razónes teóricas y de interpretación por las que también es conveniente hacer esto.\n\n\n\n\n\nRoss, Sheldon M. 1998. A First Course in Probability. Fifth. Upper Saddle River, N.J.: Prentice Hall."
  },
  {
    "objectID": "modelos-continuos.html",
    "href": "modelos-continuos.html",
    "title": "5  Modelos probabilísticos para variables continuas",
    "section": "",
    "text": "En la parte anterior consideramos un númeroo fijo de resultados numéricos de experimentos aleatorios, por ejemplo, cuando \\(X\\) el resultado de una tirada de dado. En este caso, un modelo de probabilidad para \\(X\\) asigna una probabilidad dada a cada posible resultado, por ejemplo\n\\[P(X=1) = 1/6\\]\ne igualmente \\(P(X=2)=\\cdots = P(X=6) = 1/6\\). En muchos casos, la cantidad \\(X\\) que nos interesa puede tomar valores numéricos arbitrarios, y en este esquema no está claro cómo asignaríamos probabilidades."
  },
  {
    "objectID": "modelos-continuos.html#modelo-equiprobable-o-uniforme",
    "href": "modelos-continuos.html#modelo-equiprobable-o-uniforme",
    "title": "5  Modelos probabilísticos para variables continuas",
    "section": "5.1 Modelo equiprobable o uniforme",
    "text": "5.1 Modelo equiprobable o uniforme\nLos modelos más simple para una medición continua \\(X\\) son los modelos uniforme.\nPara nuestra ruleta, por ejemplo, \\(X\\) puede tomar valores en el intervalo \\([0, 360)\\). Si la ruleta es justa, entonces la probabilidad de que la flecha caiga en cualquier sector \\([a,b]\\) debe ser igual. Una manera de lograr esto usar como probabilidad la proporción de la longitud de \\([a,b]\\) con respecto al total de \\([0, 360)\\):\n\\(P(X\\in [a,b]) = \\frac{b-a}{360}.\\)\n\nDiscute por qué esta asignación de probabilidades satisface las tres reglas básicas de probabilidad (axiomas) que presentamos anteriormente.\nEste es el equivalente continuos para espacios equiprobables con un número finito de resultados.\n\n::: {.cell type=‘comentario’}\n\nSupongamos que una variable aleatoria puede tomar valores en el intervalo \\([L,U]\\). La variable aleatoria es uniforme en \\([L,U]\\) cuando\n\\[P(X \\in [a,b]) = \\frac{b-a}{L-U}\\]\n</div>\\EndKnitrBlock{comentario}\n:::\n\n5.1.1 Ejemplo: ruleta sesgada\nAhora supongamos que nuestra ruleta no está del todo balanceada. Por ejemplo, podría ser estuviera colgada en una pared, y al girar la flecha es un poco más probable que la flecha apunte hacia el piso en lugar de hacia el cielo.\nEn este caso, si la dirección hacia arriba es 90 grados y hacia abajo es 270 grados, quisiéramos por ejemplo que\n\\[P(260 < X <280) < P(80 < X < 100)\\]\nY nótese que debe ser posible asignar probabilidades a cualquier sector de la ruleta con el nuevo modelo que propongamos. ¿Cómo podríamos modificar nuestra asignación de probabilidades?\nUna de las maneras más fáciles es pensando que nuestra probabilidad se obtiene integrando una funcion constante:\n\nSi \\([a,b]\\) es un sector de la ruleta con \\(a<b\\), podríamos poner\n\n\\[P(X\\in [a,b]) = \\int_a^b \\frac{1}{360} \\,dx = \\frac{b-a}{360}\\]\nDe forma que si \\(f(x)= 1/360\\) para valores \\(0 \\leq x < 360\\), nuestra probabilidad se escribe como la integral\n\\[P(X\\in [a,b]) = \\int_a^b f(x) \\,dx \\]\n\nEn este caso, probabilidad es área bajo la curva \\(f(x)=1/360\\) que se calcula integrando sobre el intervalo de interés\n\nPara generalizar la idea es la siguiente:\n\nUsamos la fórmula anterior, pero modificamos o perturbamos la función \\(f(x) = 1/360\\) para que \\(f\\) sea un poco más alta alrededor de 270 grados (abajo), y un poco más baja alrededor de 90 grados (arriba).\nLo único que necesitamos es que \\(f(x)\\) no puede tomar valores negativos (por que si no obtendríamos probabilidades negativas en algunos sectores), y la integral sobre la ruleta completa debe ser uno:\n\n\\[P(X\\in [0, 360]) = \\int_0^{360} f(x)\\,dx = 1\\]\nPodríamos utilizar por ejemplo:\n\n\nCódigo\nf_dens <- function(x){\n    x_rad <- 2 * pi * x / 360\n    (1/360) +  0.0002 * cos(x_rad - 3 * pi  / 2)\n}\ngraf_1_tbl <- tibble(angulo = seq(0, 360, 1), tipo = \"uniforme\",\n                   f = 1 / 360) \ngraf_2_tbl <- tibble(angulo = seq(0, 360, 1), tipo = \"colgada\") %>% \n    mutate(f = f_dens(angulo))\ngraf_tbl <- bind_rows(graf_1_tbl, graf_2_tbl)\nggplot(graf_tbl, aes(x = angulo, y = f, colour = tipo)) +\n    geom_line() +\n    ylim(c(0, 0.003)) + facet_wrap(~tipo, nrow = 1)\n\n\n\n\n\nEl cálculo se hace ahora con área bajo la curva. Para calcular la probabilidad\n\\[P(X\\in [50, 130]),\\]\nintegramos la función \\(f\\) correspondiente, que corresponde a calcular área bajo la curva:\n\n\nCódigo\nggplot(graf_tbl, aes(x = angulo, y = f, colour = tipo)) +\n    geom_line() +\n    ylim(c(0, 0.003)) + facet_wrap(~tipo, nrow = 1) +\n    geom_area(aes(x = ifelse(angulo > 50 & angulo < 130, angulo, 0)), \n              fill=\"salmon\", alpha = 0.5)\n\n\n\n\n\nY ahora vemos que para la versión perturbada, más de la probabilidad se concentra alrededor de 270 grados que alrededor de 90. Por las propiedades de la integral, todas las propiedades usuales de probabilidad se cumplen."
  },
  {
    "objectID": "modelos-continuos.html#funciones-de-densidad",
    "href": "modelos-continuos.html#funciones-de-densidad",
    "title": "5  Modelos probabilísticos para variables continuas",
    "section": "5.2 Funciones de densidad",
    "text": "5.2 Funciones de densidad\nCuando trabajamos con mediciones de tipo continuo, es más conveniente definir asignaciones de probabilidad utilizando funciones de densidad de probabilidad:\n\n\n\nUna función \\(f(x)\\) no negativa cuya integral es igual a 1 es una función de densidad de probabilidad. Las probabilidades asociadas se calculan integrando:\n\\[P(X\\in [a,b]) = \\int_a^b f(x)\\,dx\\]\nEn este caso decimos que \\(f\\) es la función de densidad de probabilidad asociada a la variable aleatoria \\(X\\). A este tipo de variables aleatorias les llamamos continuas."
  },
  {
    "objectID": "modelos-continuos.html#ejemplo-densidad-triangular",
    "href": "modelos-continuos.html#ejemplo-densidad-triangular",
    "title": "5  Modelos probabilísticos para variables continuas",
    "section": "5.3 Ejemplo: densidad triangular",
    "text": "5.3 Ejemplo: densidad triangular\nSupongamos que tenemos una variable aleatoria que tiene mediana 2, y puede tomar valores entre 0 y 4. Podríamos definir una densidad como sigue: Si \\(x\\) está entre 0 y 2, entonces\n\\[f(x) = \\frac{x}{4}\\]\ny si \\(x\\) está entre 2 y 4, entonces\n\\[f(x) = 1 - \\frac{x}{4}\\]\n\n\nCódigo\ndens_triangular <- function(x){\n    (x > 0) * (x < 4) * ifelse(x < 2, x/4, 1 - x/4)\n}\ntriangular_tbl <- tibble(x = seq(-1, 5, 0.001)) %>% \n    mutate(f = dens_triangular(x)) \nggplot(triangular_tbl, aes(x = x, y = f)) +\n    geom_line()\n\n\n\n\n\n\nEjemplo\nSupongamos que una variable \\(X\\) tiene mediana 2 y rango de 0 a 4, con densidad triangular. ¿Cuál es la probabilidad \\(P(X>1)\\)?\nSolución: Por reglas usuales de probabilidad, \\(P(X>1) = P(1<X<2) + P(X\\geq2)\\). Tenemos que \\(P(X\\geq 2) = 0.5\\). Ahora usamos la fórmula de la densidad triangular para obtener\n\\[P(1<X<2) = \\int_{1}^{2} f(x)\\,dx = \\int_1^2 \\frac{x}{4}\\,dx =\n\\left [\\frac{x^2}{8}\\right ]_1^2 = 1/2 - 1/8 = 3/8 = 0.375\\]\nde modo que\n\\[P(X<1) = 0.375 +0.500 = 0.875\\]\nEn general, podemos dar una fórmula para una densidad triangular en el intervalo \\([A,B]\\) con mediana en \\((A + B)/2\\). ¿Cómo sería la fórmula?"
  },
  {
    "objectID": "modelos-continuos.html#cuantiles-de-variables-aleatorias",
    "href": "modelos-continuos.html#cuantiles-de-variables-aleatorias",
    "title": "5  Modelos probabilísticos para variables continuas",
    "section": "5.4 Cuantiles de variables aleatorias",
    "text": "5.4 Cuantiles de variables aleatorias\nAntes vimos la definición de cuantiles para datos numéricos. Podemos definirlos también para variables aleatorias numéricas:\n::: {.cell type=‘comentario’}\n\nSea \\(p\\in (0,1)\\). El cuantil-\\(p\\) de la variable \\(X\\) con función de densidad \\(f(x)\\) es el valor \\(x(p)\\) tal que\n\\[\\int_{-\\infty}^{x(p)} f(x)\\,dx = p\\]\n</div>\\EndKnitrBlock{comentario}\n:::\nObservación: nótese que usamos como límite inferior \\(-\\infty\\) para indicar que integramos \\(f\\) sobre toda la densidad que esté a la izquierda de \\(x(p)\\).\n\nEjemplo: densidad triangular\nSupongamos que \\(X\\) tiene la densidad triangular mostrada arriba. Calcula el cuartil inferior y superior (es decir, los cuantiles 0.25 y 0.75). Para el cuartil superior, por ejemplo, buscamos al \\(x(0.75)\\) de la siguiente gráfica:\n\n\nCódigo\nsource(\"R/triangular.R\")\nggplot(triangular_tbl, aes(x = x, y = f)) +\n        geom_line() +\n    geom_area(aes(x = ifelse(x > 0 & x < qtri(0.75, 0, 4), x, 0)), \n              fill=\"salmon\", alpha = 0.5) +\n    ylim(c(0, 0.7)) +\n    annotate(\"text\", x = qtri(0.75, 0, 4), y = 0.03, label = \"x(0.75)\") +\n    annotate(\"point\", x = qtri(0.75, 0, 4), y = 0.0) \n\n\n\n\n\nComenzaremos por el cuartil inferior. Buscamos una \\(x(0.25)\\) tal que\n\\[\\int_0^{x(0.25)} f(x)\\,dx = 0.25\\]\nSabemos que \\(x(0.25)< 2\\), pues la integral hasta 2 es 0.5, así que\n\\[\\int_0^{x(0.25)} f(x)\\,dx = \\int_0^{x(0.25)} x/4 \\,dx = \\left [ x^2/8\\right]_0^{x(0.25)} = (x(0.25))^2/8\\]\nSi queremos que este valor sea igual a 0.25, entonces despejando obtenemos\n\\[x(0.25) = \\sqrt{0.25(8)} = \\sqrt{2}\\approx 1.4142\\]\nAhora podríamos calcular la otra integral, pero por simetría podemos concluir que\n\\[x(0.75) = 2 + (2 - 1.4142) \\approx 2.5858\\]\ny concluimos que los cuartiles inferiores y superiores son aproximadamente 1.41 y 2.59\n\n\nEjercicio: densidad uniforme\nCalcula la mediana, y los percentiles 0.10 y 0.90 de una variable uniforme en \\([0, 10]\\)."
  },
  {
    "objectID": "modelos-continuos.html#comparando-cuantiles-teóricos-y-empíricos",
    "href": "modelos-continuos.html#comparando-cuantiles-teóricos-y-empíricos",
    "title": "5  Modelos probabilísticos para variables continuas",
    "section": "5.5 Comparando cuantiles teóricos y empíricos",
    "text": "5.5 Comparando cuantiles teóricos y empíricos\nLos cuantiles que vimos en la parte de descriptivos para datos numéricos se llaman usualmente cuantiles empíricos. Estos cuantiles podemos compararlos con cuantiles teóricos para ver qué tan similares son, y si el modelo teórico describe adecuadamente los datos.\n\n5.5.1 Ejemplo: distribución uniforme\nSimularemos 500 datos uniformes en \\([0, 10]\\):\n\n\nCódigo\nx_sim_u <- runif(500, 0, 10)\n\n\nPodríamos calcular algunos cuantiles empíricos:\n\n\nCódigo\nquantile(x_sim_u, c(0.10, 0.50, 0.90))\n\n\n     10%      50%      90% \n1.113887 4.988600 9.014667 \n\n\nPor el ejercicio anterior sabemos cuáles son los cuantiles teóricos correspondientes a una uniforme en \\([0,10]\\). Podemos calcularlos también como sigue:\n\n\nCódigo\nqunif(c(0.10, 0.5, 0.90), 0, 10)\n\n\n[1] 1 5 9\n\n\nY vemos que son muy similares los cuantiles empíricos y teóricos. Una mejor manera de considerar esta similitud es graficando todos los cuantiles empíricos y comparándolos con los teóricos:\n\n\nCódigo\nggplot(tibble(x = x_sim_u), aes(sample = x)) +\n    geom_abline(colour = \"red\") +\n    geom_qq(distribution = stats::qunif, dparams = list(min = 0, max = 10)) +\n    xlab(\"Cuantiles Teóricos U(0,10)\") + ylab(\"Cuantiles de datos\")\n\n\n\n\n\nY vemos que la forma de las dos distribuciones es muy similar: los cuantiles empíricos son muy similares a los teóricos. Existen algunas fluctuaciones debidas al muestreo aleatorio.\n\n\n5.5.2 Ejemplo: distribución triangular\nRepetimos para la distribución triangular. Los cuantiles que calculamos arriba son:\n\n\nCódigo\nqtri(c(0.25, 0.75), a = 0, b = 4)\n\n\n[1] 1.414214 2.585786\n\n\n\n\nCódigo\nx_sim_tri <- rtri(500, 0, 4)\nggplot(tibble(x = x_sim_tri), aes(sample = x)) +\n    geom_abline(colour = \"red\") +\n    geom_qq(distribution = qtri, dparams = list(a = 0, b = 4)) +\n    xlab(\"Cuantiles Teóricos triangular(0,4)\") + ylab(\"Cuantiles de datos\")\n\n\n\n\n\nNótese que otra vez, los cuantiles teóricos se alinean bien con los teóricos."
  },
  {
    "objectID": "modelos-continuos.html#histogramas-y-densidades",
    "href": "modelos-continuos.html#histogramas-y-densidades",
    "title": "5  Modelos probabilísticos para variables continuas",
    "section": "5.6 Histogramas y densidades",
    "text": "5.6 Histogramas y densidades\nPara el análisis de datos usual, las gráficas cuantil-cuantil tienden a ser útiles para entender si unos datos se comportan según alguna densidad teórica. Sin embargo, muchas veces se usan histogramas, como en las siguientes gráficas:\n\n\nCódigo\nhist_1 <- ggplot(tibble(x = x_sim_u),\n                 aes(x = x)) +\n    geom_histogram(aes(y = ..density..), binwidth = 1, boundary = 0) +\n    geom_line(data = tibble(x = seq(0, 10, 0.01)) %>% \n                  mutate(f = dunif(x, 0, 10)),\n              aes(x = x, y = f), colour = \"red\")\nhist_2 <- ggplot(tibble(x = x_sim_tri),\n                 aes(x = x)) +\n    geom_histogram(aes(y = ..density..), binwidth = 0.25, boundary = 0) +\n    geom_line(data = tibble(x = seq(0, 4, 0.01)) %>% \n                  mutate(f = dtri(x, 0, 4)),\n              aes(x = x, y = f), colour = \"red\")\nhist_1 + hist_2\n\n\n\n\n\nNótese la escala vertical de estos histogramas, que no es simplemente el conteo de casos que caen en cada intervalo del histograma. Para poder comparar los conteos con las densidades correspondientes, es necesario observar lo siguiente:\nSi \\(I = [a,b]\\) es un intervalo del histograma, según la densidad (teórica), la probabilidad de que un dato \\(x\\) caiga en \\(I\\) es\n\\[P(x\\in I) = \\int_{a}^b f(x)\\,dx \\approx f(a) (b-a)\\]\nLa última aproximación se debe a que en un intervalo chico \\([a,b]\\), el área bajo la curva de \\(f(x)\\) es aproximadamente igual a la base (el ancho del intervalo) por la altura en un punto de la curva (\\(f(a)\\), aunque también podríamos usar \\(f(\\frac{a+b}{2})\\) por ejemplo).\nSi tenemos \\(n\\) observaciones, esperamos entonces que caigan \\(nP(X\\in I)\\) en el intervalo \\(I\\), de forma que si \\(n([a,b])\\) es el número de observaciones que caen en \\(I = [a,b]\\), esperamos\n\\[\\frac{n([a,b])}{n} \\approx f(a)(b-a),\\]\ny despejando obtenemos\n\\[f(a)\\approx \\frac{n([a, b])}{n(b-a)}.\\]\nEsto implica que para aproximar la densidad, es necesario dividir las frecuencias relativas entre el ancho de los intervalos correspondientes, y de ahí la escala vertical de las gráficas de arriba.\nObservación: las gráficas de cuantiles son generalmente más prácticas para evaluar el ajuste a un modelo teórico, aunque son menos comunes."
  },
  {
    "objectID": "modelos-continuos.html#más-descriptivos-media-y-desviación-estándar",
    "href": "modelos-continuos.html#más-descriptivos-media-y-desviación-estándar",
    "title": "5  Modelos probabilísticos para variables continuas",
    "section": "5.7 Más descriptivos: media y desviación estándar",
    "text": "5.7 Más descriptivos: media y desviación estándar\nPodemos utilizar cuantiles para describir modelos teóricos y también conjuntos de datos (por ejemplo, mediana para centralidad y diferencia entre cuantiles 0.9 y 0.10 para dispersión), y funcionan bien en general. Sin embargo, para modelos teóricos y conjuntos de datos particulares muchas veces es más conveniente usar medidas como la media y desviación estándar.\n\n5.7.1 Media teórica y empírica\nSabemos que la media de un conjunto de datos \\(x_1,x_2,\\ldots,x_n\\) está dada por\n\\[\\bar{x} = \\frac{x_1 + x_2 + \\cdots x_n}{n}.\\]\nAhora consideremos qué pasa con esta cantidad cuando las \\(x_i's\\) son observaciones independientes de una distribución con densidad teórica \\(f(x)\\). Utilizaremos simulaciones de la distribución triangular que vimos arriba\n\n\nCódigo\ndatos <- tibble(x = rtri(5000, 0, 4))\nggplot(datos, aes(x = x)) + stat_bin(breaks = seq(0, 4, 0.25))\n\n\n\n\n\nPodemos aproximar la media de estos datos promediando los valores iniciales de los intervalos de corte ponderado por el número de casos. Lo hacemos así:\n\n\nCódigo\nparticion <- seq(0, 4, 0.25)\niniciales <- head(particion, -1) # quitar último\nagrupados_cubeta <- datos %>% \n  mutate(inicial = cut(x, breaks = particion, labels = iniciales)) %>%  \n  mutate(inicial = as.numeric(as.character(inicial))) %>% \n  group_by(inicial) %>%\n  count() %>% \n  ungroup() \nagrupados_cubeta\n\n\n# A tibble: 16 × 2\n   inicial     n\n     <dbl> <int>\n 1    0       42\n 2    0.25   140\n 3    0.5    159\n 4    0.75   274\n 5    1      376\n 6    1.25   405\n 7    1.5    503\n 8    1.75   574\n 9    2      564\n10    2.25   526\n11    2.5    451\n12    2.75   338\n13    3      287\n14    3.25   211\n15    3.5    114\n16    3.75    36\n\n\nY calculamos la aproximación a la media como sigue:\n\n\nCódigo\nagrupados_cubeta %>% \n  summarise(media_aprox = sum(inicial * n) / sum(n))\n\n\n# A tibble: 1 × 1\n  media_aprox\n        <dbl>\n1        1.88\n\n\nApliquemos esta idea cuando tenemos una densidad \\(f(x)\\). Dividimos el rango de la densidad en cubetas, y aproximamos la densidad por rangos, por ejemplo:\n\n\nCódigo\nparticion <- seq(0, 4, 0.25)\nvalor <- dtri(particion, 0, 4)\napprox_tbl <- tibble(x = particion, densidad = valor)\ndensidad_tri <- tibble(x = seq(0, 4, 0.01)) %>% \n  mutate(densidad = dtri(x, 0, 4))\nggplot(densidad_tri) + \n  ylab('f(x)') + \n  geom_line(aes(x = x, y= densidad), alpha = 0.8) +\n  geom_step(data = approx_tbl, aes(x = x, y = densidad), colour = \"red\") +\n  theme_minimal() \n\n\n\n\n\nY repetimos el mismo proceso: ponderamos los valores iniciales por la altura de la densidad:\n\n\nCódigo\napprox_tbl %>% \n  summarise(media_approx = sum(x * densidad) / sum(densidad))\n\n\n# A tibble: 1 × 1\n  media_approx\n         <dbl>\n1            2\n\n\nY esta es una aproximación a la media de esta distribución.\nNótese que la cantidad que estamos calculando es\n\\[\\sum_i x_i f(x_i) \\Delta\\]\ndonde \\(\\Delta\\) es igual a\n\n\nCódigo\napprox_tbl %>% summarise(suma_densidad = 1 / sum(densidad))\n\n\n# A tibble: 1 × 1\n  suma_densidad\n          <dbl>\n1          0.25\n\n\nque es el ancho del intervalo de las particiones. Recordamos por cálculo que esta es una la aproximación a la siguiente integral:\n\\[\\sum_i x_i f(x_i) \\Delta \\approx  \\int xf(x)\\,dx\\]\nDe modo que para pasar de media de los datos \\(\\bar{x}\\) a la media de \\(\\mu_f\\) de una distribución la equivalencia es:\n$$\n{x} = x_i xf(x) = \n$$ donde\n\nUsamos la densidad en lugar de frecuencias relativas para ponderar\nUsamos integral en lugar de suma\n\nEs decir, cuando tenemos una densidad teórica continua, es necesario integrar en lugar de sumar para calcular su media.\n\n\n5.7.2 Varianza y desviación estándar\nOtra cantidad importante es la varianza de una muestra. Es una medida de dispersión, y se calcula como\n$$\n^2 = _{i=1}^n (x_i - {x})^2\n$$\nNótese que cuando los datos están altamente concentrados alrededor del valor de la media, la varianza es chica, y cuando hay más dispersión alrededor de la media, la varianza es grande.\nLa desviación estándar es la raíz cuadrada de esta cantidad:\n$$\n = \n$$ que tiene la ventaja de que está en las mismas unidades que la variable original.\nSiguiendo el mismo patrón que arriba, tenemos que integrar en lugar de sumar, y ponderar por la densidad en lugar de la frecuencia: El equivalente en una distribución teórica es también una integral, y la varianza está definida por\n\\[\\sigma^2 = \\int (x - \\mu)^2 f(x) \\,dx\\]\nLa desviación estándar \\(\\sigma\\) es la raíz cuadrada de esta cantidad.\n\\[\\sigma = \\sqrt{\\int (x - \\mu)^2 f(x)\\,dx}\\]\nEn resumen la densidad indica la frecuencia relativa de datos que esperamos observar alrededor de cada punto, y\n\nResúmenes de una distribución teórica (como cuantiles, media, varianza, etc.) se calculan integrando ponderado por la densidad.\nResúmenes de una distribución empírica se calculan sumando ponderando por la frecuencia relativa.\n\n\n\nNotación\nPara la media de una variable aleatoria \\(X\\) con densidad \\(f\\), utilizamos la notación siguiente:\n\\[\\mu = \\int x f(x)\\,dx = E(X)\\]\ny decimos también que \\(E(X)\\) es el valor esperado de \\(X\\). Igualmente, la varianza podemos escribirla como el valor esperado de la variable \\((X-\\mu)^2\\):\n\\[\\sigma^2 = \\int (x - \\mu)^2 f(x)  = E\\left ( (X-\\mu)^2 \\right)\\]\nAunque esto requiere de un teorema simple (el teorema del estadístico inconsciente) que establece que para cualquier función \\(h\\), si \\(Y=h(X)\\) y \\(f\\) es la función de densidad de \\(X\\), entonces\n\\[E(Y) = E(h(X)) = \\int h(x) f(x) \\,dx\\]\n\n\n5.7.3 ¿Cuándo usar media y desviación estándar?\nAlgunos modelos probabilísticos son más fáciles de tratar analíticamente usando media y varianza. En esos casos, conviene usar estas medidas. Esto es especialmente cierto cuando las distribuciones son simétricas y no tienen colas muy largas.\nEn cuanto a datos observados, conviene usar media y varianza cuando pretendemos modelarlos con densidades como las del párrafo anterior. En este caso, la interpretación de estos valores se hace a través de la forma de la densidad. Es importante checar (por ejemplo usando gráficas de cuantiles) que esas densidades describen apropiadamente a los datos.\n\n\nEjercicio\n\nCalcula media y desviación estándar para una densidad triangular (0,4) y otra (0,10)\nCalcula media y desviación estándar para una densidad uniforme en (0,4) y otra uniforme en (0, 10)\nContrasta tus resultados. ¿Las medias ocurren en el lugar que esperabas? ¿Qué distribuciones presentan más dispersión de acuerdo a la desviacion estándar?"
  },
  {
    "objectID": "modelos-continuos.html#la-distribución-normal",
    "href": "modelos-continuos.html#la-distribución-normal",
    "title": "5  Modelos probabilísticos para variables continuas",
    "section": "5.8 La distribución normal",
    "text": "5.8 La distribución normal\nLa distribución normal es una que aparece naturalmente en al teoría de probabilidad.\n\n5.8.1 Promedio de variables\nConsideremos que tiramos 40 dados justos de 6 lados, y consideramos su promedio \\(\\bar{X}\\) como resultado de nuestro experimento aleatorio. ¿Cómo se ve la distribución de probabilidades de esta variable \\(\\bar{X}\\)?\nComenzamos haciendo simulacion:\n\n\nCódigo\nsimular_bolsa <- function(num_dados = 40){\n    dados <- sample(1:6, num_dados, replace = TRUE)\n    media <- mean(dados)\n    media\n}\nsimular_bolsa()\n\n\n[1] 3.025\n\n\nVeamos cómo se ven los resultados si hacemos este experimento un número grande de veces:\n\n\nCódigo\nset.seed(23)\nsims_dados <- map_dbl(1:10000, ~ simular_bolsa())\nggplot(tibble(resultado = sims_dados), \n       aes(x = resultado)) +\n    geom_histogram(binwidth = 0.1)\n\n\n\n\n\nY notamos una forma de “campana” interesante. Esto se explica porque típicamente tendremos tiros bajos y altos, de modo que muchos resultados de este experimento se concentran alrededor de la media de un dado (3.5). Además, existen fluctuaciones aleatorios, y a veces tenemos un poco más de tiros altos o de tiros bajos, de forma que existe dispersión alrededor de 3.5.\nSin embargo, estas desviaciones de 3.5 no pueden ser muy grandes: por ejemplo, para tener un promedio de 1, todas las tiradas de los 40 dados tendrían que dar 1, y eso es muy poco probable. Igualmente, para que el promedio fuera cercano a 6, la gran mayoría de los 40 dados deberían de dar 6, lo cual otra vez es muy poco probable. Esto explica al menos la forma general de la forma de las colas derecha e izquierda de esta distribución.\nLos dados podrían ser diferentes (por ejemplo, un poco cargados a 1 o 6, o más cargados a valores centrales), y los argumentos de arriba también se cumplirían. Lo que es sorprendente es que, independientemente de cómo sean las particularidades de los dados, la forma analítica de esta distribución que acabamos de mostrar es la misma.\nEsta forma está descrita por la densidad normal estándar:\n\\[f(x) = \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{x^2}{2}}\\]\ncuya gráfica presentamos a continuación:\n\n\nCódigo\ntibble(x = seq(-3.5, 3.5, 0.01)) %>% \n    mutate(f = (1/sqrt(2*pi)) * exp(-x^2 / 2)) %>% \nggplot(aes(x = x, y = f)) + geom_line()\n\n\n\n\n\nA una variable \\(Z\\) que tiene esta densidad le llamamos una variable con distribución normal estándar. Comparemos cuantiles en nuestro ejemplo:\n\n\nCódigo\nggplot(tibble(resultado = sims_dados),\n       aes(sample = resultado)) +\n    geom_qq(distribution = stats::qnorm) +\n    xlab(\"Normal estándar teórica\") +\n    ylab(\"Promedio de 40 dados\")\n\n\n\n\n\nY notamos que los cuantiles no corresponden, pero el espaciamiento entre los cuantiles de los datos y los teóricos de la normal estándar es el mismo. Quiere decir que estas dos distribuciones tienen la misma forma, aunque estén escaladas y centradas en distintos valores.\nProbemos con promedios de 20 observaciones triangulares en \\((0,1)\\) por ejemplo. El resultado es el mismo:\n\n\nCódigo\nset.seed(23)\nsims_tri <- map_dbl(1:10000, ~ mean(rtri(20, 0 ,1)))\nggplot(tibble(resultado = sims_tri), \n       aes(x = resultado)) +\n    geom_histogram(binwidth = 0.01)\n\n\n\n\n\n\n\nCódigo\nggplot(tibble(resultado = sims_tri),\n       aes(sample = resultado)) +\n    geom_qq(distribution = stats::qnorm) +\n    xlab(\"Normal estándar teórica\") +\n    ylab(\"Promedio de 20 triangulares (0,1)\")\n\n\n\n\n\nOtra vez, la forma general es la misma, aún cuando los datos están centrados y escalados de manera distinta."
  },
  {
    "objectID": "modelos-continuos.html#la-densidad-normal-estándar",
    "href": "modelos-continuos.html#la-densidad-normal-estándar",
    "title": "5  Modelos probabilísticos para variables continuas",
    "section": "5.9 La densidad normal estándar",
    "text": "5.9 La densidad normal estándar\nComo expicamos, la densidad normal estándar está dada por\n\\[f(x) = \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{x^2}{2}},\\]\ncuya gráfica es como sigue:\n\n\nCódigo\nnormal_std_graf <- tibble(x = seq(-3.5, 3.5, 0.01)) %>% \n    mutate(f = dnorm(x, 0, 1))\nggplot(normal_std_graf, aes(x = x, y = f)) +\n    geom_line()\n\n\n\n\n\nLas probabilidades asociadas a una normal estándar se calculan integrando esta curva (que tiene que hacerse de forma numérica). Por ejemplo, para calcular\n\\[P(Z < 1.5),\\]\npodemos usar\n\n\nCódigo\npnorm(1.5)\n\n\n[1] 0.9331928\n\n\nQue es el área bajo la curva mostrada abajo:\n\n\nCódigo\nnormal_std_graf <- tibble(x = seq(-3.5, 3.5, 0.005)) %>% \n    mutate(f = dnorm(x, 0, 1))\nggplot(normal_std_graf, aes(x = x, y = f)) +\n    geom_line() +\n    geom_area(aes(x = ifelse(x > -3.5 & x < 1.5, x, 0)), \n              fill=\"salmon\", alpha = 0.5) +\n    ylim(c(0,0.4)) +\n    scale_x_continuous(breaks = seq(-3.5, 3.5, 0.5))\n\n\n\n\n\nEsta es la forma de la densidad estándar. Podemos centrar esta campana en otro valor \\(\\mu\\) y aumentar la dispersión por un factor \\(\\sigma\\). Si \\(Z\\) es una variable normal estándar, la variable\n\\[X = \\mu + \\sigma Z\\]\nes una variable normal con parámetros \\((\\mu, \\sigma)\\), o de manera más compacta, decimos que \\(X\\) es \\(N(\\mu, \\sigma)\\). La distribución normal estándar es \\(N(0,1)\\).\nPor ejemplo, si escogemos \\(\\mu=5\\) y \\(\\sigma = 0.5\\), obtenemos:\n\n\nCódigo\nnormal_graf <- tibble(x = seq(3, 7, 0.01)) %>% \n    mutate(f = dnorm(x, 5, 0.5))\nggplot(normal_graf, aes(x = x, y = f)) +\n    geom_line()\n\n\n\n\n\nPodemos mostrar juntas estas dos distribuciones:\n\n\nCódigo\ndensidad_normal <- tibble(x = seq(3, 7, 0.1)) %>% \n  mutate(densidad = dnorm(x, 5, 0.5))\ndensidad_normal_estandar <- tibble(x = seq(-3, 3, 0.1)) %>% \n  mutate(densidad = dnorm(x))\ng_2 <- ggplot(densidad_normal_estandar, aes(x = x, y = densidad)) + geom_line()\ng_3 <- g_2 + xlim(c(-3, 7)) + ylim(c(0, 1))\ng_1 <- ggplot(densidad_normal, aes(x = x, y = densidad)) + geom_line() + xlim(c(-3, 7)) + ylim(c(0, 1))\ng_3 + g_1\n\n\n\n\n\nSe puede demostrar que:\n\n\n\nDistribución normal\n\nLa distribución normal estándar \\(N(0,1)\\) tiene media 0 y desviación estándar 1\nLa distribución normal \\(N(\\mu,\\sigma)\\) tiene media \\(\\mu\\) y desviación estándar \\(\\sigma\\)"
  },
  {
    "objectID": "modelos-continuos.html#cuantiles-y-concentración-de-la-densidad-normal",
    "href": "modelos-continuos.html#cuantiles-y-concentración-de-la-densidad-normal",
    "title": "5  Modelos probabilísticos para variables continuas",
    "section": "5.10 Cuantiles y concentración de la densidad normal",
    "text": "5.10 Cuantiles y concentración de la densidad normal\nCon un poco de cálculo podemos ver qué tan fuertemente se concentra la densidad alrededor de la media para una distribución normal. La regla es la siguiente:\n\n68% de la densidad se concentra en el intervalo \\([\\mu-\\sigma, \\mu+\\sigma]\\)\n95% de la densidad se concentra en el intervalo \\([\\mu-2\\sigma, \\mu+2\\sigma]\\)\n99.7% de la densidad se concentra en el intervalo \\([\\mu-3\\sigma, \\mu+3\\sigma]\\)\n\n\n\nCódigo\ngrafica_concentracion <- function(mu, sigma, z){\n  x <- seq(mu - 3.1 * sigma, mu + 3.1 * sigma, 0.01)\n  valor <- dnorm(x, mu, sigma)\n  datos <- tibble(x = x, `f(x)`=valor)\n  texto <- round(100*(pnorm(z) - pnorm(-z)), 1)\n  texto <- paste0(texto, \"%\")\n  ggplot(datos, aes(x = x, y = `f(x)`)) +\n    geom_area(data = filter(datos, x < mu + z*sigma, x > mu - z*sigma), \n      fill = \"salmon\") +\n        geom_line() +\n    annotate(\"text\", x = mu, y = 0.1, label = texto) +\n    scale_x_continuous(breaks = mu + sigma*seq(-3, 3, 1)) +\n    theme_minimal() + ylab(\"\") \n}\ng_68 <- grafica_concentracion(10, 2, 1)\ng_95 <- grafica_concentracion(10, 2, 2)\ng_997 <- grafica_concentracion(10, 2, 3)\npaneles <- g_68 + g_95 + g_997\npaneles + plot_annotation(title = \"Concentración alrededor de la media (normal)\")\n\n\n\n\n\nNota: esto aplica para cualquier densidad normal, independientemente de los parámetros.\nObsérvese que esto nos da una interpretación natural de la desviación estándar de una distribución normal en términos de percentiles de los datos, y la manera usual con la que entendemos la desviación estándar de la distribución normal."
  },
  {
    "objectID": "modelos-continuos.html#el-teorema-central-del-límite",
    "href": "modelos-continuos.html#el-teorema-central-del-límite",
    "title": "5  Modelos probabilísticos para variables continuas",
    "section": "5.11 El teorema central del límite",
    "text": "5.11 El teorema central del límite\nUna de las razones por las que el modelo normal es tan importante es el siguiente resultado:\n::: {.cell type=‘comentario’}\n\nTeorema central del límite\nSi \\(X_1,X_2,\\ldots, X_n\\) son variables aleatorias independientes con media \\(\\mu\\) y desviación estándar \\(\\sigma\\) con una densidad \\(f(x)\\):\n\n\\(S_n = X_1 + X_2 + \\cdots X_n\\) es aproximadamente normal cuando \\(n\\) es suficientemente grande\n\n:::\nMuchas cantidades de interés en la estadística se pueden definir como sumas o promedios de un número grande de variables aleatorias (por ejempo, cuando queremos estimar el total de ingreso de los hogares, estatura promedio en una población, etc.) Los percentiles de una muestra grande también cumplen un teorema central del límite de este tipo.\nLa aproximación del teorema central del límite mejora cuando \\(n\\) es más grande. Aunque una regla de dedo dice que \\(n\\geq 30\\) es suficiente para muchas distribuciones, puede ser que sea necesaria usar una \\(n\\) más grande.\n\nEsto nos permite, por ejemplo, considerar nuestro primera técnica de estimación por intervalos:\n\nObservamos una muestra grande \\(x_1,\\ldots, x_n\\) de datos de una población (no necesariamente con distribución normal). Supongamos que buscamos estimar la media \\(\\mu\\) de la población con un intervalo.\nEstimamos la media con\n\n\\[\\bar{x} = \\frac{1}{n}(x_1+\\cdots + x_n) = \\frac{1}{n}\\sum_i x_i,\\]\n\nPor el teorema del límite central, {x} es aproximadamente normal, y su media es \\(\\mu\\). Esto implica que\n\n\\[P(\\mu - 2\\sigma  \\leq \\bar{x} \\leq\\mu + 2\\sigma)\\approx 0.95\\]\nDespejando \\(\\mu\\) obtenemos\n\\[P(\\bar{x} - 2\\sigma  \\leq \\mu  \\leq\\bar{x} + 2\\sigma)\\approx 0.95\\]\nFinalmente, no conocemos \\(\\sigma\\), pero la estimamos con\n\\[\\hat{\\sigma}^2 = \\frac{1}{n}((x_1 - \\bar{x})^2 + \\dots + (x_n - \\bar{x})^2) = \\frac{1}{n}\\sum_i(x_i - \\bar{x})^2\\]\nY aproximamos sustituyendo nuestra estimación:\n\\[P(\\bar{x} - 2\\hat{\\sigma } \\leq \\mu  \\leq\\bar{x} + 2\\hat{\\sigma})\\approx 0.95\\]\nEsto nos da un intervalo (llamado el intervalo de Wald) con 95% de confianza para la media poblacional:\n\\[[\\bar{x} - 2\\hat{\\sigma }  , \\bar{x} + 2\\hat{\\sigma}]\\]\nNotas:\n\nPor otras razones técnicas, a veces se usa \\(s^2 = \\frac{1}{n-1}\\sum_i (x_i-\\bar{x})^2\\) en lugar de \\(\\hat{\\sigma}^2\\). Si la muestra es grande esto no es importante.\nEstos intervalos tienen cobertura nominal de 95%, sin embargo, puede variar dependiendo del tamaño de muestra y la forma de la distribución teórica (poblacional). Existen métodos como el bootstrap donde podemos checar qué tan razonable es hacer esta aproximación. También se puede hacer simulación modelando la distribución \\(f(x)\\)."
  },
  {
    "objectID": "modelos-continuos.html#otras-densidades-comunes",
    "href": "modelos-continuos.html#otras-densidades-comunes",
    "title": "5  Modelos probabilísticos para variables continuas",
    "section": "5.12 Otras densidades comunes",
    "text": "5.12 Otras densidades comunes\nComo vimos arriba, consideraciones teóricas hacen razonable suponer que una variable aleatoria tiene cierta distribución: por ejemplo, si una variable aleatoria es suma de muchas perturbaciones independientes, la suma o promedio resultante puede modelarse como una distribución normal.\nOtras consideraciones teóricas sugieren otro tipo formas útiles de densidades. Un primer ejemplo es la distribución exponencial.\n\n5.12.1 Variables aleatorias exponenciales\nSupongamos que estamos modelando tiempos a la ocurrencia \\(X\\) de un evento (por ejemplo en análisis de supervivencia en estudios clínicos). Esta es una variable que toma valores en los números positivos. ¿Cómo podría ser su forma?\nConsideremos por ejemplo que el tiempo de espera no tienen memoria. Es decir: si hay esperamos un periodo de \\(t\\) días por ejemplo, la distribución del tiempo restante que tenemos que esperar no depende de \\(s\\). En términos de probabilidad, podríamos escribir:\n\\[P(X > s + t | X > t) = P(X > s)\\]\nEsto se lee: dado que el evento ocurre en más de \\(t\\) días, la probabilidad de que tarde al menos otros \\(s\\) días no dependen de \\(t\\). A la función \\(S(t) = P(X>t)\\) muchas veces se le llama la función de supervivencia.\nEste es un modelo base útil, que después puede extenderse a procesos donde los eventos ocurren aceleradamente (envejecen), o donde los eventos dan evidencia de robustez (los que han sobrevivido hasta cierto tiempo se espera que duren más que lo que inicialmente), o quizá una combinación de los dos dependiendo de el valor de \\(t\\).\nCon el supuesto de falta de memoria, la ecuación de arriba se cumple, y entonces (¿por qué?):\n\\[P(X > s + t) = P(X > s) P(X > t),\\]\nasí que\n\\[\\frac{1}{s}(P(X > s+ t) - P(X>t)) = \\frac{1}{s}(P(X>s) - 1)P(X>t).\\]\nQue podemos reescribir usando la densidad \\(f(x)\\) como\n\\[\\frac{1}{s}\\int_t^{t+s} f(x)\\,dx = P(X>t)\\frac{1}{s}\\int_0^s f(x)\\,dx\\]\nConforme \\(s\\) se hace más chica, el lado izquierdo converge a \\(f(t)\\). El lado derecho, por otra parte, converge a \\(f(0)\\), y obtenemos\n\\[f(t) = f(0)\\int_t^\\infty f(x)\\,dx,\\]\ny ahora derivamos de ambos lados para obtener\n\\[f'(t) = -f(0)f(t)\\]\nLa única función que satisface esta propiedad (su derivada es proporcional a ella misma) es\n\\[f(t) = \\lambda e^{-\\lambda t}\\]\nPuedes checar que efectivamente esta densidad cumple que la ecuación anterior. A esta densidad le llamamos la densidad exponencial con tasa \\(\\lambda\\).\n\n\nCódigo\nlambda <- 1\nsim_exp <- rexp(1000, rate = lambda)\nggplot(tibble(x = sim_exp), aes(x = x)) +\n    geom_histogram(boundary = 0)\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nEjercicio: demuestra que una variable aleatoria exponencial con tasa \\(\\lambda\\) tiene media \\(E(X) = 1/\\lambda\\) y $Var(X) = 1 / ^2\nEl parámetro \\(\\lambda\\) se llama tasa por la interpretación de tiempo de espera que mostramos arriba. Supongamos que \\(\\lambda = 10\\). Eso quiere decir que esperamos observar el evento en \\(1/\\lambda = 1/10\\) minutos, por ejemplo, o lo que es lo mismo, a una tasa de \\(\\lambda = 10\\) eventos por minuto.\nNótese finalmente que todas las variables exponenciales son escalamientos de una variable exponencial con \\(\\lambda = 1\\). Esto es porque si \\(Y=kX\\), y \\(X\\) es exponencial con \\(\\lambda= 1\\) entonces:\n\\[P(Y>t)=P(kX > t) = P(X > t/k) = \\int_{t/k}^\\infty e^{-x}\\,dx = e^{-t/k}\\]\nDe modo que derivando, encontramos que la densidad de \\(Y\\) es \\(\\frac{1}{k} e^{-t/k}\\), que es una exponencial con tasa \\(\\lambda = 1/k\\).\n\n\n5.12.2 Ejemplo: exponencial\nSupongamos que un tipo de focos tienen tiempos de vida exponencial con una vida media de 10 años. ¿Cuál es la probabilidad de que un foco dure más de 15 años? Si tenemos un foco que ya vivió 10 años, cuál es la probabilidad de que dure otros 15 años.\nTenemos que la vida de un foco es una variable \\(X\\) exponencial con parámetro \\(\\lambda = 1/10\\). La probabilidad de que dure más de 15 años es entonces\n\\[P(X>15) = \\int_{15}^\\infty \\frac{1}{10} e^{x/10}\\,dx\\]\nPodemos calcular a mano, o usar rutinas usuales de R:\n\n\nCódigo\npexp(15, rate = 1/10, lower.tail = FALSE)\n\n\n[1] 0.2231302\n\n\n\n\n5.12.3 Variables aleatorias gamma\nEsta es otra familia que extiende la familia de distribuciones exponenciales. La forma analítica de una densidad gamma con parámetro de forma \\(k>0\\) y tasa \\(\\lambda\\)\n\\[f(x) = C x^{k-1} e^{-\\lambda x}\\]\ndonde la constante \\(C\\) de normalización depende de \\(k\\) y \\(\\lambda\\).\nAbajo vemos datos simulados de densidades Gamma con distintas combinaciones de parámetros:\n\n\nCódigo\nparams_tbl <- crossing(k = c(1, 2, 5, 10), lambda = c(1/4, 1/2))\nsims_tbl <- params_tbl %>% \n    mutate(sims = map2(k, lambda, \n                       ~ rgamma(10000, shape = .x, rate = .y))) %>% \n    unnest(cols = sims)\n\n\n\n\nCódigo\nggplot(sims_tbl, aes(x = sims)) + \n    geom_histogram(boundary = 0, bins = 50) +\n    facet_grid(k~lambda)\n\n\n\n\n\nNótese que cada columna es un rescalamiento de la otra, pero las densidades de los renglones tienen distinta forma. Puedes ver aquí parámetros como esperanza, varianza de esta estas distribuciones, junto con otras propiedades y aplicaciones."
  },
  {
    "objectID": "modelos-continuos.html#modelos-conjuntos-de-probabilidad",
    "href": "modelos-continuos.html#modelos-conjuntos-de-probabilidad",
    "title": "5  Modelos probabilísticos para variables continuas",
    "section": "5.13 Modelos conjuntos de probabilidad",
    "text": "5.13 Modelos conjuntos de probabilidad\nUsualmente no nos interesa una sola variable aleatoria, sino varias. Nos interesa entender cómo están relacionadas o cómo depende una de otra.\nPor ejemplo, ¿cuál es la mediana de peso para un infante de 2 meses, y qué tan diferente es de la mediana de peso para un infante de 5 meses? ¿qué relación hay entre temperatura y presión atmosférica? ¿qué relación hay entre creencias religiosas y afiliación política? En todos estos casos quisiéramos describir de distintas formas cómo ser relaciona una cantidad aleatoria con otra.\nAl principio de este curso, vimos algunas técnicas descriptivas para mostrar y explorar estas relaciones. Por ejemplo:\n\n¿Cómo cambian las preferencias de forma de tomar té dependiendo del tipo de té una persona acostumbra tomar? ¿Qué tan probable es que alguien que toma té negro use azúcar vs alguien que toma té verde? (relación entre dos variables categóricas o discretas)\n¿Cómo cambian los precios medios de las casas dependiendo del vecindario donde se ubican? (describir la dependencia de una variable numérica si sabemos el valor de una variable categórica)\n¿Cómo cambia la mediana y los cuartiles de peso de un infante dependiendo de los meses desde que nació (describir cómo depende una variable numérica de otra variable numérica)\n\nEn esta parte veremos una introducción cómo se formalizan estos conceptos en modelos probabilísticos."
  },
  {
    "objectID": "modelos-continuos.html#estaturas-modelando-relaciones-de-dependencia",
    "href": "modelos-continuos.html#estaturas-modelando-relaciones-de-dependencia",
    "title": "5  Modelos probabilísticos para variables continuas",
    "section": "5.14 Estaturas: modelando relaciones de dependencia",
    "text": "5.14 Estaturas: modelando relaciones de dependencia\nSupongamos que \\(X\\) es la edad de una persona entre 4 y 15 años. y \\(Y\\) es su estatura. La relación entre \\(X\\) y \\(Y\\) no es determinística, pues existe variación en el crecimiento para las personas por distintas razones. Por esta razón, no tiene mucho sentido dar una relación como \\(Y = 80 + 5.5 X\\), por ejemplo, pues esta relación no se cumple para prácticamente ninguna persona.\nTiene más sentido, sin embargo, decir cómo es la distribución condicional de \\(Y\\) dado que conocemos \\(X\\). Por ejemplo, podríamos hacer la hipótesis de que la mediana de estatura para una persona de edad \\(X\\) está dada por\n\\[med(Y|X) = 80 + 5.5 X\\]\nNótese que escribimos la mediana condicional de \\(Y\\) dado que conocemos el valor de \\(X\\). También podríamos escribir la media condicional de \\(Y\\) dada \\(X\\) como\n\\[E(Y|X) = 80 + 5.5 X\\]\nY estas dos cantidades tienen sentido.\nEstas cantidades claramente no determinan la variabilidad que hay de la estatura cuando conocemos \\(X\\). Podríamos entonces también especificar por ejemplo la desviación estándar condicional:\n\\[\\sigma(Y|X) = 3\\sqrt{X} \\]\nGeneralmente estas relaciones se estiman empíricamente con datos observados, pero para este ejemplo utilizaremos estos modelos fijos.\nSimulamos algunos datos con estas propiedades:\n\n\nCódigo\nedades <- runif(800, 2, 15) # edad distribuida uniforme, o grupos de edad del mismo tamaño\ndatos_tbl <- \n   tibble(edad = edades) %>% \n   mutate(media = 80 + 5.5*edad, desv_est = 3 * sqrt(edad)) %>% \n   # para este ejemplo, simulamos con la distribución normal.\n   mutate(estatura_cm = rnorm(n(), mean = media, sd = desv_est))\nggplot(datos_tbl, aes(x = edad, y = estatura_cm)) +\n   geom_point()\n\n\n\n\n\n\nObsérvese cómo en efecto la estatura esperada aumenta con la edad (condicional a la edad), y que la dispersión de estatura aumenta conforme la edad aumenta.\n\nNótese que si usamos un suavizador, podemos estimar la media condicional de nuestro modelo, que en este caso está cercana a la fórmula que establecimos en nuestro modelo:\n\n\nCódigo\nggplot(datos_tbl, aes(x = edad, y = estatura_cm)) +\n   geom_point() +\n   geom_smooth(se = FALSE)\n\n\n`geom_smooth()` using method = 'loess' and formula 'y ~ x'\n\n\n\n\n\nPodemos estimar cuantiles también como vimos en secciones anteriores:\n\n\nCódigo\nggplot(datos_tbl, aes(x = edad, y = estatura_cm)) +\n   geom_point() +\n   geom_quantile(method = \"rqss\", lambda = 20, quantiles = c(0.10, 0.5, 0.90)) \n\n\nSmoothing formula not specified. Using: y ~ qss(x, lambda = 20)\n\n\n\n\n\nY observamos igualmente que la dispersión para el grupo de 15 años es cercana al doble que la dispersión para el grupo de 4 años."
  },
  {
    "objectID": "modelos-continuos.html#distribuciones-condicionales",
    "href": "modelos-continuos.html#distribuciones-condicionales",
    "title": "5  Modelos probabilísticos para variables continuas",
    "section": "5.15 Distribuciones condicionales",
    "text": "5.15 Distribuciones condicionales\nTodo el trabajo de arriba de modelación teórica consiste entonces en definir distribuciones condicionales. En el ejemplo anterior,\n\nDimos una distribución para \\(X\\), que en este caso la tomamos uniforme en [4, 15], pues suponemos que esta es la estructura de nuestra población (hay el aproximadamente el mismo número de personas de cada edad)\nDimos una distribución para \\(Y\\) condicionada a \\(X\\). En este caso, establecimos que \\(Y|X\\) es normal con media \\(80 + 5.5X\\) y desviación estándar \\(3 * sqrt(X)\\).\n\nEstas dos partes dan un modelo conjunto para \\(X\\) y \\(Y\\): sabemos que está completamente determinado pues pudimos simular del modelo. Otra manera de entender esto es que cualquier probabilidad que involucra a \\(X\\) y \\(Y\\) puede ser calculada con la regla del producto. Aunque no entraremos en detalles, la densidad conjunta de \\(X\\) y \\(Y\\) puede definirse en este caso como\n\\[f(x,y) = f_X(x)f_{Y|X}(y|x)\\]\nSabemos que \\(f_X(x) = 1/(15- 3)\\) para \\(x\\) entre 4 y 15 años, y la forma de \\(f_{Y|X}(y|x)\\) sabemos que es normal con media y varianza conocida (en términos de x). Esta conjunta puede ser integrada sobre cualquier región (al menos en teoría) para calcular la probabilidad de interés"
  },
  {
    "objectID": "modelos-continuos.html#estaturas-variación-gamma",
    "href": "modelos-continuos.html#estaturas-variación-gamma",
    "title": "5  Modelos probabilísticos para variables continuas",
    "section": "5.16 Estaturas: variación gamma",
    "text": "5.16 Estaturas: variación gamma\nPodemos juntar estos bloques de densidades condicionales para construir otro tipo de modelos. Por ejemplo, supondremos que la estatura dada la edad es una distribución gamma \\((k,\\lambda)\\) y la misma media y desviación estándar que vimos arriba. Como la media de una gamma de este tipo es \\(\\mu = k/\\lambda\\) y su desviación estándar es \\(\\sigma = \\sqrt{k}/\\lambda\\), podemos despejar \\(k\\) y \\(lambda\\) y hacer:\n\n\nCódigo\ndatos_tbl <- \n   tibble(edad = edades) %>% \n   mutate(media = 80 + 5.5*edad, desv_est = 3 * sqrt(edad)) %>%\n   mutate(k = (media/desv_est)^2, lambda = media / desv_est^2) %>% \n   # para este ejemplo, simulamos con la distribución normal.\n   mutate(estatura_cm = rgamma(n(), shape = k, rate = lambda))\nggplot(datos_tbl, aes(x = edad, y = estatura_cm)) +\n   geom_point() +\n   geom_quantile(method = \"rqss\", lambda = 10, \n                 quantiles = c(0.10, 0.5, 0.9))\n\n\nSmoothing formula not specified. Using: y ~ qss(x, lambda = 10)\n\n\n\n\n\nEste modelo es muy similar al normal. Sin embargo, podríamos intentar otras variaciones si cambiamos la magnitud de la desviación estándar en relación a la media, por ejemplo:\n\n\nCódigo\ndatos_tbl <- \n   tibble(edad = edades) %>% \n   mutate(media = 30 + 10*edad, desv_est = 7 * (edad)) %>%\n   mutate(k = (media/desv_est)^2, lambda = media / desv_est^2) %>% \n   # para este ejemplo, simulamos con la distribución normal.\n   mutate(medicion_y = rgamma(n(), shape = k, rate = lambda))\nggplot(datos_tbl, aes(x = edad, y = medicion_y)) +\n   geom_point() +\n   geom_quantile(method = \"rqss\", lambda = 10, \n                 quantiles = c(0.10, 0.5, 0.9))\n\n\nSmoothing formula not specified. Using: y ~ qss(x, lambda = 10)\n\n\n\n\n\nEste caso claramente no serviría para modelar estaturas, pero podemos ver cómo introdujimos asimetría considerable en las distribuciones condicionales de y dado x una vez que especificamos la media y la varianza condicionales."
  },
  {
    "objectID": "modelos-continuos.html#modelos-conjuntos-para-factor-categórico",
    "href": "modelos-continuos.html#modelos-conjuntos-para-factor-categórico",
    "title": "5  Modelos probabilísticos para variables continuas",
    "section": "5.17 Modelos conjuntos para factor categórico",
    "text": "5.17 Modelos conjuntos para factor categórico\nSupongamos ahora que la variable \\(Y\\) es numérica y la variable \\(X\\) es categórica. En este caso, un modelo conjunto está definido por las probabilidades \\(P(X=x)\\) junto con densidades condicionales \\(Y|X\\).\n\n5.17.1 Ejemplo: cuentas y propinas\nSupongamos que \\(X\\) es la hora del día (comida y cena) y que \\(Y\\) es el tamaño de la cuenta.\nPodríamos establecer por ejemplo, que \\(Y|X=comida\\) es Gamma con media 10 dólares y desviacion estándar 10 dólares. Sin embargo, \\(Y|X=cena\\) es Gamma con media 25 dólares y desviación estándar 20 dólares. Simulamos y analizamos:\n\n\nCódigo\ndatos_tbl <- \n   tibble(hora = sample(c(\"comida\", \"cena\"), 1000, replace = TRUE)) %>% \n   mutate(media = ifelse(hora == \"comida\", 10, 25),\n          desv_est = ifelse(hora == \"comida\", 10, 20)) %>% \n   mutate(cuenta = rgamma(n(), shape = (media / desv_est)^2,\n                               rate = media / (desv_est^2)))\nggplot(datos_tbl, aes(x = hora, y = cuenta)) +\n   geom_boxplot()\n\n\n\n\n\nY esta gráfica busca mostrar una estimación de las distribuciones condicionales de cuenta dado el turno donde el cliente consumió."
  },
  {
    "objectID": "modelos-continuos.html#modelos-multivariados",
    "href": "modelos-continuos.html#modelos-multivariados",
    "title": "5  Modelos probabilísticos para variables continuas",
    "section": "5.18 Modelos multivariados",
    "text": "5.18 Modelos multivariados\nAhora consideremos que queremos construir un modelo conjunto para tres variables \\(X, Y\\) y \\(Z\\). La forma en que procedemos dependerá del problema particular, pero podemos usar la regla del producto como guía. Por ejemplo, podríamos dar una distribución para \\(Z\\), luego una densidad condicional de Y dado \\(Z\\), y finalmente una condicional de \\(Y\\) dada tanto \\(X\\) como \\(Z\\).\n\n\nCódigo\nlibrary(dagitty)\ng <- dagitty('dag {\n    Z [pos=\"0,1\"]\n    X [pos=\"1,0\"]\n    Y [pos=\"2,1\"]\n    \n    Z -> X -> Y\n    Z -> Y\n}')\nplot(g)\n\n\n\n\n\nEn este caso, cada variable aleatorio es nodo, y representa una distribución condicional dado sus antecesores. Esta gráfica por ejemplo, muestra una manera de escribir con la regla del producto un modelo conjunto, pero podríamos cambiar de posición los nodos dependiendo de nuestro conocimiento y el problema que queremos resolver.\nEn algunos casos, es posible simplificar la construcción del modelo eliminando algunas aristas. Supongamos por ejemplo que\n\nX es la edad de la persona\nZ es “M” of “F”\nY es su estatura\n\nEn este caso, no es necesario especificar la condicional de \\(X\\) dado \\(Z\\), pues estas dos son variables independientes. Pondríamos entonces simplemente\n\n\nCódigo\nlibrary(dagitty)\ng <- dagitty('dag {\n    Z [pos=\"0,1\"]\n    X [pos=\"1,0\"]\n    Y [pos=\"2,1\"]\n    \n    X -> Y\n    Z -> Y\n}')\nplot(g)\n\n\n\n\n\nY solo necesitamos especificar las distribuciones de \\(X\\), de \\(Z\\), y la condicional de \\(Y\\) dado \\(Z\\). Siguiendo nuestro ejemplo anterior, consideraremos a\n\n\\(X\\) como uniforme en \\([4,15]\\) (que es nuestro rango de edad de interés)\n\\(Z\\) es \\(M\\) con probabilidad 0.5 y \\(F\\) con probabilidad 0.5\n\nY podríamos especificar ahora: la condicional de \\(Y\\) (estatura) es normal con los siguientes parámetros:\n\nSi \\(X\\) es la edad y \\(Z=\"F\"\\), entonces la media es \\(70 + 6.5 X\\)\nSi \\(X\\) es la edad y \\(Z=\"M\"\\), entonces la media es \\(80 + 4.5 X\\)\nLa desviación estándar sólo depende de \\(X\\), y es igual a \\(4\\sqrt{X}\\).\n\nSimulamos ahora de este modelo probabilístico:\n\n\nCódigo\ndatos_tbl <- tibble(x = runif(1000, 4, 15)) %>%\n   # independientemente simulamos M o F\n   mutate(z = sample(c(\"m\", \"f\"), 1000, replace = TRUE)) %>% \n   mutate(media = ifelse(z==\"f\", 70 + 6.5 * x, 80 + 4.5 * x)) %>% \n   mutate(desv_est = 4 * sqrt(x)) %>% \n   mutate(estatura = rnorm(n(), media, desv_est))\ndatos_tbl %>% head(20) %>% kable()\n\n\n\n\n \n  \n    x \n    z \n    media \n    desv_est \n    estatura \n  \n \n\n  \n    13.917312 \n    m \n    142.62790 \n    14.922366 \n    106.17567 \n  \n  \n    9.655767 \n    m \n    123.45095 \n    12.429492 \n    118.95931 \n  \n  \n    4.178553 \n    m \n    98.80349 \n    8.176603 \n    102.90009 \n  \n  \n    4.085706 \n    m \n    98.38568 \n    8.085252 \n    99.27880 \n  \n  \n    7.510502 \n    f \n    118.81826 \n    10.962118 \n    120.93123 \n  \n  \n    9.506507 \n    m \n    122.77928 \n    12.333049 \n    131.72703 \n  \n  \n    8.311886 \n    f \n    124.02726 \n    11.532137 \n    127.80079 \n  \n  \n    10.336809 \n    f \n    137.18926 \n    12.860363 \n    138.18963 \n  \n  \n    8.578672 \n    m \n    118.60402 \n    11.715748 \n    133.69638 \n  \n  \n    11.500391 \n    f \n    144.75254 \n    13.564891 \n    121.21221 \n  \n  \n    6.668017 \n    f \n    113.34211 \n    10.329002 \n    123.89877 \n  \n  \n    12.935783 \n    f \n    154.08259 \n    14.386540 \n    135.22746 \n  \n  \n    14.904618 \n    m \n    147.07078 \n    15.442600 \n    128.11113 \n  \n  \n    11.579196 \n    m \n    132.10638 \n    13.611287 \n    143.13437 \n  \n  \n    14.921303 \n    m \n    147.14586 \n    15.451241 \n    162.54670 \n  \n  \n    8.863920 \n    m \n    119.88764 \n    11.908934 \n    114.67713 \n  \n  \n    8.487825 \n    m \n    118.19521 \n    11.653549 \n    105.22789 \n  \n  \n    4.221525 \n    m \n    98.99686 \n    8.218540 \n    94.52403 \n  \n  \n    6.803164 \n    m \n    110.61424 \n    10.433150 \n    108.54392 \n  \n  \n    14.458625 \n    m \n    145.06381 \n    15.209799 \n    145.96106 \n  \n\n\n\n\n\nY hacemos algunas gráficas descriptivas:\n\n\nCódigo\nggplot(datos_tbl, aes(x = x, y = estatura, colour = z)) +\n   geom_point()\n\n\n\n\n\n\nDiscute qué otras cosas podrías cambiar en este modelo probabilístico para que fuera más flexible o más simple. ¿Cómo ajustarías un modelo así a datos reales?\n\n\n\nCódigo\nggplot(datos_tbl, aes(x = x, y = estatura, colour = z)) +\n   geom_point() +\n   facet_wrap(~z) +\n   geom_quantile(method = \"rqss\", lambda = 10,\n                 quantiles = c(0.10, 0.5, 0.9))\n\n\nSmoothing formula not specified. Using: y ~ qss(x, lambda = 10)\n\n\nWarning in rq.fit.sfn(x, y, tau = tau, rhs = rhs, control = control, ...): tiny diagonals replaced with Inf when calling blkfct\n\nWarning in rq.fit.sfn(x, y, tau = tau, rhs = rhs, control = control, ...): tiny diagonals replaced with Inf when calling blkfct\n\nWarning in rq.fit.sfn(x, y, tau = tau, rhs = rhs, control = control, ...): tiny diagonals replaced with Inf when calling blkfct\n\n\nSmoothing formula not specified. Using: y ~ qss(x, lambda = 10)\n\n\n\n\n\n\n\n\nEn la modelación probabilística generalmente usamos estos mecanismos (dependencia condicional, independencia) y estos bloques (distribuciones de probabilidad dadas en términos de parámetros) para obtener estimaciones de parámetros de interés.\nLas decisiones de cómo usar estos mecanismos y bloques se desprenden de conocimiento de dominio, alcances del análisis, y siempre están sujetos a revisión dependiendo del tipo de desajustes que presenten frente a los datos reales."
  },
  {
    "objectID": "inferencia-modelos.html",
    "href": "inferencia-modelos.html",
    "title": "6  Inferencia con modelos probabilísticos",
    "section": "",
    "text": "Intro"
  },
  {
    "objectID": "inferencia-bayesiana.html",
    "href": "inferencia-bayesiana.html",
    "title": "Estadística Bayesiana",
    "section": "",
    "text": "Introducción"
  },
  {
    "objectID": "modelos-bayesianos.html",
    "href": "modelos-bayesianos.html",
    "title": "7  Inferencia bayesiana",
    "section": "",
    "text": "Para esta sección seguiremos principalmente Kruschke (2015). Adicionalmente puedes ver la sección correspondiente de Chihara y Hesterberg (2018).\nEn las secciones anteriores estudiamos el método de máxima verosimilitud y métodos de remuestreo. Esto lo hemos hecho para estimar parámetros, y cuantificar la incertidumbre qué tenemos acerca de valores poblacionales. La inferencia bayesiana tiene objetivos similares.\nEl concepto probabilístico básico que utilizamos para construir estos modelos y la inferencia es el de probabilidad condicional: la probabilidad de que ocurran ciertos eventos dada la información disponible del fenómeno que nos interesa."
  },
  {
    "objectID": "modelos-bayesianos.html#un-primer-ejemplo-completo-de-inferencia-bayesiana",
    "href": "modelos-bayesianos.html#un-primer-ejemplo-completo-de-inferencia-bayesiana",
    "title": "7  Inferencia bayesiana",
    "section": "Un primer ejemplo completo de inferencia bayesiana",
    "text": "Un primer ejemplo completo de inferencia bayesiana\nConsideremos el siguiente problema: Nos dan una moneda, y solo sabemos que la moneda puede tener probabilidad \\(3/5\\) de tirar sol (está cargada a sol) o puede ser una moneda cargada a águila, con probabilidad \\(2/5\\) de tirar sol.\nVamos a lanzar la moneda dos veces y observamos su resultado (águila o sol). Queremos decir algo acerca de qué tan probable es que hayamos tirado la moneda cargada a sol o la moneda cargada a águila.\nEn este caso, tenemos dos variables: \\(X\\), que cuenta el número de soles obtenidos en el experimento aleatorio, y \\(\\theta\\), que da la probabilidad de que un volado resulte en sol (por ejemplo, si la moneda es justa entonces \\(\\theta = 0.5\\)).\n¿Qué cantidades podríamos usar para evaluar qué moneda es la que estamos usando? Si hacemos el experimento, y tiramos la moneda 2 veces, podríamos considerar la probabilidad\n\\[P(\\theta = 0.4 | X = x)\\]\ndonde \\(x\\) es el número de soles que obtuvimos en el experimento. Esta es la probabilidad condicional de que estemos tirando la moneda con probabilidad de sol 2/5 dado que observamos \\(x\\) soles. Por ejemplo, si tiramos 2 soles, deberíamos calcular\n\\[P(\\theta=0.4|X=2).\\]\n¿Cómo calculamos esta probabilidad? ¿Qué sentido tiene?\nUsando reglas de probabildad (regla de Bayes en particular), podríamos calcular\n\\[P(\\theta=0.4|X=2) = \\frac{P(X=2 | \\theta = 0.4) P(\\theta =0.4)}{P(X=2)}\\]\nNota que en el numerador uno de los factores, \\(P(X=2 | \\theta = 0.4),\\) es la verosimilitud. Así que primero necesitamos la verosimilitud:\n\\[P(X=2|\\theta = 0.4) = (0.4)^2 = 0.16.\\]\nLa novedad es que ahora tenemos que considerar la probabilidad \\(P(\\theta = 0.4)\\). Esta cantidad no la habíamos encontrado antes. Tenemos que pensar entonces que este parámetro es una cantidad aleatoria, y puede tomar dos valores \\(\\theta=0.4\\) ó \\(\\theta = 0.6\\).\nConsiderar esta cantidad como aleatoria requiere pensar, en este caso, en cómo se escogió la moneda, o qué sabemos acerca de las monedas que se usan para este experimento. Supongamos que en este caso, nos dicen que la moneda se escoge al azar de una bolsa donde hay una proporción similar de los dos tipos de moneda (0.4 ó 0.6). Es decir el espacio parametral es \\(\\Theta = \\{0.4, 0.6\\},\\) y las probabilidades asociadas a cada posibilidad son las mismas. Es decir, tenemos\n\\[P(\\theta = 0.4) = P(\\theta = 0.6) =0.5,\\]\nque representa la probabilidad de escoger de manera aleatoria la moneda con una carga en particular.\nAhora queremos calcular \\(P(X=2)\\), pero con el trabajo que hicimos esto es fácil. Pues requiere usar reglas de probabilidad usuales para hacerlo. Podemos utilizar probabilidad total \\[\\begin{align}\nP(X) &= \\sum_{\\theta \\in \\Theta} P(X, \\theta)\\\\\n&= \\sum_{\\theta \\in \\Theta} P(X\\, |\\, \\theta) P(\\theta),\n\\end{align}\\] lo cual en nuestro ejemplo se traduce en escribir\n\\[ P(X=2) = P(X=2|\\theta = 0.4)P(\\theta = 0.4) + P(X=2|\\theta=0.6)P(\\theta =0.6),\\]\npor lo que obtenemos\n\\[P(X=2) = 0.16(0.5) + 0.36(0.5) = 0.26.\\]\nFinalmente la probabilidad de haber escogido la moneda con carga \\(2/5\\) dado que observamos dos soles en el lanzamiento es\n\\[P(\\theta=0.4|X=2) = \\frac{0.16(0.5)}{0.26} \\approx  0.31.\\]\nEs decir, la probabilidad posterior de que estemos tirando la moneda \\(2/5\\) baja de 0.5 (nuestra información inicial) a 0.31.\nEste es un ejemplo completo, aunque muy simple, de inferencia bayesiana. La estrategia de inferencia bayesiana implica tomar decisiones basadas en las probabilidades posteriores.\n\n\n\n\n\n\nTip\n\n\n\n¿Cuál sería la estimación de máxima verosimilitud para este problema? ¿Cómo cuantificaríamos la incertidumbre en la estimación de máxima verosimilitud?\n\n\nFinalmente, podríamos hacer predicciones usando la posterior predictiva. Si \\({X}_{nv}\\) es una nueva tirada adicional de la moneda que estamos usando, nos interesaría saber:\n\\[P({X}_{nv}=\\mathsf{sol}\\, | \\, X=2)\\]\nNotemos que un volado adicional es un resultado binario. Por lo que podemos calcular observando que \\(P({X}_{nv}|X=2, \\theta)\\) es una variable Bernoulli con probabilidad \\(\\theta\\), que puede valer 0.4 ó 0.6. Como tenemos las probabilidades posteriores \\(P(\\theta|X=2)\\) podemos usar probabilidad total, condicionado en \\(X=2\\): \\[\\begin{align*}\nP({X}_{nv}=\\mathsf{sol}\\, | \\, X=2) & = \\sum_{\\theta \\in \\Theta} P({X}_{nv}=\\mathsf{sol}, \\theta \\, | \\, X=2) & \\text{(probabilidad total)}\\\\\n&= \\sum_{\\theta \\in \\Theta} P({X}_{nv}=\\mathsf{sol}\\, | \\theta , X=2) P(\\theta \\, | \\, X=2) & \\text{(probabilidad condicional)}\\\\\n&= \\sum_{\\theta \\in \\Theta} P({X}_{nv}=\\mathsf{sol}\\, | \\theta ) P(\\theta \\, | \\, X=2), & \\text{(independencia condicional)}\n\\end{align*}\\]\nlo que nos da el siguiente cálculo\n\\[P(X_{nv}=\\mathsf{sol}\\, |\\, \\theta=0.4) \\,  P(\\theta=0.4|X=2) \\,  +\\, P(X_{nv}=\\mathsf{sol}|\\theta = 0.6) \\, P(\\theta =0.6|X=2)\\]\nEs decir, promediamos ponderando con las probabilidades posteriores. Por lo tanto obtenemos\n\\[P(X_{nv} = \\mathsf{sol}|X=2) =  0.4 ( 0.31) + 0.6 (0.69) = 0.538.\\]\n\nObservación 0\nNótese que en contraste con máxima verosimilitud, en este ejemplo cuantificamos con probabilidad condicional la incertidumbre de los parámetros que no conocemos. En máxima verosimilitud esta probabilidad no tiene mucho sentido, pues nunca consideramos el parámetro desconocido como una cantidad aleatoria.\n\n\nObservación 1\nNótese el factor \\(P(X=2)\\) en la probabilidad posterior puede entenderse como un factor de normalización. Notemos que los denominadores en la distribución posterior son\n\\[P(X=2 | \\theta = 0.4) P(\\theta =0.4) = 0.16(0.5) = 0.08,\\]\ny\n\\[P(X=2 | \\theta = 0.6) P(\\theta =0.6) = 0.36(0.5) = 0.18.\\]\nLas probabilidades posteriores son proporcionales a estas dos cantidades, y como deben sumar uno, entonces normalizando estos dos números (dividiendo entre su suma) obtenemos las probabilidades.\n\n\nObservación 2\nLa nomenclatura que usamos es la siguiente:\n\nComo \\(X\\) son los datos observados, llamamos a \\(P(X|\\theta)\\) la verosimilitud, o modelo de los datos.\nA \\(P(\\theta)\\) le llamamos la distribución inicial o previa.\nLa distribución que usamos para hacer inferencia \\(P(\\theta|X)\\) es la distribución final o posterior.\n\nPara utilizar inferencia bayesiana, hay que hacer supuestos para definir las primeras dos partes del modelo. La parte de iniciales o previas está ausente de enfoques como máxima verosimlitud usual.\n\n\nObservación 3\n¿Cómo decidimos las probabilidades iniciales, por ejemplo \\(P(\\theta=0.4)\\) ?\nQuizá es un supuesto y no tenemos razón para pensar que se hace de otra manera. O quizá conocemos el mecanismo concreto con el que se selecciona la moneda. Discutiremos esto más adelante.\n\n\nObservación 4\n¿Cómo decidimos el modelo de los datos? Aquí típicamente también tenemos que hacer algunos supuestos, aunque algunos de estos pueden estar basados en el diseño del estudio, por ejemplo. Igual que cuando usamos máxima verosimilitud, es necesario checar que nuestro modelo ajusta razonablemente a los datos.\n\n\nEjercicio\nCambia distintos parámetros del número de soles observados, las probabilidades de sol de las monedas, y las probabilidades iniciales de selección de las monedas.\n\n\nCódigo\nn_volados <- 2\n# posible valores del parámetro desconocido\ntheta = c(0.4, 0.6)\n# probabilidades iniciales\nprobs_inicial <- tibble(moneda = c(1, 2),\n                        theta = theta,\n                        prob_inicial = c(0.5, 0.5))\nprobs_inicial\n\n\n# A tibble: 2 × 3\n  moneda theta prob_inicial\n   <dbl> <dbl>        <dbl>\n1      1   0.4          0.5\n2      2   0.6          0.5\n\n\nCódigo\n# verosimilitud\ncrear_verosim <- function(no_soles){\n    verosim <- function(theta){\n      # prob de observar no_soles en 2 volados con probabilidad de sol theta\n      dbinom(no_soles, 2, theta)\n    }\n    verosim\n}\n# evaluar verosimilitud\nverosim <- crear_verosim(2)\n# ahora usamos regla de bayes para hacer tabla de probabilidades\ntabla_inferencia <- probs_inicial %>%\n  mutate(verosimilitud = map_dbl(theta, verosim)) %>%\n  mutate(inicial_x_verosim = prob_inicial * verosimilitud) %>%\n  # normalizar\n  mutate(prob_posterior = inicial_x_verosim / sum(inicial_x_verosim))\n\ntabla_inferencia %>%\n  mutate(moneda_obs = moneda) %>%\n  select(moneda_obs, theta, prob_inicial, verosimilitud, prob_posterior)\n\n\n# A tibble: 2 × 5\n  moneda_obs theta prob_inicial verosimilitud prob_posterior\n       <dbl> <dbl>        <dbl>         <dbl>          <dbl>\n1          1   0.4          0.5          0.16          0.308\n2          2   0.6          0.5          0.36          0.692\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n¿Qué pasa cuando el número de soles es 0? ¿Cómo cambian las probabilidades posteriores de cada moneda?\nIncrementa el número de volados, por ejemplo a 10. ¿Qué pasa si observaste 8 soles, por ejemplo? ¿Y si observaste 0?\n¿Qué pasa si cambias las probabilidades iniciales (por ejemplo incrementas la probabilidad inicial de la moneda 1 a 0.9)?\n\n\n\nJustifica las siguientes aseveraciones (para este ejemplo):\n\n\n\n\n\n\nTip\n\n\n\n\nLas probabilidades posteriores o finales son una especie de punto intermedio entre verosimilitud y probablidades iniciales.\nSi tenemos pocas observaciones, las probabilidades posteriores son similares a las iniciales.\nCuando tenemos muchos datos, las probabilidades posteriores están más concentradas, y no es tan importante la inicial.\nSi la inicial está muy concentrada en algún valor, la posterior requiere de muchas observaciones para que se pueda concentrar en otros valores diferentes a los de la inicial.\n\n\n\nAhora resumimos los elementos básicos de la inferencia bayesiana, que son relativamente simples:\n\n\n\n\n\n\nInferencia bayesiana.\n\n\n\nCon la notación de arriba:\n\nComo \\(X\\) son los datos observados, llamamos a \\(P(X|\\theta)\\) la verosimilitud, proceso generador de datos o modelo de los datos.\nEl factor \\(P(\\theta)\\) le llamamos la distribución inicial o previa.\nLa distribución que usamos para hacer inferencia \\(P(\\theta|X)\\) es la distribución final o posterior\n\nHacemos inferencia usando la ecuación\n\\[P(\\theta | X) = \\frac{P(X | \\theta) P(\\theta)}{P(X)}\\]\nque también escribimos:\n\\[P(\\theta | X) \\propto P(X | \\theta) P(\\theta)\\]\ndonde \\(\\propto\\) significa “proporcional a”. No ponemos \\(P(X)\\) pues como vimos arriba, es una constante de normalización.\n\n\nEn estadística Bayesiana, las probablidades posteriores \\(P(\\theta|X)\\) dan toda la información que necesitamos para hacer inferencia. ¿Cuándo damos probablidad alta a un parámetro particular \\(\\theta\\)? Cuando su verosimilitud es alta y/o cuando su probabilidad inicial es alta. De este modo, la posterior combina la información inicial que tenemos acerca de los parámetros con la información en la muestra acerca de los parámetros (verosimilitud). Podemos ilustrar como sigue:"
  },
  {
    "objectID": "modelos-bayesianos.html#ejemplo-estimando-una-proporción",
    "href": "modelos-bayesianos.html#ejemplo-estimando-una-proporción",
    "title": "7  Inferencia bayesiana",
    "section": "Ejemplo: estimando una proporción",
    "text": "Ejemplo: estimando una proporción\nRegresamos ahora a nuestro problema de estimar una proporción \\(\\theta\\) de una población dada usando una muestra iid \\(X_1,X_2,\\ldots, X_n\\) de variables Bernoulli. Ya sabemos calcular la verosimilitud (el modelo de los datos):\n\\[P(X_1=x_1,X_2 =x_2,\\ldots, X_n=x_n|\\theta) = \\theta^k(1-\\theta)^{n-k},\\]\ndonde \\(k = x_1 + x_2 +\\cdots + x_k\\) es el número de éxitos que observamos.\nAhora necesitamos una distribución inicial o previa \\(P(\\theta)\\). Aunque esta distribución puede tener cualquier forma, supongamos que nuestro conocimiento actual podemos resumirlo con una distribución \\(\\mathsf{Beta}(3, 3)\\):\n\\[P(\\theta) \\propto \\theta^2(1-\\theta)^2.\\]\nLa constante de normalización es 1/30, pero no la requerimos. Podemos simular para examinar su forma:\n\n\nCódigo\nsim_inicial <- tibble(theta = rbeta(10000, 3, 3))\nggplot(sim_inicial) + geom_histogram(aes(x = theta, y = ..density..), bins = 15)\n\n\n\n\n\nDe modo que nuestra información inicial es que la proporción puede tomar cualquier valor entre 0 y 1, pero es probable que tome un valor no tan lejano de 0.5. Por ejemplo, con probabilidad 0.95 creemos que \\(\\theta\\) está en el intervalo\n\n\nCódigo\nquantile(sim_inicial$theta, c(0.025, 0.975)) %>% round(2)\n\n\n 2.5% 97.5% \n 0.15  0.85 \n\n\nEs difícil justificar en abstracto por qué escogeriamos una inicial con esta forma. Aunque esto los detallaremos más adelante, puedes pensar, por el momento, que alguien observó algunos casos de esta población, y quizá vio tres éxitos y tres fracasos. Esto sugeriría que es poco probable que la probablidad \\(\\theta\\) sea muy cercana a 0 o muy cercana a 1.\nAhora podemos construir nuestra posterior. Tenemos que\n\\[P(\\theta| X_1=x_1, \\ldots, X_n=x_n) \\propto P(X_1 = x_1,\\ldots X_n=x_n | \\theta)P(\\theta) = \\theta^{k+2}(1-\\theta)^{n-k + 2}\\]\ndonde la constante de normalización no depende de \\(\\theta\\). Como \\(\\theta\\) es un parámetro continuo, la expresión de la derecha nos debe dar una densidad posterior.\nSupongamos entonces que hicimos la prueba con \\(n = 30\\) (número de prueba) y observamos 19 éxitos. Tendríamos entonces\n\\[P(\\theta | S_n = 19) \\propto \\theta^{19 + 2} (1-\\theta)^{30 - 19 +2} = \\theta^{21}(1-\\theta)^{13}\\]\nLa cantidad de la derecha, una vez que normalizemos por el número \\(P(X=19)\\), nos dará una densidad posterior (tal cual, esta expresion no integra a 1). Podemos obtenerla usando cálculo, pero recordamos que una distribución \\(\\mathsf{\\mathsf{Beta}}(a,b)\\) tiene como fórmula\n\\[\\frac{1}{B(a,b)} \\theta^{a-1}(1-\\theta)^{b-1}\\]\nConcluimos entonces que la posterior tiene una distribución \\(\\mathsf{Beta}(22, 14)\\). Podemos simular de la posterior usando código estándar para ver cómo luce:\n\n\nCódigo\nsim_inicial <- sim_inicial %>% mutate(dist = \"inicial\")\nsim_posterior <- tibble(theta = rbeta(10000, 22, 14)) %>% mutate(dist = \"posterior\")\nsims <- bind_rows(sim_inicial, sim_posterior)\nggplot(sims, aes(x = theta, fill = dist)) +\n  geom_histogram(aes(x = theta), bins = 30, alpha = 0.5, position = \"identity\")\n\n\n\n\n\nLa posterior nos dice cuáles son las posibilidades de dónde puede estar el parámetro \\(\\theta\\). Nótese que ahora excluye prácticamente valores más chicos que 0.25 o mayores que 0.9. Esta distribución posterior es el objeto con el que hacemos inferencia: nos dice dónde es creíble que esté el parámetro \\(\\theta\\).\nPodemos resumir de varias maneras. Por ejemplo, si queremos un estimador puntual usamos la media posterior:\n\n\nCódigo\nsims %>% group_by(dist) %>%\n  summarise(theta_hat = mean(theta) %>% round(3))\n\n\n# A tibble: 2 × 2\n  dist      theta_hat\n  <chr>         <dbl>\n1 inicial       0.502\n2 posterior     0.611\n\n\nNota que el estimador de máxima verosimilitud es \\(\\hat{p} = 19/30 = 0.63\\), que es ligeramente diferente de la media posterior. ¿Por qué?\nY podemos construir intervalos de percentiles, que en esta situación suelen llamarse intervalos de credibilidad, por ejemplo:\n\n\nCódigo\nf <- c(0.025, 0.975)\nsims %>% group_by(dist) %>%\n  summarise(cuantiles = quantile(theta, f) %>% round(2), f = f) %>%\n  pivot_wider(names_from = f, values_from = cuantiles)\n\n\n`summarise()` has grouped output by 'dist'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 2 × 3\n# Groups:   dist [2]\n  dist      `0.025` `0.975`\n  <chr>       <dbl>   <dbl>\n1 inicial      0.15    0.85\n2 posterior    0.45    0.76\n\n\nEl segundo renglón nos da un intervalo posterior para \\(\\theta\\) de credibilidad 95%. En inferencia bayesiana esto sustituye a los intervalos de confianza.\n\nEl intervalo de la inicial expresa nuestras creencias a priori acerca de \\(\\theta\\). Este intervalo es muy amplio (va de 0.15 a 0.85)\nEl intervalo de la posterior actualiza nuestras creencias acerca de \\(\\theta\\) una vez que observamos los datos, y es considerablemente más angosto y por lo tanto informativo.\n\nObservaciones:\n\nNótese que escogimos una forma analítica fácil para la inicial, pues resultó así que la posterior es una distribución beta. No siempre es así, y veremos qué hacer cuando nuestra inicial no es de un tipo “conveniente”.\nComo tenemos la forma analítica de la posterior, es posible hacer los cálculos de la media posterior, por ejemplo, integrando la densidad posterior a mano. Esto generalmente no es factible, y en este ejemplo preferimos hacer una aproximación numérica. En este caso particular es posible usando cálculo, y sabemos que la media de una \\(\\mathsf{\\mathsf{Beta}}(a,b)\\) es \\(a/(a+b)\\), de modo que nuestra media posterior es\n\n\\[\\hat{\\mu} = (19 + 2)/(30 + 4) = 21/34 = 0.617 \\]\nque podemos interpretar como sigue: para calcular la media posterior, a nuestras \\(n\\) pruebas iniciales agregamos 4 pruebas adicionales fijas, con 2 éxitos y 2 fracasos, y calculamos la proporción usual de éxitos.\n\n\n\n\n\n\nTip\n\n\n\nRepite el análisis considerando en general \\(n\\) pruebas, con \\(k\\) éxitos. Utiliza la misma distribución inicial.\n\n\n\nLo mismo aplica para el intervalo de 95% (¿cómo se calcularía integrando?). También puedes usar la aproximación de R, por ejemplo:\n\n\n\nCódigo\nqbeta(0.025, shape1 = 22, shape2 = 14) %>% round(2)\n\n\n[1] 0.45\n\n\nCódigo\nqbeta(0.975, shape1 = 22, shape2 = 14) %>% round(2)\n\n\n[1] 0.76"
  },
  {
    "objectID": "modelos-bayesianos.html#ejemplo-observaciones-uniformes",
    "href": "modelos-bayesianos.html#ejemplo-observaciones-uniformes",
    "title": "7  Inferencia bayesiana",
    "section": "Ejemplo: observaciones uniformes",
    "text": "Ejemplo: observaciones uniformes\nAhora regresamos al problema de estimación del máximo de una distribución uniforme. En este caso, consideraremos un problema más concreto. Supongamos que hay una lotería (tipo tradicional) en México y no sabemos cuántos números hay. Obtendremos una muestra iid de \\(n\\) números, ya haremos una aproximación continua, suponiendo que\n\\[X_i \\sim U[0,\\theta]\\]\nLa verosimilitud es entonces\n\\[P(X_1,\\ldots, X_n|\\theta) = \\theta^{-n},\\]\ncuando \\(\\theta\\) es mayor que todas las \\(X_i\\), y cero en otro caso. Necesitaremos una inicial \\(P(\\theta)\\).\nPor la forma que tiene la verosimilitud, podemos intentar una distribución Pareto, que tiene la forma\n\\[P(\\theta) = \\frac{\\alpha \\theta_0^\\alpha}{\\theta^{\\alpha + 1}}\\]\ncon soporte en \\([\\theta_0,\\infty]\\). Tenemos que escoger entonces el mínimo \\(\\theta_0\\) y el parámetro \\(\\alpha\\). En primer lugar, como sabemos que es una lotería nacional, creemos que no puede haber menos de unos 300 mil números, así que \\(\\theta_0 = 300\\). La función acumulada de la pareto es \\(1- (300/\\theta)^\\alpha\\), así que el cuantil 99% es\n\n\nCódigo\nalpha <- 1.1\n(300/(0.01)^(1/alpha))\n\n\n[1] 19738\n\n\nes decir, alrededor de 20 millones de números. Creemos que es un poco probable que el número de boletos sea mayor a esta cota. Nótese ahora que la posterior cumple (multiplicando verosimilitud por inicial):\n\\[P(\\theta|X_1,\\ldots, X_n |\\theta) \\propto \\theta^{-(n + 2.1)}\\]\npara \\(\\theta\\) mayor que el máximo de las \\(X_n\\)’s y 300, y cero en otro caso. Esta distribución es pareto con \\(\\theta_0' = \\max\\{300, X_1,\\ldots, X_n\\}\\) y \\(\\alpha = n + 1.1\\)\nUna vez planteado nuestro modelo, veamos los datos. Obtuvimos la siguiente muestra de números:\n\n\nCódigo\nloteria_tbl <- read_csv(\"datos/nums_loteria_avion.csv\", col_names = c(\"id\", \"numero\")) %>%\n  mutate(numero = as.integer(numero))\n\n\nRows: 99 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): numero\ndbl (1): id\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCódigo\nset.seed(334)\nmuestra_loteria <- sample_n(loteria_tbl, 25) %>%\n  mutate(numero = numero/1000)\nmuestra_loteria %>% as.data.frame %>% head\n\n\n  id   numero\n1 87  348.341\n2  5 5851.982\n3 40 1891.786\n4 51 1815.455\n5 14 5732.907\n6 48 3158.414\n\n\nPodemos simular de una Pareto como sigue:\n\n\nCódigo\nrpareto <- function(n, theta_0, alpha){\n  # usar el método de inverso de distribución acumulada\n  u <- runif(n, 0, 1)\n  theta_0 / (1 - u)^(1/alpha)\n}\n\n\nSimulamos de la inicial:\n\n\nCódigo\nsims_pareto_inicial <- tibble(\n  theta = rpareto(20000, 300, 1.1 ),\n  dist = \"inicial\")\n\n\nY con los datos de la muestra, simulamos de la posterior:\n\n\nCódigo\nsims_pareto_posterior <- tibble(\n  theta = rpareto(20000,\n                  max(c(300, muestra_loteria$numero)),\n                  nrow(muestra_loteria) + 1.1),\n  dist = \"posterior\")\nsims_theta <- bind_rows(sims_pareto_inicial, sims_pareto_posterior)\nggplot(sims_theta) +\n  geom_histogram(aes(x = theta, fill = dist),\n                 bins = 70, alpha = 0.5, position = \"identity\",\n                 boundary = max(muestra_loteria$numero))  +\n  xlim(0, 15000) + scale_y_sqrt() +\n  geom_rug(data = muestra_loteria, aes(x = numero))\n\n\nWarning: Removed 273 rows containing non-finite values (stat_bin).\n\n\nWarning: Removed 4 rows containing missing values (geom_bar).\n\n\n\n\n\nNótese que cortamos algunos valores de la inicial en la cola derecha: un defecto de esta distribución inicial, con una cola tan larga a la derecha, es que pone cierto peso en valores que son poco creíbles y la vuelve poco apropiada para este problema. Regresamos más adelante a este problema.\nSi obtenemos percentiles, obtenemos el intervalo\n\n\nCódigo\nf <- c(0.025, 0.5, 0.975)\nsims_theta %>% group_by(dist) %>%\n  summarise(cuantiles = quantile(theta, f) %>% round(2), f = f) %>%\n  pivot_wider(names_from = f, values_from = cuantiles)\n\n\n`summarise()` has grouped output by 'dist'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 2 × 4\n# Groups:   dist [2]\n  dist      `0.025` `0.5` `0.975`\n  <chr>       <dbl> <dbl>   <dbl>\n1 inicial      307.  569.   8449.\n2 posterior   5858. 6010.   6732.\n\n\nEstimamos entre 5.8 millones y 6.7 millones de boletos. El máximo en la muestra es de\n\n\nCódigo\nmax(muestra_loteria$numero)\n\n\n[1] 5851.982\n\n\nEscoger la distribución pareto como inicial es conveniente y nos permitió resolver el problema sin dificultad, pero por su forma vemos que no necesariamente es apropiada para el problema por lo que señalamos arriba. Nos gustaría, por ejemplo, poner una inicial como la siguiente\n\n\nCódigo\nqplot(rgamma(2000, 5, 0.001), geom=\"histogram\", bins = 20) +\n  scale_x_continuous(breaks = seq(1000, 15000, by = 2000))\n\n\n\n\n\nSin embargo, los cálculos no son tan simples en este caso, pues la posterior no tiene un forma reconocible. Tendremos que usar otras estrategias de simulación para ejemplos como este (Monte Carlo por medio de Cadenas de Markov, que veremos más adelante)."
  },
  {
    "objectID": "modelos-bayesianos.html#probabilidad-a-priori",
    "href": "modelos-bayesianos.html#probabilidad-a-priori",
    "title": "7  Inferencia bayesiana",
    "section": "Probabilidad a priori",
    "text": "Probabilidad a priori\nLa inferencia bayesiana es conceptualmente simple: siempre hay que calcular la posterior a partir de verosimilitud (modelo de datos) y distribución inicial o a priori. Sin embargo, una crítica usual que se hace de la inferencia bayesiana es precisamente que hay que tener esa información inicial, y que distintos analistas llegan a distintos resultados si tienen información inicial distinta.\nEso realmente no es un defecto, es una ventaja de la inferencia bayesiana. Los datos y los problemas que queremos resolver no viven en un vacío donde podemos creer que la estatura de las personas, por ejemplo, puede variar de 0 a mil kilómetros, el número de boletos de una lotería puede ir de 2 o 3 boletos o también quizá 500 millones de boletos, o la proporción de personas infectadas de una enfermedad puede ser de unos cuantos hasta miles de millones.\n\nEn todos estos casos tenemos cierta información inicial que podemos usar para informar nuestras estimaciones. Esta información debe usarse.\nAntes de tener datos, las probabilidades iniciales deben ser examinadas en términos del conocimiento de expertos.\nLas probabilidades iniciales son supuestos que hacemos acerca del problema de interés, y también están sujetas a críticas y confrontación con datos."
  },
  {
    "objectID": "modelos-bayesianos.html#análisis-conjugado",
    "href": "modelos-bayesianos.html#análisis-conjugado",
    "title": "7  Inferencia bayesiana",
    "section": "Análisis conjugado",
    "text": "Análisis conjugado\nLos dos ejemplos que hemos visto arriba son ejemplos de análisis conjugado:\n\n(Beta-bernoulli) Si las observaciones \\(X_i\\) son \\(\\mathsf{Bernoulli}(p)\\) (\\(n\\) fija) queremos estimar \\(p\\), y tomamos como distribución inicial para \\(p\\) una \\(\\mathsf{Beta}(a,b)\\), entonces la posterior para \\(p\\) cuando \\(S_n=k\\) es \\(\\mathsf{Beta}(k + a, n - k + b)\\), donde \\(S_n = X_1 + X_2 +\\cdots +X_n\\).\n\nY más en general:\n\n(Beta-binomial) Si las observaciones \\(X_i, i=1,2,\\ldots, m\\) son \\(\\mathsf{Binomial}(n_i, p)\\) (\\(n_i\\)’s fijas) independientes, queremos estimar \\(p\\), y tomamos como distribución inicial para \\(p\\) una \\(\\mathsf{Beta}(a,b)\\), entonces la posterior para \\(p\\) cuando \\(S_m=k\\) es \\(\\mathsf{Beta}(k + a, n - k + b)\\), donde \\(S_m = X_1 + X_2 +\\cdots +X_m\\) y \\(n= n_1+n_2+\\cdots+n_m\\)\n\nTambién aplicamos:\n\n(Uniforme-Pareto) Si el modelo de datos \\(X_i\\) es uniforme \\(\\mathsf{U}[0,\\theta]\\) (\\(n\\) fija), queremos estimar \\(\\theta\\), y tomamos como distribución inicial para \\(\\theta\\) una Pareto \\((\\theta_0, \\alpha)\\), entonces la posterior para \\(p\\) si el máximo de las \\(X_i\\)’s es igual a \\(M\\) es Pareto con parámetros \\((\\max\\{\\theta_0, M\\}, \\alpha + n)\\).\n\nNótese que en estos casos, dada una forma de la verosimilitud, tenemos una familia conocida de iniciales tales que las posteriores están en la misma familia. Estos modelos son convenientes porque podemos hacer simulaciones de la posterior de manera fácil, o usar sus propiedades teóricas.\nOtro ejemplo típico es el modelo normal-normal:\n\n(Normal-normal) Si \\(X_i\\sim \\mathsf{N}(\\mu,\\sigma)\\), con \\(\\sigma\\) conocida, y tomamos como distribución inicial para \\(\\mu \\sim \\mathsf{N}(\\mu_0,\\sigma_0)\\), y definimos la precisión \\(\\tau\\) como el inverso de la varianza \\(\\sigma^2\\), entonces la posterior de \\(\\mu\\) es Normal con media \\((1-\\lambda) \\mu_0 + \\lambda\\overline{x}\\), y precisión \\(\\tau_0 + n\\tau\\), donde \\(\\lambda = \\frac{n\\tau}{\\tau_0 + n\\tau}\\)\n\nMás útil es el siguiente modelo:\n\n(Normal-Gamma inverso) Sean \\(X_i\\sim \\mathsf{N}(\\mu, \\sigma)\\). Queremos estimar \\(\\mu\\) y \\(\\sigma\\). Tomamos como distribuciones iniciales (dadas por 4 parámetros: \\(\\mu_0, n_0, \\alpha,\\beta\\)):\n\n\\(\\tau = \\frac{1}{\\sigma^2} \\sim \\mathsf{Gamma}(\\alpha,\\beta)\\)\n\\(\\mu|\\sigma\\) es normal con media \\(\\mu_0\\) y varianza \\(\\sigma^2 / {n_0}\\) , y\n\\(p(\\mu, \\sigma) = p(\\mu|\\sigma)p(\\sigma)\\)\n\nEntonces la posterior es:\n\n\\(\\tau|x\\) es \\(\\mathsf{Gamma}(\\alpha', \\beta')\\), con \\(\\alpha' = \\alpha + n/2\\), \\(\\beta' = \\beta + \\frac{1}{2}\\sum_{i=1}^{n}(x_{i} - \\bar{x})^2 + \\frac{nn_0}{n+n_0}\\frac{({\\bar{x}}-\\mu_{0})^2}{2}\\)\n\\(\\mu|\\sigma,x\\) es normal con media \\(\\mu' = \\frac{n_0\\mu_{0}+n{\\bar{x}}}{n_0 +n}\\) y varianza $ ^2/({n_0 +n})$.\n\\(p(\\mu,\\sigma|x) = p(\\mu|x,\\sigma)p(\\sigma|x)\\)\n\n\nObservaciones\n\nNótese que este último ejemplo tienen más de un parámetro. En estos casos, el objeto de interés es la posterior conjunta de los parámetros \\(p(\\theta_1,\\theta_2,\\cdots, \\theta_p|x)\\). Este último ejemplo es relativamente simple pues por la selección de iniciales, para simular de la conjunta de \\(\\mu\\) y \\(\\tau\\) podemos simular primero \\(\\tau\\) (o \\(\\sigma\\)), y después usar este valor para simular de \\(\\mu\\): el par de valores resultantes son una simulación de la conjunta.\nLos parámetros \\(a,b\\) para la inicial de \\(\\tau\\) pueden interpretarse como sigue: \\(\\sqrt{b/a}\\) es un valor “típico” a priori para la varianza poblacional, y \\(a\\) indica qué tan seguros estamos de este valor típico.\nNótese que para que funcionen las fórmulas de la manera más simple, escogimos una dependencia a priori entre la media y la precisión: \\(\\tau = \\sigma^{-2}\\) indica la escala de variabilidad que hay en la población, la incial de la media tiene varianza \\(\\sigma^2/n_0\\). Si la escala de variabilidad de la población es más grande, tenemos más incertidumbre acerca de la localización de la media.\nAunque esto tiene sentido en algunas aplicaciones, y por convenviencia usamos esta familia conjugada, muchas veces es preferible otro tipo de especificaciones para las iniciales: por ejemplo, la media normal y la desviación estándar uniforme, o media normal, con iniciales independientes. Sin embargo, estos casos no son tratables con análisis conjugado (veremos más adelante cómo tratarlos con MCMC).\n\n\nEjemplo\nSupongamos que queremos estimar la estatura de los cantantes de tesitura tenor con una muestra iid de tenores de Estados Unidos. Usaremos el modelo normal de forma que \\(X_i\\sim \\mathsf{N}(\\mu, \\sigma^2)\\).\nUna vez decidido el modelo, tenemos que poner distribución inicial para los parámetros \\((\\mu, \\sigma^2)\\).\nComenzamos con \\(\\sigma^2\\). Como está el modelo, esta inicial debe estar dada para la precisión \\(\\tau\\), pero podemos simular para ver cómo se ve nuestra inicial para la desviación estándar. En la población general la desviación estándar es alrededor de 7 centímetros\n\n\nCódigo\n# Comenzamos seleccionando un valor que creemos típico para la desviación estándar\nsigma_0 <- 7\n# seleccionamos un valor para a, por ejemplo: si es más chico sigma tendrá más\n# disperisón\na <- 3\n# ponemos 8 = sqrt(b/a) -> b = a * 64\nb <- a * sigma_0^2\nc(a = a, b = b)\n\n\n  a   b \n  3 147 \n\n\nAhora simulamos para calcular cuantiles\n\n\nCódigo\ntau <- rgamma(1000, a, b)\nquantile(tau, c(0.05, 0.95))\n\n\n         5%         95% \n0.005781607 0.042170161 \n\n\nCódigo\nsigma <- 1 / sqrt(tau)\nmean(sigma)\n\n\n[1] 8.002706\n\n\nCódigo\nquantile(sigma, c(0.05, 0.95))\n\n\n       5%       95% \n 4.869653 13.151520 \n\n\nQue es dispersión considerable: con poca probabilidad la desviación estándar es menor a 4 centímetros, y también creemos que es poco creíble la desviación estándar sea de más de 13 centímetros.\nComenzamos con \\(\\mu\\). Sabemos, por ejemplo, que con alta probabilidad la media debe ser algún número entre 1.60 y 1.80. Podemos investigar: la media nacional en estados unidos está alrededor de 1.75, y el percentil 90% es 1.82. Esto es variabilidad en la población: debe ser muy poco probable, por ejemplo, que la media de tenores sea 1.82 Quizá los cantantes tienden a ser un poco más altos o bajos que la población general, así que podríamos agregar algo de dispersión.\nPodemos establecer parámetros y simular de la marginal a partir de las fórmulas de arriba para entender cómo se ve la inicial de \\(\\mu\\):\n\n\nCódigo\nmu_0 <- 175 # valor medio de inicial\nn_0 <- 5 # cuánta concentración en la inicial\ntau <- rgamma(1000, a,b)\nsigma <- 1/sqrt(tau)\nmu <- map_dbl(sigma, ~ rnorm(1, mu_0, .x / sqrt(n_0)))\nquantile(mu, c(0.05, 0.5, 0.95))\n\n\n      5%      50%      95% \n168.7275 174.8412 180.7905 \n\n\nQue consideramos un rango en el que con alta probabilidad debe estar la media poblacional de los cantantes.\nPodemos checar nuestros supuestos simulando posibles muestras usando sólo nuestra información previa:\n\n\nCódigo\nsimular_normal_invgamma <- function(n, pars){\n  mu_0 <- pars[1]\n  n_0 <- pars[2]\n  a <- pars[3]\n  b <- pars[4]\n  # simular media\n  tau <- rgamma(1, a, b)\n  sigma <- 1 / sqrt(tau)\n  mu <- rnorm(1, mu_0, sigma/sqrt(n_0))\n  # simular sigma\n  rnorm(n, mu, sigma)\n}\nset.seed(3461)\nsims_tbl <- tibble(rep = 1:20) %>%\n  mutate(estatura = map(rep, ~ simular_normal_invgamma(500, c(mu_0, n_0, a, b)))) %>%\n  unnest(cols = c(estatura))\nggplot(sims_tbl, aes(x = estatura)) + geom_histogram() +\n  facet_wrap(~ rep) +\n  geom_vline(xintercept = c(150, 180), colour = \"red\")\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nPusimos líneas de referencia en 150 y 180. Vemos que nuestras iniciales no producen simulaciones totalmente fuera del contexto, y parecen cubrir apropiadamente el espacio de posiblidades para estaturas de los tenores. Quizá hay algunas realizaciones poco creíbles, pero no extremadamente. En este punto, podemos regresar y ajustar la inicial para \\(\\sigma\\), que parece tomar valores demasiado grandes (produciendo por ejemplo una simulación con estatura de 220 y 140, que deberían ser menos probables).\nAhora podemos usar los datos para calcular nuestras posteriores.\n\n\nCódigo\nset.seed(3413)\ncantantes <- lattice::singer %>%\n  mutate(estatura_cm = round(2.54 * height)) %>%\n  filter(str_detect(voice.part, \"Tenor\")) %>%\n  sample_n(20)\ncantantes\n\n\n    height voice.part estatura_cm\n139     70    Tenor 1         178\n150     68    Tenor 2         173\n140     65    Tenor 1         165\n132     66    Tenor 1         168\n152     69    Tenor 2         175\n141     72    Tenor 1         183\n161     71    Tenor 2         180\n156     71    Tenor 2         180\n158     71    Tenor 2         180\n164     69    Tenor 2         175\n147     68    Tenor 1         173\n130     72    Tenor 1         183\n162     71    Tenor 2         180\n134     74    Tenor 1         188\n170     69    Tenor 2         175\n167     68    Tenor 2         173\n149     64    Tenor 1         163\n143     68    Tenor 1         173\n157     69    Tenor 2         175\n153     71    Tenor 2         180\n\n\nLos cálculos son un poco tediosos, pero podemos construir una función apropiada:\n\n\nCódigo\ncalcular_pars_posterior <- function(x, pars_inicial){\n  # iniciales\n  mu_0 <- pars_inicial[1]\n  n_0 <- pars_inicial[2]\n  a_0 <- pars_inicial[3]\n  b_0 <- pars_inicial[4]\n  # muestra\n  n <- length(x)\n  media <- mean(x)\n  S2 <- sum((x - media)^2)\n  # sigma post\n  a_1 <- a_0 + 0.5 * n\n  b_1 <- b_0 + 0.5 * S2 + 0.5 * (n * n_0) / (n + n_0) * (media - mu_0)^2\n  # posterior mu\n  mu_1 <- (n_0 * mu_0 + n * media) / (n + n_0)\n  n_1 <- n + n_0\n  c(mu_1, n_1, a_1, b_1)\n}\npars_posterior <- calcular_pars_posterior(cantantes$estatura_cm, c(mu_0, n_0, a, b))\npars_posterior\n\n\n[1] 175.8  25.0  13.0 509.0\n\n\n¿Cómo se ve nuestra posterior comparada con la inicial? Podemos hacer simulaciones:\n\n\nCódigo\nsim_params <- function(m, pars){\n  mu_0 <- pars[1]\n  n_0 <- pars[2]\n  a <- pars[3]\n  b <- pars[4]\n  # simular sigmas\n  sims <- tibble(tau = rgamma(m, a, b)) %>%\n    mutate(sigma = 1 / sqrt(tau))\n  # simular mu\n  sims <- sims %>% mutate(mu = rnorm(m, mu_0, sigma / sqrt(n_0)))\n  sims\n}\nsims_inicial <- sim_params(5000, c(mu_0, n_0, a, b)) %>%\n  mutate(dist = \"inicial\")\nsims_posterior <- sim_params(5000, pars_posterior) %>%\n  mutate(dist = \"posterior\")\nsims <- bind_rows(sims_inicial, sims_posterior)\nggplot(sims, aes(x = mu, y = sigma, colour = dist)) +\n  geom_point()\n\n\n\n\n\nY vemos que nuestra posterior es consistente con la información inicial que usamos, hemos aprendido considerablemente de la muestra. La posterior se ve como sigue. Hemos marcado también las medias posteriores de cada parámetro: media y desviación estándar.\n\n\nCódigo\nmedias_post <- sims %>% filter(dist == \"posterior\") %>%\n  select(-dist) %>%\n  summarise(across(everything(), mean))\nggplot(sims %>% filter(dist == \"posterior\"),\n    aes(x = mu, y = sigma)) +\n  geom_point(colour = \"#00BFC4\") +\n  geom_point(data = medias_post, size = 5, colour = \"black\") +\n  coord_equal()\n\n\n\n\n\nPodemos construir intervalos creíbles del 90% para estos dos parámetros, por ejemplo haciendo intervalos de percentiles:\n\n\nCódigo\nf <- c(0.05, 0.5, 0.95)\nsims %>%\n  pivot_longer(cols = mu:sigma, names_to = \"parametro\") %>%\n  group_by(dist, parametro) %>%\n  summarise(cuantil = quantile(value, f) %>% round(1), f= f) %>%\n  pivot_wider(names_from = f, values_from = cuantil)\n\n\n`summarise()` has grouped output by 'dist', 'parametro'. You can override using\nthe `.groups` argument.\n\n\n# A tibble: 4 × 5\n# Groups:   dist, parametro [4]\n  dist      parametro `0.05` `0.5` `0.95`\n  <chr>     <chr>      <dbl> <dbl>  <dbl>\n1 inicial   mu         169.  175.   181. \n2 inicial   sigma        4.8   7.4   13.3\n3 posterior mu         174.  176.   178. \n4 posterior sigma        5.1   6.3    8.2\n\n\nComo comparación, los estimadores de máxima verosimlitud son\n\n\nCódigo\nmedia_mv <- mean(cantantes$estatura_cm)\nsigma_mv <- mean((cantantes$estatura_cm - media_mv)^2) %>% sqrt\nc(media_mv, sigma_mv)\n\n\n[1] 176   6\n\n\nAhora solo resta checar que el modelo es razonable. Veremos más adelante cómo hacer esto, usando la distribución predictiva posterior."
  },
  {
    "objectID": "modelos-bayesianos.html#pasos-de-un-análisis-de-datos-bayesiano",
    "href": "modelos-bayesianos.html#pasos-de-un-análisis-de-datos-bayesiano",
    "title": "7  Inferencia bayesiana",
    "section": "Pasos de un análisis de datos bayesiano",
    "text": "Pasos de un análisis de datos bayesiano\n\n\n\n\n\n\nTip\n\n\n\nComo vimos en los ejemplos, en general un análisis de datos bayesiano sigue los siguientes pasos:\n\nIdentificar los datos releventes a nuestra pregunta de investigación, el tipo de datos que vamos a describir, que variables queremos estimar.\nDefinir el modelo descriptivo para los datos. La forma matemática y los parámetros deben ser apropiados para los objetivos del análisis.\nEspecificar la distribución inicial de los parámetros.\nUtilizar inferencia bayesiana para reubicar la credibilidad a lo largo de los posibles valores de los parámetros.\nVerificar que la distribución posterior replique los datos de manera razonable, de no ser el caso considerar otros modelos descriptivos para los datos.\n\n\n\n\nElicitando probablidades subjetivas (opcional)\nNo siempre es fácil elicitar probabilidades subjetivas de manera que capturemos el verdadero conocimiento de dominio que tenemos. Una manera clásica de hacerlo es con apuestas\nConsidera una pregunta sencilla que puede afectar a un viajero: ¿Qué tanto crees que habrá una tormenta que ocasionará el cierre de la autopista México-Acapulco en el puente del \\(20\\) de noviembre? Como respuesta debes dar un número entre \\(0\\) y \\(1\\) que refleje tus creencias. Una manera de seleccionar dicho número es calibrar las creencias en relación a otros eventos cuyas probabilidades son claras.\nComo evento de comparación considera una experimento donde hay canicas en una urna: \\(5\\) rojas y \\(5\\) blancas. Seleccionamos una canica al azar. Usaremos esta urna como comparación para considerar la tormenta en la autopista. Ahora, considera el siguiente par de apuestas de las cuales puedes elegir una:\n\nA. Obtienes \\(\\$1000\\) si hay una tormenta que ocasiona el cierre de la autopista el próximo \\(20\\) de noviembre.\nB. Obtienes \\(\\$1000\\) si seleccionas una canica roja de la urna que contiene \\(5\\) canicas rojas y \\(5\\) blancas.\n\nSi prefieres la apuesta B, quiere decir que consideras que la probabilidad de tormenta es menor a \\(0.5\\), por lo que al menos sabes que tu creencia subjetiva de una la probabilidad de tormenta es menor a \\(0.5\\). Podemos continuar con el proceso para tener una mejor estimación de la creencia subjetiva.\n\nA. Obtienes \\(\\$1000\\) si hay una tormenta que ocasiona el cierre de la autopista el próximo \\(20\\) de noviembre.\nC. Obtienes \\(\\$1000\\) si seleccionas una canica roja de la urna que contiene \\(1\\) canica roja y \\(9\\) blancas.\n\nSi ahora seleccionas la apuesta \\(A\\), esto querría decir que consideras que la probabilidad de que ocurra una tormenta es mayor a \\(0.10\\). Si consideramos ambas comparaciones tenemos que tu probabilidad subjetiva se ubica entre \\(0.1\\) y \\(0.5\\)."
  },
  {
    "objectID": "modelos-bayesianos.html#verificación-predictiva-posterior",
    "href": "modelos-bayesianos.html#verificación-predictiva-posterior",
    "title": "7  Inferencia bayesiana",
    "section": "Verificación predictiva posterior",
    "text": "Verificación predictiva posterior\nUna vez que ajustamos un modelo bayesiano, podemos simular nuevas observaciones a partir del modelo. Esto tiene dos utilidades:\n\nHacer predicciones acerca de datos no observados.\nConfirmar que nuevas producidas simuladas con el modelo son similares a las que de hecho observamos. Esto nos permite confirmar la calidad del ajuste del modelo, y se llama verificación predictiva posterior.\n\nSupongamos que tenemos la posterior \\(p(\\theta | x)\\). Podemos generar una nueva replicación de los datos como sigue:\nLa distribución predictiva posterior genera nuevas observaciones a partir de la información observada. La denotamos como \\(p(\\tilde{x}|x)\\).\nPara simular de ella:\n\nMuestreamos un valor \\(\\tilde{\\theta}\\) de la posterior \\(p(\\theta|x)\\).\nSimulamos del modelo de las observaciones \\(\\tilde{x} \\sim p(\\tilde{x}|\\tilde{\\theta})\\).\nRepetimos el proceso hasta obtener una muestra grande.\nUsamos este método para producir, por ejemplo, intervalos de predicción para nuevos datos.\n\nSi queremos una replicación de las observaciones de la predictiva posterior,\n\nMuestreamos un valor \\(\\tilde{\\theta}\\) de la posterior \\(p(\\theta|x)\\).\nSimulamos del modelo de las observaciones \\(\\tilde{x}_1, \\tilde{x}_2,\\ldots, \\tilde{x}_n \\sim p(\\tilde{x}|\\tilde{\\theta})\\), done \\(n\\) es el tamaño de muestra de la muestra original \\(x\\).\nUsamos este método para producir conjuntos de datos simulados que comparamos con los observados para verificar nuestro modelo.\n\n\nEjemplo: estaturas de tenores\nEn este ejemplo, usaremos la posterior predictiva para checar nuestro modelo. Vamos a crear varias muestras, del mismo tamaño que la original, según nuestra predictiva posterior, y compararemos estas muestras con la observada.\nY ahora simulamos otra muestra\n\n\nCódigo\nmuestra_sim <- simular_normal_invgamma(20, pars_posterior)\nmuestra_sim %>% round(0)\n\n\n [1] 167 181 184 181 167 167 172 170 177 172 169 174 182 184 176 171 175 176 168\n[20] 181\n\n\nPodemos simular varias muestras y hacer una prueba de lineup:\n\n\nCódigo\nlibrary(nullabor)\nsims_obs <- tibble(.n = 1:19) %>%\n  mutate(estatura_cm = map(.n, ~ simular_normal_invgamma(20, pars_posterior))) %>%\n  unnest(estatura_cm)\nset.seed(9921)\npos <- sample(1:20, 1)\nlineup_tbl <- lineup(true = cantantes %>% select(estatura_cm),\n                     samples = sims_obs, pos = pos)\nggplot(lineup_tbl, aes(x = estatura_cm)) + geom_histogram(binwidth = 2.5) +\n  facet_wrap(~.sample)\n\n\n\n\n\nCon este tipo de gráficas podemos checar desajustes potenciales de nuestro modelo.\n\n¿Puedes encontrar los datos verdaderos? ¿Cuántos seleccionaron los datos correctos?\nPrueba hacer pruebas con una gráfica de cuantiles. ¿Qué problema ves y cómo lo resolverías?\n\n\n\nEjemplo: modelo Poisson\nSupongamos que pensamos el modelo para las observaciones es Poisson con parámetro \\(\\lambda\\). Pondremos como inicial para \\(\\lambda\\) una exponencial con media 10.\nNótese que la posterior está dada por\n\\[p(\\lambda|x_1,\\ldots, x_n) \\propto e^{-n\\lambda}\\lambda^{\\sum_i x_i} e^{-0.1\\lambda} = \\lambda^{n\\overline{x}}e^{-\\lambda(n + 0.1)}\\]\nque es una distribución gamma con parámetros \\((n\\overline{x} + 1, n+0.1)\\)\nAhora supongamos que observamos la siguiente muestra, ajustamos nuestro modelo y hacemos replicaciones posteriores de los datos observados:\n\n\nCódigo\nx <- rnbinom(250, mu = 20, size = 3)\ncrear_sim_rep <- function(x){\n  n <- length(x)\n  suma <- sum(x)\n  sim_rep <- function(rep){\n    lambda <- rgamma(1, sum(x) + 1, n + 0.1)\n    x_rep <- rpois(n, lambda)\n    tibble(rep = rep, x_rep = x_rep)\n  }\n}\nsim_rep <- crear_sim_rep(x)\nlineup_tbl <- map(1:5, ~ sim_rep(.x)) %>%\n  bind_rows() %>%\n  bind_rows(tibble(rep = 6, x_rep = x))\nggplot(lineup_tbl, aes(x = x_rep)) +\n  geom_histogram(bins = 15) +\n  facet_wrap(~rep)\n\n\n\n\n\nY vemos claramente que nuestro modelo no explica apropiadamente la variación de los datos observados. Contrasta con:\n\n\nCódigo\nset.seed(223)\nx <- rpois(250, 15)\ncrear_sim_rep <- function(x){\n  n <- length(x)\n  suma <- sum(x)\n  sim_rep <- function(rep){\n    lambda <- rgamma(1, sum(x) + 1, n + 0.1)\n    x_rep <- rpois(n, lambda)\n    tibble(rep = rep, x_rep = x_rep)\n  }\n}\nsim_rep <- crear_sim_rep(x)\nlineup_tbl <- map(1:5, ~ sim_rep(.x)) %>%\n  bind_rows() %>%\n  bind_rows(tibble(rep = 6, x_rep = x))\nggplot(lineup_tbl, aes(x = x_rep)) +\n  geom_histogram(bins = 15) +\n  facet_wrap(~rep)\n\n\n\n\n\nY verificamos que en este caso el ajuste del modelo es apropiado."
  },
  {
    "objectID": "modelos-bayesianos.html#predicción",
    "href": "modelos-bayesianos.html#predicción",
    "title": "7  Inferencia bayesiana",
    "section": "Predicción",
    "text": "Predicción\nCuando queremos hacer predicciones particulares acerca de datos que observemos en el futuro, también podemos usar la posterior predictiva. En este caso, tenemos que considerar\n\nLa variabilidad que produce la incertidumbre en la estimación de los parámetros\nLa variabilidad de las observaciones dados los parámetros.\n\nEs decir, tenemos que simular sobre todos las combinaciones factibles de los parámetros.\n\nEjemplo: cantantes\nSi un nuevo tenor llega a un coro, ¿cómo hacemos una predicción de su estatura? Como siempre, quisiéramos obtener un intervalo que exprese nuestra incertidumbre acerca del valor que vamos a observar. Entonces haríamos:\n\n\nCódigo\nsims_posterior <- sim_params(50000, pars_posterior) %>%\n  mutate(y_pred = rnorm(n(), mu, sigma))\nsims_posterior %>% head\n\n\n# A tibble: 6 × 4\n     tau sigma    mu y_pred\n   <dbl> <dbl> <dbl>  <dbl>\n1 0.0286  5.91  175.   181.\n2 0.0200  7.07  177.   178.\n3 0.0257  6.23  176.   170.\n4 0.0344  5.39  176.   174.\n5 0.0297  5.80  175.   169.\n6 0.0282  5.96  177.   170.\n\n\n\n\nCódigo\nf <- c(0.025, 0.5, 0.975)\nsims_posterior %>% summarise(f = f, y_pred = quantile(y_pred, f))\n\n\n# A tibble: 3 × 2\n      f y_pred\n  <dbl>  <dbl>\n1 0.025   163.\n2 0.5     176.\n3 0.975   189.\n\n\nY con esto obtenemos el intervalo (163, 189), al 95%, para una nueva observación. Nótese que este intervalo no puede construirse con una simulación particular de la posterior de los parámetros, pues sería demasiado corto.\nEs posible demostrar que en este caso, la posterior predictiva tiene una forma conocida:\n\nLa posterior predictiva para el modelo normal-gamma inverso es una distribución \\(t\\) con \\(2\\alpha'\\) grados de libertad, centrada en \\(\\mu'\\), y con escala \\(s^2 = \\frac{\\beta'}{\\alpha'}\\frac{n + n_0 + 1}{n +n_0}\\)\n\n\n\nCódigo\nmu_post <- pars_posterior[1]\nn_post <- pars_posterior[2]\nalpha_post <- pars_posterior[3]\nbeta_post <- pars_posterior[4]\ns <- sqrt(beta_post/alpha_post) * sqrt((n_post + 1)/n_post)\nqt(c(0.025, 0.5, 0.975), 2 * alpha_post) * s + mu_post\n\n\n[1] 162.6832 175.8000 188.9168\n\n\n\n\nEjemplo: posterior predictiva de Pareto-Uniforme.\nLa posterior predictiva del modelo Pareto-Uniforme no tiene un nombre estándar, pero podemos aproximarla usando simulación. Usando los mismos datos del ejercicio de la lotería, haríamos:\n\n\nCódigo\nrpareto <- function(n, theta_0, alpha){\n  # usar el método de inverso de distribución acumulada\n  u <- runif(n, 0, 1)\n  theta_0 / (1 - u)^(1/alpha)\n}\n# Simulamos de la posterior de los parámetros\nlim_inf_post <- max(c(300, muestra_loteria$numero))\nk_posterior <- nrow(muestra_loteria) + 1.1\nsims_pareto_posterior <- tibble(\n  theta = rpareto(100000, lim_inf_post, k_posterior))\n# Simulamos una observación para cada una de las anteriores:\nsims_post_pred <- sims_pareto_posterior %>%\n  mutate(x_pred = map_dbl(theta, ~ runif(1, 0, .x)))\n# Graficamos\nggplot(sims_post_pred, aes(x = x_pred)) +\n  geom_histogram(binwidth = 50) +\n  geom_vline(xintercept = lim_inf_post, colour = \"red\")\n\n\n\n\n\nQue es una mezcla de una uniforme con una Pareto.\n\n\n\n\nChihara, Laura M., y Tim C. Hesterberg. 2018. Mathematical Statistics with Resampling and R. 2.ª ed. Hoboken, NJ: John Wiley & Sons. https://sites.google.com/site/chiharahesterberg/home.\n\n\nKruschke, John. 2015. Doing Bayesian Data Analysis (Second Edition). Academic Press."
  }
]