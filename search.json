[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Pensamiento estadístico",
    "section": "",
    "text": "En casi todas las soluciones basadas en datos, los científicos de datos ejercen el pensamiento estadístico al diseñar estrategias de recopilación de datos, obtener evidencia para la toma de decisiones y construir modelos para predecir tendencias futuras.\nEste curso busca explicar los principios básicos de la estadística y su papel en el análisis de datos. Nuestro punto de vista es uno de fundamentos, con menos énfasis en recetas o técnicas particulares.\nEn particular, estudiaremos básicos de probabilidad, métodos basados en remuestreo, y en la parte final la filosofía de la inferencia bayesiana y las técnicas de modelado bayesiano utilizando estudios de casos ilustrativos.\n\n\n\nCiencia de datos y estadística. Intepretando datos y su proceso generador\nResúmenes y descripción para variables numéricas y categóricas\nPruebas de hipótesis\nEstimación por remuestreo (bootstrap)\nIntroducción a modelos de probabilidad\nEstimación por máxima verosimilitud y el bootstrap paramétrico\nIntroducción a inferencia bayesiana\n\n\n\n\n\n\nLicencia Creative Commons\n\n\nEste trabajo está bajo una licencia: Attribution-NonCommercial 4.0 International\nEres libre de adaptarlo para propósitos no comerciales otorgando el crédito correspondiente."
  },
  {
    "objectID": "01-intro-est-cd-1.html",
    "href": "01-intro-est-cd-1.html",
    "title": "Estadística y ciencia de datos",
    "section": "",
    "text": "La ciencia de datos antes se llamaba análisis de datos. Esto quiere decir que no ocurre en un espacio teórico o matemático, sino en aplicaciones específicas donde buscamos tomar decisiones informadas. A su vez, algunas personas consideran el análisis de datos como “estadística aplicada”.\nLa ciencia de datos, a diferencia del análisis de datos más tradicional, reconoce y adopta ideas de desarrollo de software e ingeniería que son relevantes para producir análisis y productos con buena calidad y desempeño.\n\nDesde este punto de vista, el estándar de validez más importante en la ciencia de datos (Tukey (1962)) es su funcionamiento en la práctica, y no la adherencia a argumentos teóricos, matemáticos o estadísticos.\nIgualmente puede ser difícil definir qué es la estadística (algunos la ven como una parte o rama de las matemáticas, en un extremo, y otros la consideran algo más cercano al análisis de datos). En cualquier caso:\n\nLa estadística puede considerarse como parte de la ciencia de datos. Sus resultados teóricos son guías y nos dan bases para juzgar y pensar en procedimientos para contestar preguntas con datos (Tukey (1962)).\n\n\n\n\n\nTukey, John W. 1962. «The Future of Data Analysis». Ann. Math. Statist. 33 (1): 1-67. https://doi.org/10.1214/aoms/1177704711."
  },
  {
    "objectID": "01-est-cd-1.html",
    "href": "01-est-cd-1.html",
    "title": "1  Preguntas y datos",
    "section": "",
    "text": "A grandes rasgos, cuanto más sepamos de este proceso, mejor podemos contestar preguntas de interés.\nEn muchos casos, tendremos que hacer algunos supuestos de cómo se generan estos datos para dar respuestas (condicionales a esos supuestos).\n\n\n1.0.1 Ejemplo: nacimientos\nComenzamos con un ejemplo de análisis exploratorio. Consideremos una parte de los datos de nacimientos por día del INEGI de 1999 a 2016. Consideraremos sólo tres meses: enero a marzo de 2016. Estos datos, por su tamaño, pueden representarse de manera razonablemente efectiva en una visualización de serie de tiempo\n\n\nCódigo\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(kableExtra)\nggplot2::theme_set(ggplot2::theme_light())\nnacimientos <- read_rds(\"datos/nacimientos/natalidad.rds\") |>\n   ungroup() |> \n   filter(year(fecha) == 2016, month(fecha) <= 3)\n\n\nExaminamos partes del contenido de la tabla:\n\n\nCódigo\ntab_1 <- nacimientos |> \n   select(fecha, n) |> \n   slice_head(n = 5)\ntab_2 <- nacimientos |> \n   select(fecha, n) |> \n   slice_tail(n = 5)\nkable(list(tab_1, tab_2)) |> kable_styling()\n\n\n\n\n\n  \n    \n\n\n \n  \n    fecha \n    n \n  \n \n\n  \n    2016-01-01 \n    3952 \n  \n  \n    2016-01-02 \n    4858 \n  \n  \n    2016-01-03 \n    4665 \n  \n  \n    2016-01-04 \n    5948 \n  \n  \n    2016-01-05 \n    6087 \n  \n\n\n\n \n    \n\n\n \n  \n    fecha \n    n \n  \n \n\n  \n    2016-03-27 \n    4112 \n  \n  \n    2016-03-28 \n    5805 \n  \n  \n    2016-03-29 \n    5957 \n  \n  \n    2016-03-30 \n    5766 \n  \n  \n    2016-03-31 \n    5497 \n  \n\n\n\n \n  \n\n\n\n\n\nEn un examen rápido de estos números no vemos nada fuera de orden. Los datos tienen forma de serie de tiempo regularmente espaciada (un dato para cada día). Podemos graficar de manera simple como sigue:\n\n\nCódigo\nggplot(nacimientos, aes(x = fecha, y = n)) +\n   geom_point() +\n   geom_line() + \n   scale_x_date(breaks = \"1 week\", date_labels = \"%d-%b\") \n\n\n\n\n\nEsta es una descripción de los datos, que quizá no es muy compacta pero muestra varios aspectos importantes. En este caso notamos algunos patrones que saltan a la vista. Podemos marcar los domingos de cada semana:\n\n\nCódigo\ndomingos_tbl <- nacimientos |> \n   filter(weekdays(fecha) == \"Sunday\")\nggplot(nacimientos, aes(x = fecha, y = n)) +\n   geom_vline(aes(xintercept = fecha), domingos_tbl, colour = \"salmon\") +\n   geom_point() +\n   geom_line() + \n   scale_x_date(breaks = \"1 week\", date_labels = \"%d-%b\") \n\n\n\n\n\nObservamos que los domingos ocurren menos nacimientos y los sábados también ocurren relativamente menos nacimentos. ¿Por qué crees que sea esto?\nAdicionalmente a estos patrones observamos otros aspectos interesantes:\n\nEl primero de enero hay considerablemente menos nacimientos de los que esperaríamos para un viernes. ¿Por qué?\nEl primero de marzo hay un exceso de nacimientos considerable. ¿Qué tiene de especial este primero de marzo?\n¿Cómo describirías lo que sucede en la semana que comienza el 21 de marzo? ¿Por qué crees que pase eso?\n¿Cuáles son los domingos con más nacimientos? ¿Qué tienen de especial y qué explicación puede tener?\n\nLa confirmación de estas hipótesis, dependiendo de su forma, puede ser relativamente simple (por ejemplo ver una serie más larga de domingos comparados con otros días de la semana) hasta muy compleja (investigar preferencias de madres, de doctores o de hospitales, costumbres y actitudes, procesos en el registro civil, etc.) En todo caso, una descripción correcta de estos datos requiere conocer tanto hechos generales como conocimiento detallado de prácticas relacionadas con la natalidad y el registro de nacimientos.\n\nEl análisis exploratorio y descripción de los datos requiere también conocimiento de dominio: ¿qué cosas intervienen en el proceso que genera estos datos?\n\n\n\nEjemplo (cálculos renales)\nEste es un estudio real acerca de tratamientos para cálculos renales (Julious y Mullee (1994)). Pacientes se asignaron de una forma no controlada a dos tipos de tratamientos para reducir cálculos renales. Para cada paciente, conocemos el tipo de ćalculos que tenía (grandes o chicos) y si el tratamiento tuvo éxito o no.\nLa tabla original tiene 700 renglones (cada renglón es un paciente)\n\n\nCódigo\ncalculos <- read_csv(\"./datos/kidney_stone_data.csv\")\nnames(calculos) <- c(\"tratamiento\", \"tamaño\", \"éxito\")\ncalculos <- calculos |> \n   mutate(tamaño = ifelse(tamaño == \"large\", \"grandes\", \"chicos\")) |> \n   mutate(resultado = ifelse(éxito == 1, \"mejora\", \"sin_mejora\")) |> \n   select(tratamiento, tamaño, resultado)\nnrow(calculos)\n\n\n[1] 700\n\n\ny se ve como sigue (muestreamos algunos renglones):\n\n\nCódigo\ncalculos |> \n   sample_n(20) |> kable() |> \n   kable_paper(full_width = FALSE)\n\n\n\n\n \n  \n    tratamiento \n    tamaño \n    resultado \n  \n \n\n  \n    A \n    grandes \n    mejora \n  \n  \n    B \n    chicos \n    mejora \n  \n  \n    B \n    chicos \n    sin_mejora \n  \n  \n    A \n    grandes \n    mejora \n  \n  \n    B \n    chicos \n    mejora \n  \n  \n    B \n    chicos \n    mejora \n  \n  \n    B \n    grandes \n    mejora \n  \n  \n    A \n    grandes \n    mejora \n  \n  \n    B \n    chicos \n    mejora \n  \n  \n    A \n    grandes \n    mejora \n  \n  \n    B \n    chicos \n    mejora \n  \n  \n    A \n    grandes \n    sin_mejora \n  \n  \n    A \n    grandes \n    mejora \n  \n  \n    B \n    grandes \n    mejora \n  \n  \n    A \n    grandes \n    mejora \n  \n  \n    A \n    grandes \n    sin_mejora \n  \n  \n    B \n    chicos \n    mejora \n  \n  \n    B \n    chicos \n    mejora \n  \n  \n    A \n    grandes \n    mejora \n  \n  \n    A \n    grandes \n    mejora \n  \n\n\n\n\n\nAunque estos datos contienen información de 700 pacientes, los datos pueden resumirse sin pérdida de información contando como sigue:\n\n\nCódigo\ncalculos_agregada <- calculos |> \n   group_by(tratamiento, tamaño, resultado) |> \n   count()\ncalculos_agregada |> kable() |> \n   kable_paper(full_width = FALSE)\n\n\n\n\n \n  \n    tratamiento \n    tamaño \n    resultado \n    n \n  \n \n\n  \n    A \n    chicos \n    mejora \n    81 \n  \n  \n    A \n    chicos \n    sin_mejora \n    6 \n  \n  \n    A \n    grandes \n    mejora \n    192 \n  \n  \n    A \n    grandes \n    sin_mejora \n    71 \n  \n  \n    B \n    chicos \n    mejora \n    234 \n  \n  \n    B \n    chicos \n    sin_mejora \n    36 \n  \n  \n    B \n    grandes \n    mejora \n    55 \n  \n  \n    B \n    grandes \n    sin_mejora \n    25 \n  \n\n\n\n\n\nEste resumen no es muy informativo, pero al menos vemos qué valores aparecen en cada columna de la tabla. Como en este caso nos interesa principalmente la tasa de éxito de cada tratamiento, podemos mejorar mostrando como sigue:\n\n\nCódigo\ncalculos_agregada |> pivot_wider(names_from = resultado, values_from = n) |> \n   mutate(total = mejora + sin_mejora) |> \n   mutate(prop_mejora = round(mejora / total, 2)) |> \n   select(tratamiento, tamaño, total, prop_mejora) |> \n   arrange(tamaño) |> \n   kable() |> \n   kable_paper(full_width = FALSE)\n\n\n\n\n \n  \n    tratamiento \n    tamaño \n    total \n    prop_mejora \n  \n \n\n  \n    A \n    chicos \n    87 \n    0.93 \n  \n  \n    B \n    chicos \n    270 \n    0.87 \n  \n  \n    A \n    grandes \n    263 \n    0.73 \n  \n  \n    B \n    grandes \n    80 \n    0.69 \n  \n\n\n\n\n\nEsta tabla descriptiva es una reescritura de los datos, y no hemos resumido nada todavía. Pero es apropiada para empezar a contestar la pregunta:\n\n¿Qué indican estos datos acerca de qué tratamiento es mejor? ¿Acerca del tamaño de cálculos grandes o chicos?\n\nSupongamos que otro analista decide comparar los pacientes que recibieron cada tratamiento, ignorando la variable de tamaño:\n\n\nCódigo\ncalculos |> group_by(tratamiento) |> \n   summarise(prop_mejora = mean(resultado == \"mejora\") |> round(2)) |> \n   kable() |> \n   kable_paper(full_width = FALSE)\n\n\n\n\n \n  \n    tratamiento \n    prop_mejora \n  \n \n\n  \n    A \n    0.78 \n  \n  \n    B \n    0.83 \n  \n\n\n\n\n\ny parece ser que el tratamiento \\(B\\) es mejor que el \\(A\\). Esta es una paradoja (un ejemplo de la paradoja de Simpson) . Si un médico no sabe que tipo de cálculos tiene el paciente, ¿entonces debería recetar \\(B\\)? ¿Si sabe debería recetar \\(A\\)? Esta discusión parece no tener mucho sentido.\nPodemos investigar por qué está pasando esto considerando la siguiente tabla, que solo examina cómo se asignó el tratamiento dependiendo del tipo de cálculos de cada paciente:\n\n\nCódigo\ncalculos |> group_by(tratamiento, tamaño) |> count() |> \n   kable() |> \n   kable_paper(full_width = FALSE)\n\n\n\n\n \n  \n    tratamiento \n    tamaño \n    n \n  \n \n\n  \n    A \n    chicos \n    87 \n  \n  \n    A \n    grandes \n    263 \n  \n  \n    B \n    chicos \n    270 \n  \n  \n    B \n    grandes \n    80 \n  \n\n\n\n\n\nNuestra hipótesis aquí es que la decisión de qué tratamiento usar depende del tamaño de los cálculos. En este caso, hay una decisión pues A es una cirugía y B es un procedimiento menos invasivo, y se prefiere utilizar el tratamiento \\(A\\) para cálculos grandes, y \\(B\\) para cálculos chicos. Esto quiere decir que en la tabla total el tratamiento \\(A\\) está en desventaja porque se usa en casos más difíciles, pero el tratamiento \\(A\\) parece ser en general mejor. La razón es probablemente un proceso de optimización de recursos y riesgo que hacen los doctores.\n\nUna mejor respuesta a la pregunta de qué tratamiento es mejor es la que presenta los datos desagregados\nLa tabla desagregada de asignación del tratamiento nos informa acerca de cómo se está distribuyendo el tratamiento en los pacientes.\n\nIgual que en el ejemplo anterior, los resúmenes descriptivos están acompañados de hipótesis acerca del proceso generador de datos, y esto ilumina lo que estamos observando y nos guía hacia descripciones provechosas de los datos. Las explicaciones no son tan simples y, otra vez, interviene el comportamiento de doctores, tratamientos, y distintos tipos de padecimientos.\n\n\nEjemplo (cálculos renales 2)\nContrastemos el ejemplo anterior usando exactamente los mismos datos, pero con una interpretación diferente. En este caso, los tratamientos son para mejorar alguna enfermedad del corazón. Sabemos que parte del efecto de este tratamiento ocurre gracias a una baja en presión arterial de los pacientes, así que después de administrar el tratamiento, se toma la presión arterial de los pacientes. Ahora tenemos la tabla agregada y desagregada como sigue:\n\n\nCódigo\ncorazon <- calculos |> \n  select(tratamiento, presión = tamaño, resultado) |> \n  mutate(presión = ifelse(presión == \"grandes\", \"alta\", \"baja\"))\ncorazon_agregada <- corazon |> \n   group_by(tratamiento, presión, resultado) |> \n   count()\ncorazon_agregada |> pivot_wider(names_from = resultado, values_from = n) |> \n   mutate(total = mejora + sin_mejora) |> \n   mutate(prop_mejora = round(mejora / total, 2)) |> \n   select(tratamiento, presión, total, prop_mejora) |> \n   arrange(presión) |> \n   kable() |> \n   kable_paper(full_width = FALSE)\n\n\n\n\n \n  \n    tratamiento \n    presión \n    total \n    prop_mejora \n  \n \n\n  \n    A \n    alta \n    263 \n    0.73 \n  \n  \n    B \n    alta \n    80 \n    0.69 \n  \n  \n    A \n    baja \n    87 \n    0.93 \n  \n  \n    B \n    baja \n    270 \n    0.87 \n  \n\n\n\n\n\n\n\nCódigo\ncorazon |> group_by(tratamiento) |> \n   summarise(prop_mejora = mean(resultado == \"mejora\") |> round(2)) |> \n   kable() |> \n   kable_paper(full_width = FALSE)\n\n\n\n\n \n  \n    tratamiento \n    prop_mejora \n  \n \n\n  \n    A \n    0.78 \n  \n  \n    B \n    0.83 \n  \n\n\n\n\n\n¿Cuál creemos que es el mejor tratamiento en este caso? ¿Deberíamos usar la tabla agregada o la desagregada por presión?\n\nEn este caso, la tabla agregada es más apropiada (B es mejor tratamiento).\nLa razón es que presión en este caso es una consecuencia de tomar el tratamiento, y como las tablas muestran, B es más exitoso en bajar la presión de los pacientes.\nSi sólo comparamos dentro de los grupos de presión baja o de presión alta, ignoramos parte del efecto del tratamiento en la probabilidad de mejorar.\n\n\n\n\n\nJulious, Steven A, y Mark A Mullee. 1994. «Confounding and Simpson’s paradox». BMJ 309 (6967): 1480-81. https://doi.org/10.1136/bmj.309.6967.1480."
  },
  {
    "objectID": "01-diagramas-est-cd-1.html",
    "href": "01-diagramas-est-cd-1.html",
    "title": "2  Diagramas causales",
    "section": "",
    "text": "Podemos utilizar diagramas causales introducidos por Judea Pearl (Pearl, Glymour, y Jewell (2016)) para explicar por qué el análisis se hace de manera diferente en cada uno de los casos de arriba. Los diagramas causales son representaciones de nuestro conocimiento de dominio acerca de cómo se relacionan de manera causal las variables de interés. En el caso de cálculos renales, podemos escribir el diagrama como sigue:\n\n\nCódigo\nlibrary(dagitty)\nlibrary(ggdag)\ndag_1 <- dagitty('dag{\"Tratamiento\" [exposure,pos=\"-3,0\"]\n  \"Resultado\" [outcome,pos=\"3,0\"]\n  \"Tamaño\" [pos=\"0,1\"]\n  \"Tamaño\"  -> \"Tratamiento\"\n    \"Tamaño\" -> \"Resultado\"\n    \"Tratamiento\" -> \"Resultado\"\n  }')\ndag_1_tidy <- tidy_dagitty(dag_1) \ndag_1_tidy |>\n  ggplot(aes(x = x, y = y, xend = xend, yend = yend )) + \n  geom_dag_edges() +\n  geom_dag_point(colour = \"salmon\", size = 20) +\n  geom_dag_text(colour = \"gray20\") +\n  theme_dag() \n\n\n\n\n\n\nEl tamaño de los cálculos afecta al resultado y a la asignación del tratamiento. Es un confusor si queremos entender el efecto del tratamiento en el resultado.\nPartimos los datos según este confusor para “comparar peras con peras”.\n\nSin embargo, en el segundo ejemplo tenemos:\n\n\nCódigo\nlibrary(dagitty)\nlibrary(ggdag)\ndag_1 <- dagitty('dag{\"Tratamiento\" [exposure,pos=\"-3,0\"]\n  \"Resultado\" [outcome,pos=\"3,0\"]\n  \"Presión\" [pos=\"0,1\"]\n  \"Tratamiento\"  -> \"Presión\"\n    \"Presión\" -> \"Resultado\"\n    \"Tratamiento\" -> \"Resultado\"\n  }')\ndag_1_tidy <- tidy_dagitty(dag_1) \ndag_1_tidy |>\n  ggplot(aes(x = x, y = y, xend = xend, yend = yend )) + \n  geom_dag_edges() +\n  geom_dag_point(colour = \"salmon\", size = 20) +\n  geom_dag_text(colour = \"gray20\") +\n  theme_dag()\n\n\n\n\n\n\nEn este caso, la presión es consecuencia también del tratamiento, así que es un camino por medio del cual el tratamiento produce resultados.\nComparar el tratamiento dentro de grupos de presión alta o baja estima el efecto del tratamiento que no tiene qué ver con la regulación de la presión, lo cual da una respuesta incompleta.\n\nAdicionalmente, en ambos ejemplos, estamos suponiendo que no existen otras variables confusoras que puedan afectar nuestro análisis. Qué tan correcta es esa suposición depende de que conozcamos los detalles de cómo fueron recopilados estos datos.\n\nEjemplo: prevalencia de anemia\nEn un estudio de hospitales en Australia se registró que 57% de una muestra pacientes tenían anemia cuando fueron ingresados. ¿Qué podemos decir acerca de la prevalencia de anemia en la población general de Australia? Con información básica acerca del proceso generador de esta muestra podemos concluir que será difícil generalizar con estos datos a la población general. La razón es que:\n\nMuchas enfermedades graves (por ejemplo del corazón) pueden producir anemia.\nEstas enfermededes hacen más probable que alguien sea hospitalizado.\nPor lo tanto, en este estudio hay una asociación entre tener anemia y ser seleccionado para el estudio (tener anemia sube la probabilidad de ser seleccionado para el estudio)\nNuestra conclusión es que el 57% es probablemente una sobreestimación de la prevalencia de anemia en la población.\n\n\n\nCódigo\ndag_1 <- dagitty('dag{\"Selección\" [exposure, pos = \"2,1\"]\n  \"Anemia\" [outcome, pos = \"-1, 2.5\"]\n  \"Hospitalización\" [pos=\"1,2\"]\n  \"Enfermedad\" [pos=\"0, 3\"]\n  \"Hospitalización\" -> \"Selección\"\n    \"Enfermedad\" -> \"Anemia\"\n    \"Anemia\" -> \"Hospitalización\"\n    \"Enfermedad\" -> \"Hospitalización\"\n  }')\ndag_1_tidy <- tidy_dagitty(dag_1) \ndag_1_tidy |>\n  ggplot(aes(x = x, y = y, xend = xend, yend = yend )) + \n  geom_dag_edges() +\n  geom_dag_point(colour = \"salmon\", size = 20) +\n  geom_dag_text(colour = \"gray20\") +\n  theme_dag()\n\n\n\n\n\nEste diagrama indica que puede ser difícil generalizar con las personas que han sido seleccionadas, porque tanto la selección como la variable de interés tienen una causa común: la existencia o no de una enfermedad en la persona. Será difícil generalizar para las personas no observadas en el estudio.\n\n\nEjemplo: colisionadores y sesgo de selección\nEn los ejemplos anteriores vimos dos estructuras causales importantes para entender cómo interpretar datos: vimos variables confusoras que afectan a tratamiento y resultado (como el ejemplo de anemia), y vimos cadenas (como en el ejemplo de presión alta).\nUna tercera estructura importante es la de colisionador: una variable que tiene como causa tratamiento y resultado. La interpretación de los datos cambia dependiendo si están condicionados a un valor del colisionador o no. Por ejemplo:\n\nSupongamos que queremos entender la relación en desempeño en matemáticas y en español para estudiantes que entran a una universidad.\nEncontramos una relación negativa entre las calificaciones de los dos exámenes: parece ser que habilidad verbal se contrapone a habilidad numérica.\n\n¿Por qué tenemos que tener cuidado al interpretar esta correlación? ¿Existe esta correlación en la población general?\n\n\nCódigo\nlibrary(dagitty)\nlibrary(ggdag)\ndag_1 <- dagitty('dag{\"Español\" [exposure,pos=\"1,1\"]\n  \"Mate\" [outcome,pos=\"1,-1\"]\n  \"Admisión\" [pos=\"2,0\"]\n  \"Español\"  -> \"Admisión\"\n    \"Mate\" -> \"Admisión\"\n  }')\ndag_1_tidy <- tidy_dagitty(dag_1) \ndag_1_tidy |>\n  ggplot(aes(x = x, y = y, xend = xend, yend = yend )) + \n  geom_dag_edges() +\n  geom_dag_point(colour = \"salmon\", size = 20) +\n  geom_dag_text(colour = \"gray20\") +\n  theme_dag()\n\n\n\n\n\n\nDescubrimos que la universidad hace una calificación compuesta de español y matemáticas para que los alumnos sean aceptados en la universidad\nEsto quiere decir que para entrar es necesario al menos desempeñarse bien en alguna de las dos\n\nAhora observamos que aunque en la población general no hay tal relación, al seleccionar sólo a los alumnos de la universidad “activamos” una correlación debido al proceso de selección:\n\n\nCódigo\nset.seed(823)\ntibble(x = rnorm(2000), y = rnorm(2000)) |> \n  mutate(aceptados = x + y > 1.5 ) |> \nggplot(aes(x, y, colour = aceptados)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(method = \"lm\", se = FALSE)\n\n\n`geom_smooth()` using formula 'y ~ x'\n\n\n\n\n\n\n\nEjemplo: sesgo de Berkson\nAlgunos estudios fueron publicados en la primera mitad de 2020 que notaban que el porcentaje fumadores entre los casos positivos de COVID era menor que en la población general, y se hicieron algunas interpretaciones acerca de este hecho. Estos estudios se hicieron con personas que se hicieron una prueba.\nEn este ejemplo replicaremos cómo es que podemos encontrar esta asociación en este tipo de estudios aún cuando no exista tal asociación en la población general (ver este artículo). Usaremos datos sintéticos (simulados).\nPrimero vamos a razonar acerca del proceso generador de datos y a hacer algunos supuestos:\n\nEn primer lugar, ¿cuándo decide hacerse alguien una prueba? A principios de 2020, son principalmente personas que tienen síntomas considerables, y trabajadores de salud (tengan o no síntomas).\nSer trabajador de salud incrementa el riesgo de contagiarse.\nEn algunos países, fumar está asociado con ser trabajador de salud (no tienen la misma tasa de tabaquismo que la población general).\nSólo observamos a las personas que se hicieron una prueba.\n\nPodemos resumir cualitativamente con el siguiente diagrama:\n\n\nCódigo\nlibrary(dagitty)\nlibrary(ggdag)\ndag_1 <- dagitty('dag{\"Covid\" [outcome, pos = \"-0.5, 2.5\"]\n  \"Prueba\" [pos=\"0,-2\"]\n  \"TrabSalud\" [pos=\"0, 3\"]\n  \"Sintomas\" [pos=\"-1, 1\"]\n  \"Fumar\" [pos = \"1, 1\"]\n  \"TrabSalud\" -> \"Covid\"\n  \"TrabSalud\" -> \"Prueba\"\n  \"TrabSalud\" -> \"Fumar\"\n  \"Covid\" -> \"Sintomas\"\n  \"Sintomas\" -> \"Prueba\"\n  }')\ndag_1_tidy <- tidy_dagitty(dag_1) \ndag_1_tidy |>\n  ggplot(aes(x = x, y = y, xend = xend, yend = yend )) + \n  geom_dag_edges() +\n  geom_dag_point(colour = \"salmon\", size = 20) +\n  geom_dag_text(colour = \"gray20\") +\n  theme_dag()\n\n\n\n\n\nEl código para simular es el siguiente: todas las variables toman valores 0 o 1, pero con diferentes probabilidades y dependiendo de las variables que son padres en la gráfica de arriba.\n\nSimulamos 100,000 personas de las cuales aproximadamente el 1% son trabajadores de salud.\nSuponemos que el 4% de los trabajadores de salud resultaron covid positivo y el 1% del resto de las personas resultaron covid positivo.\nSuponemos que de las personas que tienen covid, el 50% tienen síntomas y de las personas que no tienen covid, el 1% tiene síntomas.\nSuponemos que de los trabadores de salud el 99% se hicieron prueba (sin importar si tenían o no síntomas) y el resto de las personas se divide en 2, de los no trabadores de salud con síntomas, el 60% se hicieron una prueba y de los no trabajdores de salud sin síntomas, el 1% se hizo una prueba\nDe los trabajadores de salud, el 30% fuman, del resto de las personas el 10% fuman.\n\n\n\nCódigo\nset.seed(821)\n#simular población\nn <- 1000000\ntrab_salud <- rbinom(n, 1, 0.01)\ncovid <- rbinom(n, 1, ifelse(trab_salud==1, 0.04, 0.01))\ndatos <- tibble(trab_salud = trab_salud, covid) |> \n  mutate(sintomas = rbernoulli(n, ifelse(covid == 1, 0.5, 0.01))) |> \n  mutate(prueba = rbernoulli(n, ifelse(trab_salud ==1, 0.99, 0.6 * sintomas + 0.01))) |> \n  mutate(fumar = rbernoulli(n, ifelse(trab_salud == 1, 0.3, 0.1))) |> \n  mutate(covid = ifelse(covid ==1, \"positivo\", \"negativo\")) |> \n  mutate(fumar = ifelse(fumar, \"fuma\", \"no_fuma\"))\n\n\nSuponemos ahora que tomamos como muestra a todas aquellas personas que se hicieron una prueba. En primer lugar, la proporción de fumadores en la muestra es un poco más alta que la población, porque los trabajadores de salud están sobrerrepresentados\n\n\nCódigo\ndatos_pruebas <- filter(datos, prueba == 1)\ntable(datos_pruebas$fumar) |> prop.table()\n\n\n\n     fuma   no_fuma \n0.1712317 0.8287683 \n\n\nY ahora vemos que están asociados fumar y salir positivo:\n\n\nCódigo\ntable(datos_pruebas$covid, datos_pruebas$fumar) |> prop.table(margin = 2) |> \n  round(2)\n\n\n          \n           fuma no_fuma\n  negativo 0.91    0.87\n  positivo 0.09    0.13\n\n\nEn la población no existe tal asociación, además de que la tasa de positivos es considerablemente más baja:\n\n\nCódigo\ntable(datos$covid, datos$fumar) |> prop.table(margin = 2) |> \n  round(3)\n\n\n          \n            fuma no_fuma\n  negativo 0.989   0.990\n  positivo 0.011   0.010\n\n\n\nEn este ejemplo, al seleccionar sólo aquellas personas que tomaron una prueba, cambia la relación entre tener covid y ser trabajador de salud, pues sólo los que tienen síntomas de la población general toman la prueba. Esto produce que una prueba negativa esté más relacionada con ser trabajador de salud, y por lo tanto, mayor probabilidad de ser fumador.\nTambién puede entenderse pensando que cuando tomamos solamente las personas que se hicieron pruebas, entonces los trabajadores de salud están sobrerrepresantados en la muestra.\n\n\n\n\n\nPearl, J., M. Glymour, y N. P. Jewell. 2016. Causal Inference in Statistics: A Primer. Wiley. https://books.google.com.mx/books?id=L3G-CgAAQBAJ."
  },
  {
    "objectID": "01-proceso-est-cd-1.html",
    "href": "01-proceso-est-cd-1.html",
    "title": "3  Procesos generadores de datos",
    "section": "",
    "text": "Código\nlibrary(tidyverse)\nlibrary(kableExtra)\nggplot2::theme_set(ggplot2::theme_light())\nNótese que en todas estas preguntas hemos tenido que recurrir a conocimientos generales y de dominio para interpretar y hacer hipótesis acerca de lo que vemos en la gráfica. Una visión descontextualizada no tiene mucha utilidad. Las explicaciones son típicamente complejas e intervienen distintos aspectos del comportamiento de actores, sistemas, y métodos de recolección de datos involucrados.\nEn la Ciencia de Datos buscamos entender las partes importantes del proceso generador\nMucha parte de este trabajo no es estadístico, sino que es un esfuerzo por entender el dominio (como sugiere el título de artículo de David A. Friedman: Statistical Models and Shoe Leather)."
  },
  {
    "objectID": "01-proceso-est-cd-1.html#ejercicio-admisiones-de-berkeley",
    "href": "01-proceso-est-cd-1.html#ejercicio-admisiones-de-berkeley",
    "title": "3  Procesos generadores de datos",
    "section": "Ejercicio: admisiones de Berkeley",
    "text": "Ejercicio: admisiones de Berkeley\nConsideramos ahora los siguientes datos de admisión a distintos departamentos de Berkeley en 1975:\n\n\nCódigo\ndata(\"UCBAdmissions\")\nadm_original <- UCBAdmissions |> as_tibble() |> \n   pivot_wider(names_from = Admit, values_from = n) \nadm_original |> knitr::kable() |> \n   kable_paper(full_width = FALSE)\n\n\n\n\n \n  \n    Gender \n    Dept \n    Admitted \n    Rejected \n  \n \n\n  \n    Male \n    A \n    512 \n    313 \n  \n  \n    Female \n    A \n    89 \n    19 \n  \n  \n    Male \n    B \n    353 \n    207 \n  \n  \n    Female \n    B \n    17 \n    8 \n  \n  \n    Male \n    C \n    120 \n    205 \n  \n  \n    Female \n    C \n    202 \n    391 \n  \n  \n    Male \n    D \n    138 \n    279 \n  \n  \n    Female \n    D \n    131 \n    244 \n  \n  \n    Male \n    E \n    53 \n    138 \n  \n  \n    Female \n    E \n    94 \n    299 \n  \n  \n    Male \n    F \n    22 \n    351 \n  \n  \n    Female \n    F \n    24 \n    317 \n  \n\n\n\n\n\nCon algo de manipulación podemos ver tasas de admisión para Male y Female, y los totales de cada grupo que solicitaron en cada Departamento.\n\n\nCódigo\nadm_tbl <- adm_original |> \n   mutate(prop_adm = round(Admitted / (Admitted + Rejected), 2), total = Admitted + Rejected) |> \n   select(Gender, Dept, prop_adm, total) |> \n   pivot_wider(names_from = Gender, values_from = prop_adm:total)\nadm_tbl |> knitr::kable() |> \n   kable_paper(full_width = FALSE)\n\n\n\n\n \n  \n    Dept \n    prop_adm_Male \n    prop_adm_Female \n    total_Male \n    total_Female \n  \n \n\n  \n    A \n    0.62 \n    0.82 \n    825 \n    108 \n  \n  \n    B \n    0.63 \n    0.68 \n    560 \n    25 \n  \n  \n    C \n    0.37 \n    0.34 \n    325 \n    593 \n  \n  \n    D \n    0.33 \n    0.35 \n    417 \n    375 \n  \n  \n    E \n    0.28 \n    0.24 \n    191 \n    393 \n  \n  \n    F \n    0.06 \n    0.07 \n    373 \n    341 \n  \n\n\n\n\n\nY complementamos con las tasas de aceptación a total por género, y tasas de aceptación por departamento:\n\n\nCódigo\nadm_original |> group_by(Gender) |> \n   summarise(Admitted = sum(Admitted), Rejected = sum(Rejected)) |> \n   mutate(prop_adm = round(Admitted / (Admitted + Rejected),2)) |> \n   kable() |> \n   kable_paper(full_width = FALSE)\n\n\n\n\n \n  \n    Gender \n    Admitted \n    Rejected \n    prop_adm \n  \n \n\n  \n    Female \n    557 \n    1278 \n    0.30 \n  \n  \n    Male \n    1198 \n    1493 \n    0.45 \n  \n\n\n\n\n\n\n\nCódigo\nadm_original |> group_by(Dept) |> \n   summarise(Admitted = sum(Admitted), Rejected = sum(Rejected)) |> \n   mutate(prop_adm = round(Admitted / (Admitted + Rejected),2)) |> \n   kable() |> \n   kable_paper(full_width = FALSE)\n\n\n\n\n \n  \n    Dept \n    Admitted \n    Rejected \n    prop_adm \n  \n \n\n  \n    A \n    601 \n    332 \n    0.64 \n  \n  \n    B \n    370 \n    215 \n    0.63 \n  \n  \n    C \n    322 \n    596 \n    0.35 \n  \n  \n    D \n    269 \n    523 \n    0.34 \n  \n  \n    E \n    147 \n    437 \n    0.25 \n  \n  \n    F \n    46 \n    668 \n    0.06 \n  \n\n\n\n\n\n\nDibuja el diagrama causal\n¿Qué observas acerca de las tasas de admisión en cada departamento, diferenciadas por género? ¿Qué tiene qué ver con el número de personas que solicitan en cada departamento?\nEsta es una tabla descriptiva. Sin embargo, tiene que ser entendida en el contexto de los datos y su generación. ¿Qué hipótesis importantes sugieren estos datos? ¿Por qué hay tanta diferencia de género de solicitudes en algunos departamentos? ¿Por qué es sorprendente o no las variaciones en tasas de aceptación de estudiantes de cada género?"
  },
  {
    "objectID": "02-resumenes.html",
    "href": "02-resumenes.html",
    "title": "Resúmenes y descripciones de datos",
    "section": "",
    "text": "Una buena referencia para esta parte, que se enfoca principalmente en visualización bajo principios estadísticos, es (cleveland93) por ejemplo."
  },
  {
    "objectID": "02-resumenes-analisis-1.html",
    "href": "02-resumenes-analisis-1.html",
    "title": "4  Resúmenes para datos numéricos",
    "section": "",
    "text": "El primer concepto se refiere a entender cómo se distribuyen los datos a los largo de su escala de medición. Comenzamos con un ejemplo: los siguientes datos fueron registrados en un restaurante durante cuatro días consecutivos.\n\n\nCódigo\n# usamos los datos tips del paquete reshape2\npropinas <- read_csv(\"./datos/propinas.csv\")\nslice_sample(propinas, n = 10) |> kable() |> \n   kable_paper(full_width = FALSE)\n\n\n\n\n \n  \n    cuenta_total \n    propina \n    fumador \n    dia \n    momento \n    num_personas \n  \n \n\n  \n    20.49 \n    4.06 \n    Si \n    Sab \n    Cena \n    2 \n  \n  \n    14.52 \n    2.00 \n    No \n    Jue \n    Comida \n    2 \n  \n  \n    10.27 \n    1.71 \n    No \n    Dom \n    Cena \n    2 \n  \n  \n    11.24 \n    1.76 \n    Si \n    Sab \n    Cena \n    2 \n  \n  \n    12.60 \n    1.00 \n    Si \n    Sab \n    Cena \n    2 \n  \n  \n    19.49 \n    3.51 \n    No \n    Dom \n    Cena \n    2 \n  \n  \n    13.42 \n    3.48 \n    Si \n    Vie \n    Comida \n    2 \n  \n  \n    50.81 \n    10.00 \n    Si \n    Sab \n    Cena \n    3 \n  \n  \n    16.47 \n    3.23 \n    Si \n    Jue \n    Comida \n    3 \n  \n  \n    14.78 \n    3.23 \n    No \n    Dom \n    Cena \n    2 \n  \n\n\n\n\n\nAquí la unidad de observación es una cuenta particular. Tenemos tres mediciones numéricas de cada cuenta: cúanto fue la cuenta total, la propina, y el número de personas asociadas a la cuenta. Los datos están separados según se fumó o no en la mesa, y temporalmente en dos partes: el día (Jueves, Viernes, Sábado o Domingo), cada uno separado por Cena y Comida.\nEl primer tipo de comparaciones que nos interesa hacer es para una medición numérica es: ¿Varían mucho o poco los datos? ¿Cuáles son valores típicos o centrales? ¿Existen valores muy extremos alejados de valores típicos?\nSupongamos entonces que consideramos simplemente la variable de cuenta_total. Podemos comenzar por ordenar los datos, y ver cuáles datos están en los extremos y cuáles están en los lugares centrales:\n\n\nCódigo\npropinas <- propinas |> \n  mutate(orden_cuenta = rank(cuenta_total, ties.method = \"first\"), \n         f = orden_cuenta / n()) \ncuenta <- propinas |>  select(orden_cuenta, f, cuenta_total) |>  arrange(f)\nbind_rows(head(cuenta), tail(cuenta)) |>  knitr::kable() |> \n   kable_paper(full_width = FALSE)\n\n\n\n\n \n  \n    orden_cuenta \n    f \n    cuenta_total \n  \n \n\n  \n    1 \n    0.0040984 \n    3.07 \n  \n  \n    2 \n    0.0081967 \n    5.75 \n  \n  \n    3 \n    0.0122951 \n    7.25 \n  \n  \n    4 \n    0.0163934 \n    7.25 \n  \n  \n    5 \n    0.0204918 \n    7.51 \n  \n  \n    6 \n    0.0245902 \n    7.56 \n  \n  \n    239 \n    0.9795082 \n    44.30 \n  \n  \n    240 \n    0.9836066 \n    45.35 \n  \n  \n    241 \n    0.9877049 \n    48.17 \n  \n  \n    242 \n    0.9918033 \n    48.27 \n  \n  \n    243 \n    0.9959016 \n    48.33 \n  \n  \n    244 \n    1.0000000 \n    50.81 \n  \n\n\n\n\n\ny graficamos los datos en orden, interpolando valores consecutivos.\n\n\n\n\n\nA esta función le llamamos la función de cuantiles para la variable cuenta total. Nos sirve para comparar directamente los distintos valores que observamos los datos según el orden que ocupan.\n\n\n\n\n\n\nCuantiles de datos numéricos\n\n\n\nEl cuantil \\(f\\) de un bonche de datos numéricos es el valor \\(q(f)\\), en la escala de medición de nuestros datos, tal que aproximadamente una fracción \\(f\\) de los datos está por abajo de \\(q(f)\\).\n\nAl cuantil \\(f=0.5\\) le llamamos la mediana.\nA los cuantiles \\(f=0.25\\) y \\(f=0.75\\) les llamamos cuartiles inferior y superior.\n\n\n\nNota: si los datos originales son \\(y_1, y_2, \\ldots, y_n\\), y los mismos datos ordenados son \\(y_{(1)}, y_{(2)}, \\ldots, y_{(n)}\\), entonces si \\(f= j/n\\), \\(q(f) = y_{(j)}\\). Si \\(f\\) toma un valor intermedio entre \\((j-1)/n\\) y \\(j/n\\), entonces interpolamos \\(y_{(j-1)}\\) y \\(y_{(j)}\\) para encontrar \\(q(f)\\).\nHay otras maneras de definir los cuantiles que pueden ser más convenientes. Los que estamos usando ahora son los cuantiles tipo 4:\n\nquantile(cuenta$cuenta_total, probs = c(6/244, 239/244), type = 4)\n\n2.459016% 97.95082% \n     7.56     44.30 \n\n\n¿Qué podemos leer en la gráfica de cuantiles?\nDispersión y valores centrales\n\nEl rango de datos va de unos 3 dólares hasta 50 dólares\nLos valores centrales (del cuantil 0.25 al 0.75, por ejemplo), están entre unos 13 y 25 dólares\nPodemos usar el cuantil 0.5 (mediana) para dar un valor central de esta distribución, que está alrededor de 18 dólares.\n\nY podemos dar resúmenes más refinados si es necesario\n\nEl cuantil 0.95 es de unos 35 dólares - sólo 5% de las cuentas son de más de 35 dólares\nEl cuantil 0.05 es de unos 8 dólares - sólo 5% de las cuentas son de 8 dólares o menos.\n\nFinalmente, la forma de la gráfica se interpreta usando su pendientes, haciendo comparaciones de diferentes partes de la gráfica:\n\nEntre los cuantiles 0.2 y 0.5 es donde existe mayor densidad de datos: la pendiente es baja, lo que significa que al avanzar en los cuantiles, los valores observados no cambian mucho.\nCuando la pendiente es alta, quiere decir que los datos tienen más dispersión local o están más separados.\n\nY podemos considerar qué sucede en las colas de la distribucion:\n\nLa distribución de valores tiene asimetría: el 10% de las cuentas más altas tiene considerablemente más dispersión que el 10% de las cuentas más bajas. A veces decimos que la cola de la derecha es más larga que la cola de la izquierda\n\nEn algunos casos, es más natural hacer un histograma, donde dividimos el rango de la variable en cubetas o intervalos (en este caso de igual longitud), y graficamos cuántos datos caen en cada cubeta. En la siguiente gráfica variamos el ancho de las cubetas:\n\n\nCódigo\nbinwidth_min = 1\ng_1 <- ggplot(propinas, aes(x = cuenta_total)) + geom_histogram(binwidth = binwidth_min) \ng_2 <- ggplot(propinas, aes(x = cuenta_total)) + geom_histogram(binwidth = binwidth_min * 2)\ng_3 <- ggplot(propinas, aes(x = cuenta_total)) + geom_histogram(binwidth = binwidth_min * 5) \ng_1 + g_2 + g_3\n\n\n\n\n\nEs una gráfica más popular, pero perdemos cierto nivel de detalle, y distintas particiones resaltan distintos aspectos de los datos.\nFinalmente, una gráfica más compacta que resume la gráfica de cuantiles o el histograma es el diagrama de caja y brazos. Mostramos dos versiones, la clásica de Tukey (T) y otra versión menos común de Spear/Tufte (ST):\n\n\nCódigo\nlibrary(ggthemes)\ncuartiles <- quantile(cuenta$cuenta_total)\ncuartiles\n\n\n     0%     25%     50%     75%    100% \n 3.0700 13.3475 17.7950 24.1275 50.8100 \n\n\nCódigo\ng_1 <- ggplot(cuenta, aes(x = f, y = cuenta_total)) + \n  labs(subtitle = \"Gráfica de cuantiles: Cuenta total\") +\n  geom_hline(yintercept = cuartiles[2], colour = \"gray\") + \n  geom_hline(yintercept = cuartiles[3], colour = \"gray\") +\n  geom_hline(yintercept = cuartiles[4], colour = \"gray\") +\n  geom_point(alpha = 0.5) + geom_line() \ng_2 <- ggplot(cuenta, aes(x = factor(\"ST\", levels =c(\"ST\")), y = cuenta_total)) + \n  geom_tufteboxplot() +\n  labs(subtitle = \" \") +  xlab(\"\") + ylab(\"\")\ng_3 <- ggplot(cuenta, aes(x = factor(\"T\"), y = cuenta_total)) + geom_boxplot() +\n  labs(subtitle = \" \") +  xlab(\"\") + ylab(\"\")\ng_4 <- ggplot(cuenta, aes(x = factor(\"P\"), y = cuenta_total)) + geom_jitter(height = 0, width =0.2, alpha = 0.5) +\n  labs(subtitle = \" \") +  xlab(\"\") + ylab(\"\")\ng_1 + g_2 + g_3 + g_4 +\n  plot_layout(widths = c(8, 2, 2, 2))"
  },
  {
    "objectID": "02-resumenes-analisis-1.html#distribución-acumulada-empírica",
    "href": "02-resumenes-analisis-1.html#distribución-acumulada-empírica",
    "title": "4  Resúmenes para datos numéricos",
    "section": "4.2 Distribución acumulada empírica",
    "text": "4.2 Distribución acumulada empírica\nOtra forma de graficar la dispersión de los datos sin perder información es mediante la función de distribución acumulada empírica, o fda empírica. En un sentido, es la inversa de la función de cuantiles:\n\n\nCódigo\nggplot(cuenta, aes(x = cuenta_total)) +\n  stat_ecdf()\n\n\n\n\n\nEn esta gráfica, vemos que proporción de los datos que son iguales o están por debajo de cada valor en el eje horizontal.\n\n\n\n\n\n\nNota\n\n\n\n\nEn análisis de datos, es más frecuente utilizar la función de cuantiles pues existen versiones más generales que son útiles, por ejemplo, para evaluar ajuste de modelos probabilísticos\nEn la teoría, generalmente es más común utilizar la fda empírica, que tiene una única definición que veremos coincide con definiciones teóricas."
  },
  {
    "objectID": "02-resumenes-analisis-1.html#media-y-desviación-estándar",
    "href": "02-resumenes-analisis-1.html#media-y-desviación-estándar",
    "title": "4  Resúmenes para datos numéricos",
    "section": "4.3 Media y desviación estándar",
    "text": "4.3 Media y desviación estándar\nOtras medidas más comunes de localización y dispersión para conjuntos de datos son media y desviación estándar muestral.\nLa media de un conjunto de datos \\(x_1,\\ldots, x_n\\) es\n\\[\\bar{x} = \\frac{1}{n}\\sum x_i\\]\ny la desviación estándar es\n\\[\\hat{\\sigma} =\\sqrt{\\frac{1}{n}\\sum (x_i - \\bar{x})^2}\\]\nEn general, no son muy apropiadas para iniciar el análisis exploratorio, y se requieren cuidados adicionales al utilizarlas, pues:\n\nSon medidas más difíciles de interpretar y explicar que los cuantiles. En este sentido, son medidas especializadas. Como ejercicio, intenta explicar intuitivamente qué es la media. Después prueba con la desviación estándar. Sin embargo, la mediana o el rango intercuartílico son fáciles de explicar.\nNo son resistentes a valores atípicos o erróneos. Su falta de resistencia los vuelve poco útiles en las primeras etapas de descripción, y muchas veces requieren transformaciones o cuidados adicionales/supuestos para evitar mal comportamiento por esa falta de resistencia.\n\nSin embargo,\n\nLa media y desviación estándar son computacionalmente convenientes, y para el trabajo de modelado, por ejemplo, tienen ventajas claras (cuando se cumplen supuestos). Por lo tanto regresaremos a estas medidas una vez que estudiemos modelos de probabilidad básicos.\nMuchas veces, ya sea por tradición, porque así se ha hecho el análisis antes, conviene usar estas medidas conocidas."
  },
  {
    "objectID": "02-resumenes-analisis-1.html#distribuciones-sesgadas-y-atípicos",
    "href": "02-resumenes-analisis-1.html#distribuciones-sesgadas-y-atípicos",
    "title": "4  Resúmenes para datos numéricos",
    "section": "4.4 Distribuciones sesgadas y atípicos",
    "text": "4.4 Distribuciones sesgadas y atípicos\nEn algunos casos tenemos que trabajar con mediciones que tienen una cola (usualmente la derecha) mucho más larga que la otra. Veamos cuáles son consecuencias típicas.\nConsideremos por ejemplos una muestra de los datos de ENIGH 2018\n\n\nCódigo\nenigh <- read_csv(\"./datos/enigh-ejemplo.csv\")\n\n\nY los deciles de ingreso son\n\n\nCódigo\nenigh <- mutate(enigh, ingreso_mensual_miles = INGTOT / 3000)\n\nenigh |> \n  summarise(\n    f = seq(0, 1, 0.1),\n    cuantiles_ingreso =  quantile(ingreso_mensual_miles, probs = seq(0, 1, 0.1), type = 4)) |> \n  kable(digits = 2) |> \n   kable_paper(full_width = FALSE)\n\n\n\n\n \n  \n    f \n    cuantiles_ingreso \n  \n \n\n  \n    0.0 \n    0.81 \n  \n  \n    0.1 \n    2.57 \n  \n  \n    0.2 \n    3.86 \n  \n  \n    0.3 \n    5.52 \n  \n  \n    0.4 \n    6.73 \n  \n  \n    0.5 \n    8.25 \n  \n  \n    0.6 \n    9.98 \n  \n  \n    0.7 \n    12.94 \n  \n  \n    0.8 \n    16.18 \n  \n  \n    0.9 \n    22.16 \n  \n  \n    1.0 \n    317.53 \n  \n\n\n\n\n\ndonde podemos ver cómo cuando nos movemos a deciles más altos, la dispersión aumenta. Existen algunos valores muy grandes. Un histograma no funciona muy bien con estos datos.\n\n\nCódigo\nggplot(enigh, aes(x = ingreso_mensual_miles)) + geom_histogram()\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nSi filtramos los valores muy grandes, de todas formas encontramos una forma similar con una cola larga a la derecha:\n\n\nCódigo\nggplot(enigh |> filter(ingreso_mensual_miles < 90), \n       aes(x = ingreso_mensual_miles)) + geom_histogram()\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nNótese que la media de estos datos no es un resúmen muy útil, porque es difícil de interpretar. Por los valores grandes, la media es considerablemente más alta que la mediana:\n\n\nCódigo\nenigh |> \n  summarise(\n    media = mean(ingreso_mensual_miles),\n    mediana =  quantile(ingreso_mensual_miles, probs = 0.5)) |> \n  kable(digits = 2) |> \n   kable_paper(full_width = FALSE)\n\n\n\n\n \n  \n    media \n    mediana \n  \n \n\n  \n    12.04 \n    8.27 \n  \n\n\n\n\n\nEsta es otra razón para incluir información de cuantiles en la etapa descriptiva. Por ejemplo, podríamos resumir:\n\n\nCódigo\nenigh |> \n  summarise(\n    f = c(\"min\", 0.05, \"0.50\",  0.95, \"max\"),\n    cuantiles_ingreso =  quantile(ingreso_mensual_miles, probs = c(0, 0.05, 0.5, 0.95, 1))) |> \n  kable(digits = 2) |> \n   kable_paper(full_width = FALSE)\n\n\n\n\n \n  \n    f \n    cuantiles_ingreso \n  \n \n\n  \n    min \n    0.81 \n  \n  \n    0.05 \n    1.92 \n  \n  \n    0.50 \n    8.27 \n  \n  \n    0.95 \n    32.24 \n  \n  \n    max \n    317.53 \n  \n\n\n\n\n\nOtra opción es utilizar una escala logarítmica. El logaritmo de los ingresos es más fácil de describir y veremos también más fácil de trabajar.\n\n\nCódigo\nggplot(enigh, \n       aes(x = ingreso_mensual_miles)) + \n  geom_histogram(binwidth = 0.12) +\n  scale_x_log10(breaks = c(1, 2, 4, 8, 16, 32, 64, 128, 256))\n\n\n\n\n\nPor las propiedades de los cuantiles, cualquier cantidad basada en cuantiles que se calcula en escala logarítmica puede pasarase a la escala original transformando\n\n\nCódigo\nquantile(log(enigh$ingreso_mensual_miles)) |> exp()\n\n\n         0%         25%         50%         75%        100% \n  0.8132833   4.7986689   8.2740789  14.1517930 317.5284167 \n\n\nCódigo\nquantile(enigh$ingreso_mensual_miles) \n\n\n         0%         25%         50%         75%        100% \n  0.8132833   4.7986692   8.2741033  14.1517942 317.5284167 \n\n\nNota: esto no sucede con medidas más complicadas como la media. El exponencial de la media de los logaritmos no es la media en la escala original."
  },
  {
    "objectID": "02-resumenes-analisis-1.html#comparando-grupos-con-variables-numéricas",
    "href": "02-resumenes-analisis-1.html#comparando-grupos-con-variables-numéricas",
    "title": "4  Resúmenes para datos numéricos",
    "section": "4.5 Comparando grupos con variables numéricas",
    "text": "4.5 Comparando grupos con variables numéricas\n\nEjemplo: precios de casas\nConsideramos datos de precios de ventas de la ciudad de Ames, Iowa. Nos interesa entender la variación del precio de las casas.\n\n\n\nCalculamos primeros unos cuantiles de los precios de las casas:\n\n\nCódigo\nquantile(casas |>  pull(precio_miles)) \n\n\n   0%   25%   50%   75%  100% \n 37.9 132.0 165.0 215.0 755.0 \n\n\nUna primera comparación que podemos hacer es considerar las distintas zonas de la ciudad. Podemos usar diagramas de caja y brazos para comparar precios en distintas zonas de la ciudad:\n\n\nCódigo\nggplot(casas, aes(x = nombre_zona, y = precio_miles)) + geom_boxplot() + coord_flip()\n\n\n\n\n\nNótese que de cada zona, los datos tienen una cola derecha más larga que la izquierda, e incluso hay valores extremos en la cola derecha que exceden el rango de variación usual. Una razón por la que puede suceder esto es que haya características particulares que agregan valor considerable a una casa, por ejemplo, el tamaño, una alberca, etc.\nEn primer lugar, podemos considerar el área de las casas. En lugar de graficar el precio, graficamos el precio por metro cuadrado, por ejemplo:\n\n\n\n\n\nCódigo\nggplot(casas, aes(x = nombre_zona, y = precio_m2)) + geom_boxplot() + coord_flip()\n\n\n\n\n\nNótese ahora que la variación alrededor de la media es mucho más simétrica, y ya no vemos tantos datos extremos. Aún más, la variación dentro de cada zona parece ser similar, y podríamos describir restos datos de la siguiente forma:\nCuantificamos la variación que observamos de zona a zona y la variación que hay dentro de zonas. La variación que vemos entre las medianas de la zona es:\n\n\nCódigo\ncasas |> group_by(nombre_zona) |> \n  summarise(mediana_zona = median(precio_m2)) |> \n  pull(mediana_zona) |> quantile() |> round()\n\n\n  0%  25%  50%  75% 100% \n 963 1219 1298 1420 1725 \n\n\nY las variaciones con respecto a las medianas dentro de cada zona, agrupadas, se resume como:\n\n\nCódigo\nquantile(casas |> group_by(nombre_zona) |> \n  mutate(residual = precio_m2 - median(precio_m2)) |> \n  pull(residual)) |> round()\n\n\n  0%  25%  50%  75% 100% \n-765 -166    0  172 1314 \n\n\nNótese que este último paso tiene sentido pues la variación dentro de las zonas, en términos de precio por metro cuadrado, es similar. Esto no lo podríamos hacer de manera efectiva si hubiéramos usado el precio de las casas sin ajustar por su tamaño.\nY vemos que la mayor parte de la variación del precio por metro cuadrado ocurre dentro de cada zona, una vez que controlamos por el tamaño de las casas. La variación dentro de cada zona es aproximadamente simétrica, aunque la cola derecha es ligeramente más larga con algunos valores extremos."
  },
  {
    "objectID": "02-resumenes-analisis-1.html#factor-y-respuesta-numéricos-opcional",
    "href": "02-resumenes-analisis-1.html#factor-y-respuesta-numéricos-opcional",
    "title": "4  Resúmenes para datos numéricos",
    "section": "4.6 Factor y respuesta numéricos (opcional)",
    "text": "4.6 Factor y respuesta numéricos (opcional)\nEn las secciones anteriores vimos cómo describir “bonches” de datos numéricos y categóricos. Adicionalmente, vimos cómo usar esas técnicas para comparar las descripciones a lo largo de varios subconjuntos de los datos.\nEn estos casos, muchas veces llamamos factor a la variables que forma los grupos, y respuesta a la variable que estamos comparando. Por ejemplo, en el caso de los precios de las casas comparamos el precio de las casas (respuesta) dependiendo del vecindario (factor) dónde se encuentran.\nCuando tenemos una factor numérico y una respuesta numérica podemos comenzar haciendo diagramas de dispersión. Por ejemplo,"
  },
  {
    "objectID": "02-resumenes-analisis-1.html#ejemplo-cuenta-total-y-propina",
    "href": "02-resumenes-analisis-1.html#ejemplo-cuenta-total-y-propina",
    "title": "4  Resúmenes para datos numéricos",
    "section": "Ejemplo: cuenta total y propina",
    "text": "Ejemplo: cuenta total y propina\n\n\nCódigo\nlibrary(tidyverse)\nlibrary(patchwork)\nlibrary(kableExtra)\n# usamos los datos tips del paquete reshape2\npropinas <- read_csv(\"./datos/propinas.csv\")\n\n\nPodríamos comenzar haciendo:\n\n\nCódigo\nggplot(propinas, aes(x = cuenta_total, y = propina)) +\n   geom_point() + geom_rug(colour = \"salmon\", alpha = 0.5)\n\n\n\n\n\nAhora queremos comparar la distribución de propina (respuesta) para distintos niveles del factor (cuenta_total). Por ejemplo, ¿cómo se compara propina cuando la cuenta es de 15 dólares vs 30 dólares?\n\n\nCódigo\nggplot(propinas, aes(x = cuenta_total, y = propina)) +\n   geom_vline(xintercept = c(15, 30), colour = \"red\") +\n   geom_point() \n\n\n\n\n\nVemos que los datos de propinas alrededor de 30 dólares están centrados en valores más grandes que en el nivel de 15 dólares, y también que hay más dispersión en el nivel de 30 dólares. Sin embargo, vemos que tenemos un problema: existen realmente muy pocos datos que tengan exactamente 15 o 30 dólares de cuenta. La estrategia es entonces considerar qué sucede cuando la cuenta está alrededor de 15 o alrededor de 30 dólares, donde alrededor depende del problema particular y de cuántos datos tenemos:\n\n\nCódigo\nggplot(propinas, aes(x = cuenta_total, y = propina)) +\n   geom_ribbon(aes(xmin = 13, xmax = 17), fill = \"salmon\", alpha = 0.5) +\n   geom_ribbon(aes(xmin = 28, xmax = 32), fill = \"salmon\", alpha = 0.5) +\n   geom_point() \n\n\n\n\n\nConsiderando estos grupos de datos, podemos describir de las siguiente forma, por ejemplo:\n\n\nCódigo\npropinas |> \n   mutate(grupo = cut(cuenta_total,  breaks = c(0, 13, 17, 28, 32))) |> \n   filter(grupo %in% c(\"(13,17]\", \"(28,32]\")) |> \n   group_by(grupo) |> \n   summarise(\n      n = n(),\n      q10 = quantile(propina, 0.10),\n      mediana = quantile(propina, 0.5),\n      q90 = quantile(propina, 0.90),\n      rango_cuartiles = quantile(propina, 0.75) - quantile(propina, 0.25)) |> \n   kable(digits = 2) |> \n   kable_paper(full_width = FALSE)\n\n\n\n\n \n  \n    grupo \n    n \n    q10 \n    mediana \n    q90 \n    rango_cuartiles \n  \n \n\n  \n    (13,17] \n    57 \n    1.85 \n    2.47 \n    3.49 \n    1.0 \n  \n  \n    (28,32] \n    16 \n    2.02 \n    3.69 \n    5.76 \n    2.2 \n  \n\n\n\n\n\nDonde confirmamos que el nivel general de propinas es más alto alrededor de cuentas de total 30 que de total 15, y la dispersión también es mayor. Podríamos hacer un diagrama de caja y brazos también."
  },
  {
    "objectID": "02-resumenes-analisis-1.html#suavizadores-locales",
    "href": "02-resumenes-analisis-1.html#suavizadores-locales",
    "title": "4  Resúmenes para datos numéricos",
    "section": "4.7 Suavizadores locales",
    "text": "4.7 Suavizadores locales\nEl enfoque del ejemplo anterior puede ayudar en algunos casos nuestra tarea descriptiva, pero quisiéramos tener un método más general y completo para entender cómo es una respuesta numérica cuando el factor es también numérico.\nEn este caso, podemos hacer por ejemplo medias o medianas locales. La idea general es, en términos de nuestro ejemplo de propinas:\n\nQueremos producir un resumen en un valor de cuenta total \\(x\\).\nConsideramos valores de propina asociados a cuentas totales en un intervalo \\([x-e, x+e]\\).\nCalculamos estadísticas resumen en este rango para la respuesta\nUsualmente también ponderamos más alto valores que están cerca de \\(x\\) y ponderamos menos valores más lejanos a \\(x\\)\n\nEste tipo de suavizadores se llaman a veces suavizadores loess (ver (Cleveland 1993)).\nPor ejemplo,\n\n\nCódigo\nggplot(propinas, aes(x = cuenta_total, y = propina)) +\n   geom_ribbon(aes(xmin = 13, xmax = 17), fill = \"salmon\", alpha = 0.15) +\n   geom_ribbon(aes(xmin = 28, xmax = 32), fill = \"salmon\", alpha = 0.15) +\n   geom_point() +\n   geom_smooth(method = \"loess\", span = 0.5, degree= 0, \n               method.args = list(family = \"symmetric\"), se = FALSE) \n\n\n\n\n\nCódigo\n# symmetric es un método robusto iterativo, que reduce el peso de atípicos\n\n\nEl parametro span controla el tamaño de la ventana de datos que se toma en cada punto. Nótese como alrededor de 15 y 30 los valores por donde pasa el suavizador son similares a las medianas que escribimos arriba.\nPodemos ajustar en cada ventana tambien rectas de minimos cuadrados, y obtener un suavizador de tipo lineal. En la siguiente gráfica mostramos cómo funciona este suavizador para distintos tamaños de ventanas (span)\n\n\n\nSuavizador loess\n\n\n\n\n\nLos suavizadores loess tienen como fin mostrar alrededor de qué valor se distribuye la respuesta (eje vertical) para distintos valores del factor (eje horizontal). Se escoge span suficientemente baja de forma que mostremos patrones claros en los datos y casi no capturemos variación debida a los tamaños de muestra chicos.\n\n\nEn la animación anterior, un valor de span de 0.15 funciona apropiadamente, uno de 0.05 es demasiado bajo y uno de 1.0 es demasiado alto. Es importante explorar con el valor de span pues depende de cuántos datos tenemos y cómo es su dispersión.\nPodemos también mostrar estimaciones de medianas y cuantiles de la siguiente forma (nota: es necesario escoger lambda con cuidado, cuanto más alto sea lambda más suave es la curva obtenida):\n\n\nCódigo\nggplot(propinas, aes(x = cuenta_total, y = propina)) +\n   geom_ribbon(aes(xmin = 13, xmax = 17), fill = \"salmon\", alpha = 0.15) +\n   geom_ribbon(aes(xmin = 28, xmax = 32), fill = \"salmon\", alpha = 0.15) +\n   geom_point() +\n   geom_quantile(method = \"rqss\", lambda = 15, quantiles = c(0.25, 0.5, 0.75)) +\n   scale_y_continuous(breaks = seq(0, 10, 1))\n\n\n\n\n\nFinalmente, el entendimiento de los datos nos permite también hacer gráficas más útiles. En este caso particular podría, por ejemplo, calcular el porcentaje de la propina sobre la cuenta total:\n\n\nCódigo\npropinas <- mutate(propinas, pct_propina = propina / cuenta_total)\nggplot(propinas, aes(x = cuenta_total, y = pct_propina)) +\n   geom_point() +\n   scale_y_continuous(breaks = seq(0,1, 0.05)) +\n   geom_quantile(method = \"rqss\", lambda = 15, quantiles = c(0.25, 0.5, 0.75))\n\n\n\n\n\nObserva que la descripción es más simple que si usamos propina cruda y cuenta\n\nPara cuentas chicas, el porcentaje de propina puede ser muy alto (aún cuando la propina en sí no es tan grande):\n\n\n\nCódigo\nfilter(propinas, pct_propina > 0.30) |> \n  arrange(desc(pct_propina)) |> \n  kable(digits = 2) |> \n   kable_paper(full_width = FALSE)\n\n\n\n\n \n  \n    cuenta_total \n    propina \n    fumador \n    dia \n    momento \n    num_personas \n    pct_propina \n  \n \n\n  \n    7.25 \n    5.15 \n    Si \n    Dom \n    Cena \n    2 \n    0.71 \n  \n  \n    9.60 \n    4.00 \n    Si \n    Dom \n    Cena \n    2 \n    0.42 \n  \n  \n    3.07 \n    1.00 \n    Si \n    Sab \n    Cena \n    1 \n    0.33 \n  \n\n\n\n\n\n\nPara cuentas relativamente chicas (10 dólares, el porcentaje de propina está por encima de 15%). Este porcentaje tiende a reducirse a valores 10% y 15% para cuentas más grandes\nExiste variación considerable alrededor de estos valores centrales. El rango intercuartiles es aproximadamente de 5 puntos porcentuales.\n\nO de manera más resumida:\n\nLa mediana de propinas está ligeramente por arriba de 15% para cuantas relativamente chicas. Esta mediana baja hasta alrededor de 10%-15% para cuentas más grandes (más de 40 dólares)\nLa mitad de las propinas no varía más de unos 3 puntos porcentuales alrededor de estas medianas.\nExisten propinas atípicas: algunas muy bajas de 1 dólar, muy por debajo del 15%, y ocasionalmente algunas muy altas en porcentaje. Estas últimas ocurren ocasinalmente especialmente en cuentas chicas (por ejemplo, una propina de 1 dólar en una cuenta de 3 dólares).\n\n\n\n\n\nCleveland, William S. 1993. Visualizing Data. Hobart Press."
  },
  {
    "objectID": "02-resumenes-analisis-2.html",
    "href": "02-resumenes-analisis-2.html",
    "title": "5  Datos univariados categóricos",
    "section": "",
    "text": "En esta sección mostraremos cómo hacer distintos tipos de resúmenes para mediciones individuales. Consideraremos también el uso de estas descripciones para comparar distintos grupos (o bonches de datos, como les llamaba Tukey), aplicando repetidamente los mismos resúmenes a lo largo de esos distintos grupos."
  },
  {
    "objectID": "02-resumenes-analisis-2.html#datos-categóricos-y-tablas",
    "href": "02-resumenes-analisis-2.html#datos-categóricos-y-tablas",
    "title": "5  Datos univariados categóricos",
    "section": "5.1 Datos categóricos y tablas",
    "text": "5.1 Datos categóricos y tablas\nUna medición categórica es una que toma sus valores posibles en un conjunto que no es numérico. Consideremos los siguiente datos de 300 tomadores de té (Lê, Josse, y Husson (2008)):\n\n\nCódigo\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(kableExtra)\n\n\n\n\nCódigo\n# cargamos y traducimos los datos\nte_tbl <- read_csv(\"./datos/tea.csv\") |> \n   mutate(id = row_number()) |> \n   select(id, Tea, How, sugar, how, price, age) |> \n   rename(tipo = Tea, complementos = How, azucar = sugar, \n          presentacion = how, precio = price, edad = age) |> \n   mutate(tipo = recode(tipo, black = \"negro\", green = \"verde\", `Earl Grey` = \"earl_grey\"),\n          complementos = recode(complementos, alone = \"solo\", milk = \"leche\", \n                                lemon = \"limón\", .default = \"otros\"),\n          azucar = recode(azucar, sugar = \"con_azúcar\", No.sugar = \"sin_azúcar\"),\n          presentacion = recode(presentacion, `tea bag`=\"bolsa\", \n                                unpackaged = \"suelto\", .default = \"mixto\"),\n          precio = recode(precio, p_upscale = \"fino\", p_branded = \"de_marca\",\n                          p_private_label = \"marca_propia\", p_variable = \"variable\",\n                          .default = \"no_sabe\"))\nsample_n(te_tbl, 10) |> kable() |> \n   kable_paper(full_width = FALSE)\n\n\n\n\n \n  \n    id \n    tipo \n    complementos \n    azucar \n    presentacion \n    precio \n    edad \n  \n \n\n  \n    250 \n    earl_grey \n    solo \n    sin_azúcar \n    bolsa \n    de_marca \n    31 \n  \n  \n    286 \n    earl_grey \n    solo \n    sin_azúcar \n    bolsa \n    variable \n    31 \n  \n  \n    69 \n    earl_grey \n    limón \n    sin_azúcar \n    bolsa \n    variable \n    22 \n  \n  \n    132 \n    negro \n    solo \n    sin_azúcar \n    bolsa \n    de_marca \n    37 \n  \n  \n    292 \n    earl_grey \n    limón \n    con_azúcar \n    bolsa \n    no_sabe \n    72 \n  \n  \n    209 \n    verde \n    solo \n    con_azúcar \n    suelto \n    variable \n    27 \n  \n  \n    113 \n    earl_grey \n    solo \n    con_azúcar \n    bolsa \n    fino \n    71 \n  \n  \n    168 \n    negro \n    limón \n    sin_azúcar \n    suelto \n    fino \n    53 \n  \n  \n    30 \n    earl_grey \n    solo \n    con_azúcar \n    bolsa \n    variable \n    37 \n  \n  \n    229 \n    verde \n    solo \n    sin_azúcar \n    suelto \n    fino \n    25 \n  \n\n\n\n\n\nMediciones como tipo, presentación o azucar son variables categóricas. Desde el punto de vista univariado, generalmente no es necesario resumir, sino simplemente agrupar y contar cuántas veces ocurre cada categoría. Por ejemplo\n\n\nCódigo\n tabla_1 <- te_tbl |> count(tipo) |> \n    arrange(desc(n))\n tabla_1 |> kable() |> \n   kable_paper(full_width = FALSE)\n\n\n\n\n \n  \n    tipo \n    n \n  \n \n\n  \n    earl_grey \n    193 \n  \n  \n    negro \n    74 \n  \n  \n    verde \n    33 \n  \n\n\n\n\n\nUsualmente es más útil reportar la porporción o porcentaje de casos por categoría\n\n\nCódigo\n tabla_2 <- te_tbl |> \n    count(tipo) |> \n    mutate(n_total = sum(n), prop = n / n_total) |> \n    select(tipo, n_total, prop) |> \n    mutate(across(where(is.numeric), round, 2)) |> \n    arrange(desc(prop))\n tabla_2 |> kable() |> \n   kable_paper(full_width = FALSE)\n\n\n\n\n \n  \n    tipo \n    n_total \n    prop \n  \n \n\n  \n    earl_grey \n    300 \n    0.64 \n  \n  \n    negro \n    300 \n    0.25 \n  \n  \n    verde \n    300 \n    0.11 \n  \n\n\n\n\n\nPodemos hacer varias variables juntas de la siguiente manera:\n\n\nCódigo\n perfiles_col_tbl <- te_tbl |> select(id, tipo, complementos, presentacion, azucar) |>\n    pivot_longer(cols = tipo:azucar, names_to = \"variable\", values_to = \"valor\") |>\n    count(variable, valor) |>\n    group_by(variable) |>\n    mutate(n_total = sum(n), prop = n / n_total) |>\n    mutate(prop = round(prop, 2)) |>\n    arrange(desc(prop), .by_group = TRUE)\nperfiles_col_tbl |> \n   ungroup() |> \n   select(-variable, -n_total) |> \n   kable() |>  \n   pack_rows(index = table(perfiles_col_tbl$variable))\n\n\n\n\n \n  \n    valor \n    n \n    prop \n  \n \n\n  azucar\n\n    sin_azúcar \n    155 \n    0.52 \n  \n  \n    con_azúcar \n    145 \n    0.48 \n  \n  complementos\n\n    solo \n    195 \n    0.65 \n  \n  \n    leche \n    63 \n    0.21 \n  \n  \n    limón \n    33 \n    0.11 \n  \n  \n    otros \n    9 \n    0.03 \n  \n  presentacion\n\n    bolsa \n    170 \n    0.57 \n  \n  \n    mixto \n    94 \n    0.31 \n  \n  \n    suelto \n    36 \n    0.12 \n  \n  tipo\n\n    earl_grey \n    193 \n    0.64 \n  \n  \n    negro \n    74 \n    0.25 \n  \n  \n    verde \n    33 \n    0.11"
  },
  {
    "objectID": "02-resumenes-analisis-2.html#comparando-grupos-con-variables-categóricas",
    "href": "02-resumenes-analisis-2.html#comparando-grupos-con-variables-categóricas",
    "title": "5  Datos univariados categóricos",
    "section": "5.2 Comparando grupos con variables categóricas",
    "text": "5.2 Comparando grupos con variables categóricas\nEste análisis generalmente es más interesante cuando comparamos grupos. Supongamos que nos interesa ver si existe una relación entre usar el tipo de té que toman estas personas y el uso de complementos como leche o limón. Podríamos entonces dividir los datos según el uso de azúcar y repetir para cada grupo las tablas mostradas arriba:\n\n\nCódigo\nperfiles_col_tbl <- te_tbl |> count(complementos, tipo) |> \n   group_by(tipo) |> \n   mutate(prop = n / sum(n)) |>\n   group_by(complementos) |> \n   select(-n) |> \n   pivot_wider(names_from = tipo, values_from = prop, values_fill = 0)\nperfiles_col_tbl |>  kable(digits = 2, caption = \"Perfiles por columna\") |> \n   kable_paper(full_width = FALSE)\n\n\n\n\nPerfiles por columna\n \n  \n    complementos \n    earl_grey \n    negro \n    verde \n  \n \n\n  \n    leche \n    0.20 \n    0.26 \n    0.18 \n  \n  \n    limón \n    0.12 \n    0.09 \n    0.06 \n  \n  \n    otros \n    0.02 \n    0.08 \n    0.00 \n  \n  \n    solo \n    0.66 \n    0.57 \n    0.76 \n  \n\n\n\n\n\nComparando los perfiles de las columnas observamos variaciones interesantes: por ejemplo, los tomadores de Earl Grey tienden a usar más limón como complemento que otros grupos. Son resúmenes univariados que ahora comparamos a lo largo de grupos. Podemos hacer las comparaciones más simples si hacemos todas contra una columna marginal del uso general en la muestra de los distintos complementos\n\n\nCódigo\ncomp_tbl <- te_tbl |> count(complementos) |> mutate(total = n / sum(n))\nperfiles_col_tbl <- left_join(perfiles_col_tbl, comp_tbl) |> \n      arrange(desc(total)) |> \n      select(-n)\nperfiles_col_tbl |> kable(digits = 2) |> \n   kable_paper(full_width = FALSE)\n\n\n\n\n \n  \n    complementos \n    earl_grey \n    negro \n    verde \n    total \n  \n \n\n  \n    solo \n    0.66 \n    0.57 \n    0.76 \n    0.65 \n  \n  \n    leche \n    0.20 \n    0.26 \n    0.18 \n    0.21 \n  \n  \n    limón \n    0.12 \n    0.09 \n    0.06 \n    0.11 \n  \n  \n    otros \n    0.02 \n    0.08 \n    0.00 \n    0.03 \n  \n\n\n\n\n\nEn este punto, vemos que hay coincidencias y diferencias entre los grupos de tomadores de té. Podemos expresar esto de manera simple calculando índices contra la columna de total:\n\n\nCódigo\nres_tbl <- perfiles_col_tbl |> \n   mutate(across(where(is.numeric), ~ .x / total)) |> \n   select(-total)\nres_tbl |> kable(digits = 2) |> \n   kable_paper(full_width = FALSE)\n\n\n\n\n \n  \n    complementos \n    earl_grey \n    negro \n    verde \n  \n \n\n  \n    solo \n    1.02 \n    0.87 \n    1.17 \n  \n  \n    leche \n    0.94 \n    1.22 \n    0.87 \n  \n  \n    limón \n    1.13 \n    0.86 \n    0.55 \n  \n  \n    otros \n    0.52 \n    2.70 \n    0.00 \n  \n\n\n\n\n\nValores por encima de 1 indican columnas por arriba de la población general, y análogamente para valores por debajo de uno. Estas cantidades pueden escribirse en términos porcentuales, o se les puede restar 1 para terminar como una variación porcentual del promedio. A estas cantidades se les llama residuales crudos:\n\n\nCódigo\nres_tbl <- perfiles_col_tbl |> \n   mutate(across(where(is.numeric) & !total, ~ .x / total - 1)) \nres_tbl |> kable(digits = 2) |> \n   kable_paper(full_width = FALSE)\n\n\n\n\n \n  \n    complementos \n    earl_grey \n    negro \n    verde \n    total \n  \n \n\n  \n    solo \n    0.02 \n    -0.13 \n    0.17 \n    0.65 \n  \n  \n    leche \n    -0.06 \n    0.22 \n    -0.13 \n    0.21 \n  \n  \n    limón \n    0.13 \n    -0.14 \n    -0.45 \n    0.11 \n  \n  \n    otros \n    -0.48 \n    1.70 \n    -1.00 \n    0.03 \n  \n\n\n\n\n\nPodemos finalmente marcar la tabla:\n\n\nCódigo\nres_tbl |>  mutate(across(where(is.numeric), round, 2)) |> \n   mutate(across(where(is.numeric) & ! total, \n                 ~ cell_spec(.x, color = ifelse(.x > 0.1, \"black\", \n                                         ifelse(.x < -0.1, \"red\", \"gray\"))))) |>\n   arrange(desc(total)) |> \n   kable(escape = FALSE) |> \n   kable_paper(full_width = FALSE)\n\n\n\n\n \n  \n    complementos \n    earl_grey \n    negro \n    verde \n    total \n  \n \n\n  \n    solo \n    0.02 \n    -0.13 \n    0.17 \n    0.65 \n  \n  \n    leche \n    -0.06 \n    0.22 \n    -0.13 \n    0.21 \n  \n  \n    limón \n    0.13 \n    -0.14 \n    -0.45 \n    0.11 \n  \n  \n    otros \n    -0.48 \n    1.7 \n    -1 \n    0.03 \n  \n\n\n\n\n\n\n\n\n\n\n\nPerfiles\n\n\n\nA este tipo de análisis de tablas cruzadas a veces se le llama análisis de perfiles columna. Nos permite entender cómo varía la distribución de la variable de los renglones según el grupo indicado por la columna.\n\nDesviaciones grandes en los residuales indican asociaciones fuertes entre la variable de los reglones y de las columnas\nRecordemos que este análisis aplica a la muestra de datos que tenemos. Columnas con pocos individuos tienden a mostrar más variación y debemos ser cuidadosos al generalizar.\n\n\n\nPodemos incluir también totales para ayudarnos a juzgar las variaciones:\n\n\n\n\n \n  \n    complementos \n    earl_grey \n    negro \n    verde \n    total \n  \n \n\n  \n     \n    193 \n    74 \n    33 \n    1.00 \n  \n  \n    solo \n    0.02 \n    -0.13 \n    0.17 \n    0.65 \n  \n  \n    leche \n    -0.06 \n    0.22 \n    -0.13 \n    0.21 \n  \n  \n    limón \n    0.13 \n    -0.14 \n    -0.45 \n    0.11 \n  \n  \n    otros \n    -0.48 \n    1.7 \n    -1 \n    0.03"
  },
  {
    "objectID": "02-resumenes-analisis-2.html#observación-perfiles-renglón-y-columna",
    "href": "02-resumenes-analisis-2.html#observación-perfiles-renglón-y-columna",
    "title": "5  Datos univariados categóricos",
    "section": "5.3 Observación: perfiles renglón y columna",
    "text": "5.3 Observación: perfiles renglón y columna\nEl análisis también lo podemos hacer con los perfiles de los renglones. Los residuales crudos que usamos para interpretar son los mismos. La razón es la siguiente:\nPara los perfiles columna, si escribimos \\(n_{+j}\\) como los totales por columna, y \\(n_{i+}\\) los totales por renglón, tenemos que los perfiles columna son: \\[c_{i,j} = \\frac{n_{i,j}}{n_{+j}}\\] Escribimos también \\(c_i = \\frac{n_{i+}}{n}\\) y \\(r_j = \\frac{n_{+j}}{n}\\) como los porcentajes marginales por columna y por renglón respectivamente.\nLos residuales son entonces\n\\[r_{i,j} = \\frac{\\frac{n_{i,j}}{n_{+,j}}} { \\frac{n_{i,+}}{n}} - 1 = \\frac{p_{i,j} - r_ic_j}{r_ic_j}\\]\nNótese que no importa entonces cómo comencemos el cálculo, por renglones o por columnas, el resultado es el mismo."
  },
  {
    "objectID": "02-resumenes-analisis-2.html#visualización-de-tablas-cruzadas-opcional",
    "href": "02-resumenes-analisis-2.html#visualización-de-tablas-cruzadas-opcional",
    "title": "5  Datos univariados categóricos",
    "section": "5.4 Visualización de tablas cruzadas (opcional)",
    "text": "5.4 Visualización de tablas cruzadas (opcional)\nPara tablas más grandes, muchas veces las técnicas que mostramos arriba no son suficientes para entender y presentar patrones importantes en los datos. En estos casos, buscamos reducir la dimensionalidad de los datos para poder presentarlos en una gráfica de dos dimensiones.\nPodemos utilizar análisis de correspondencias. A grandes rasgos (ver (Izenman 2009) para los detalles) buscamos una representación tal que:\n\nCada categoría de las columnas está representada por una flecha que sale del origen de nuestra gráfica\nCada categoría de los renglones está representada por un punto en nuestra gráfica\nSi proyectamos los puntos (renglones) sobre las direcciones de las columnas, entonces el tamaño de la proyección es lo más cercano posible a el residual correspondiente de las tablas del análisis mostrado arriba.\n\nPara construir esta gráfica, entonces, existe un proceso de optimización que busca representar lo más fielmente los residuales del análisis mostrado arriba en dos dimensiones, y de esta forma buscamos recuperar una buena parte de la información de los residuales de una manera más compacta."
  },
  {
    "objectID": "02-resumenes-analisis-2.html#ejemplo-tés-y-complementos",
    "href": "02-resumenes-analisis-2.html#ejemplo-tés-y-complementos",
    "title": "5  Datos univariados categóricos",
    "section": "5.5 Ejemplo: tés y complementos",
    "text": "5.5 Ejemplo: tés y complementos\n\n\nCódigo\nlibrary(ca)\ncorr_te <- ca(table(te_tbl$complementos, te_tbl$tipo))\nplot(corr_te, map = \"rowprincipal\", arrows = c(FALSE, TRUE))\n\n\n\n\n\nLa contribución de cada dimensión a la aproximación se indica en los ejes y la suma de las contribuciones nos da la calidad de la representación, que en este caso es perfecta.\n\n\n\n\n\n\nNota\n\n\n\n\nEl análisis de correspondencias es un tema relativamente avanzado de estadística multivariada, y su definición precisa requiere de matemáticas más avanzadas (por ejemplo la descomposición en valores singulares).\nCualquier hallazgo obtenido en este tipo de análisis debe ser verificado en las tablas correspondientes de perfiles\nHay distintos tipos de gráficas (biplots) asociadas al análisis de correspondencias, que privilegian representar mejor diferentes características de los datos\n\n\n\n\n5.6 Ejemplo: robo en tiendas\n\nConsideramos los siguientes datos de robos en tiendas en Holanda por personas de distintas edades y genéros (Izenman (2009)). En este caso, las variables ya están cruzadas:\n\n\nCódigo\nhurto_tbl <- read_csv(\"./datos/hurto.csv\") |> \n   mutate(grupo = ifelse(grupo == \"-12 h\", \"01-12 h\", grupo),\n          grupo = ifelse(grupo == \"-12 m\", \"01-12 m\", grupo))\nhurto_tbl |> kable() |> \n   kable_paper()\n\n\n\n\n \n  \n    grupo \n    ropa \n    accesorios \n    tabaco \n    escritura \n    libros \n    discos \n    bienes \n    dulces \n    juguetes \n    joyería \n    perfumes \n    herramientas \n    otros \n  \n \n\n  \n    01-12 h \n    81 \n    66 \n    150 \n    667 \n    67 \n    24 \n    47 \n    430 \n    743 \n    132 \n    32 \n    197 \n    209 \n  \n  \n    12-14 h \n    138 \n    204 \n    340 \n    1409 \n    259 \n    272 \n    117 \n    637 \n    684 \n    408 \n    57 \n    547 \n    550 \n  \n  \n    15-17 h \n    304 \n    193 \n    229 \n    527 \n    258 \n    368 \n    98 \n    246 \n    116 \n    298 \n    61 \n    402 \n    454 \n  \n  \n    18-20 h \n    384 \n    149 \n    151 \n    84 \n    146 \n    141 \n    61 \n    40 \n    13 \n    71 \n    52 \n    138 \n    252 \n  \n  \n    21-29 h \n    942 \n    297 \n    313 \n    92 \n    251 \n    167 \n    193 \n    30 \n    16 \n    130 \n    111 \n    280 \n    624 \n  \n  \n    30-39 h \n    359 \n    109 \n    136 \n    36 \n    96 \n    67 \n    75 \n    11 \n    16 \n    31 \n    54 \n    200 \n    195 \n  \n  \n    40-49 h \n    178 \n    53 \n    121 \n    36 \n    48 \n    29 \n    50 \n    5 \n    6 \n    14 \n    41 \n    152 \n    88 \n  \n  \n    50-64 h \n    137 \n    68 \n    171 \n    37 \n    56 \n    27 \n    55 \n    17 \n    3 \n    11 \n    50 \n    211 \n    90 \n  \n  \n    64+ h \n    45 \n    28 \n    145 \n    17 \n    41 \n    7 \n    29 \n    28 \n    8 \n    10 \n    28 \n    111 \n    34 \n  \n  \n    01-12 m \n    71 \n    19 \n    59 \n    224 \n    19 \n    7 \n    22 \n    137 \n    113 \n    162 \n    70 \n    15 \n    24 \n  \n  \n    12-14 m \n    241 \n    98 \n    111 \n    346 \n    60 \n    32 \n    29 \n    240 \n    98 \n    548 \n    178 \n    29 \n    58 \n  \n  \n    15-17 m \n    477 \n    114 \n    58 \n    91 \n    50 \n    27 \n    41 \n    80 \n    14 \n    303 \n    141 \n    9 \n    72 \n  \n  \n    18-20 m \n    436 \n    108 \n    76 \n    18 \n    32 \n    12 \n    32 \n    12 \n    10 \n    74 \n    70 \n    14 \n    67 \n  \n  \n    21-29 m \n    1180 \n    207 \n    132 \n    30 \n    61 \n    21 \n    65 \n    16 \n    12 \n    100 \n    104 \n    30 \n    157 \n  \n  \n    30-39 m \n    1009 \n    165 \n    121 \n    27 \n    43 \n    9 \n    74 \n    14 \n    31 \n    48 \n    81 \n    36 \n    107 \n  \n  \n    40-49 m \n    517 \n    102 \n    93 \n    23 \n    31 \n    7 \n    51 \n    10 \n    8 \n    22 \n    46 \n    24 \n    66 \n  \n  \n    50-64 m \n    488 \n    127 \n    214 \n    27 \n    57 \n    13 \n    79 \n    23 \n    17 \n    26 \n    69 \n    35 \n    64 \n  \n  \n    64+ m \n    173 \n    64 \n    215 \n    13 \n    44 \n    0 \n    39 \n    42 \n    6 \n    12 \n    41 \n    11 \n    55 \n  \n\n\n\n\n\nEsta tabla es más grande y difícil de entender tal cual está. Comenzamos por examinar las marginales:\n\n\nCódigo\nhurto_tbl |> \n   pivot_longer(cols = ropa:otros, names_to = \"producto\", values_to = \"n\") |> \n   group_by(producto) |> \n   summarise(n = sum(n)) |> \n   mutate(prop = n / sum(n)) |> \n   arrange(desc(prop)) |> \n   kable(digits = 2) |> \n   kable_paper()\n\n\n\n\n \n  \n    producto \n    n \n    prop \n  \n \n\n  \n    ropa \n    7160 \n    0.22 \n  \n  \n    escritura \n    3704 \n    0.11 \n  \n  \n    otros \n    3166 \n    0.10 \n  \n  \n    tabaco \n    2835 \n    0.09 \n  \n  \n    herramientas \n    2441 \n    0.07 \n  \n  \n    joyería \n    2400 \n    0.07 \n  \n  \n    accesorios \n    2171 \n    0.07 \n  \n  \n    dulces \n    2018 \n    0.06 \n  \n  \n    juguetes \n    1914 \n    0.06 \n  \n  \n    libros \n    1619 \n    0.05 \n  \n  \n    perfumes \n    1286 \n    0.04 \n  \n  \n    discos \n    1230 \n    0.04 \n  \n  \n    bienes \n    1157 \n    0.03 \n  \n\n\n\n\n\n\n\nCódigo\ngrupos_tbl <- hurto_tbl |> \n   pivot_longer(cols = ropa:otros, names_to = \"producto\", values_to = \"n\") |> \n   group_by(grupo) |> \n   summarise(n = sum(n)) |> \n   mutate(prop = n / sum(n)) |> \n   arrange(desc(prop))\ngrupos_tbl |> kable(digits = 2) |> \n   kable_paper()\n\n\n\n\n \n  \n    grupo \n    n \n    prop \n  \n \n\n  \n    12-14 h \n    5622 \n    0.17 \n  \n  \n    15-17 h \n    3554 \n    0.11 \n  \n  \n    21-29 h \n    3446 \n    0.10 \n  \n  \n    01-12 h \n    2845 \n    0.09 \n  \n  \n    21-29 m \n    2115 \n    0.06 \n  \n  \n    12-14 m \n    2068 \n    0.06 \n  \n  \n    30-39 m \n    1765 \n    0.05 \n  \n  \n    18-20 h \n    1682 \n    0.05 \n  \n  \n    15-17 m \n    1477 \n    0.04 \n  \n  \n    30-39 h \n    1385 \n    0.04 \n  \n  \n    50-64 m \n    1239 \n    0.04 \n  \n  \n    40-49 m \n    1000 \n    0.03 \n  \n  \n    18-20 m \n    961 \n    0.03 \n  \n  \n    01-12 m \n    942 \n    0.03 \n  \n  \n    50-64 h \n    933 \n    0.03 \n  \n  \n    40-49 h \n    821 \n    0.02 \n  \n  \n    64+ m \n    715 \n    0.02 \n  \n  \n    64+ h \n    531 \n    0.02 \n  \n\n\n\n\n\nIntentamos análisis de correspondencias para comparar los perfiles columna:\n\n\nCódigo\nhurto_df <- as.data.frame(hurto_tbl)\nrownames(hurto_df) <- hurto_tbl$grupo\nhurto_df$grupo <- NULL\ncorr_hurto <- ca(hurto_df)\ngrafica_datos <- plot(corr_hurto, map = \"rowgreen\", arrows = c(FALSE, TRUE))\n\n\n\n\n\n\nSegún esta gráfica, ¿qué categorias de productos están sobrerrepresentadas en cada grupo de edad? ¿Cómo tendrían que verse el análisis de perfiles columna?\n\nComo se aprecia, en la siguiente tabla, es difícil entender los patrones generales en los datos. Quitamos algunas columnas para imprimir más fácilmente\n\n\nCódigo\nperfiles_hurto_tbl <- hurto_tbl |> \n   pivot_longer(cols = ropa:otros, names_to = \"producto\", values_to = \"n\") |> \n   group_by(producto) |> \n   mutate(prop = n / sum(n)) |> \n   select(-n) |> \n   pivot_wider(names_from = producto, values_from = prop) \nperfiles_hurto_tbl |> \n   select(-bienes, -discos, -perfumes) |> \n   kable(digits = 2) |> \n   kable_styling(font_size = 10)\n\n\n\n\n \n  \n    grupo \n    ropa \n    accesorios \n    tabaco \n    escritura \n    libros \n    dulces \n    juguetes \n    joyería \n    herramientas \n    otros \n  \n \n\n  \n    01-12 h \n    0.01 \n    0.03 \n    0.05 \n    0.18 \n    0.04 \n    0.21 \n    0.39 \n    0.06 \n    0.08 \n    0.07 \n  \n  \n    12-14 h \n    0.02 \n    0.09 \n    0.12 \n    0.38 \n    0.16 \n    0.32 \n    0.36 \n    0.17 \n    0.22 \n    0.17 \n  \n  \n    15-17 h \n    0.04 \n    0.09 \n    0.08 \n    0.14 \n    0.16 \n    0.12 \n    0.06 \n    0.12 \n    0.16 \n    0.14 \n  \n  \n    18-20 h \n    0.05 \n    0.07 \n    0.05 \n    0.02 \n    0.09 \n    0.02 \n    0.01 \n    0.03 \n    0.06 \n    0.08 \n  \n  \n    21-29 h \n    0.13 \n    0.14 \n    0.11 \n    0.02 \n    0.16 \n    0.01 \n    0.01 \n    0.05 \n    0.11 \n    0.20 \n  \n  \n    30-39 h \n    0.05 \n    0.05 \n    0.05 \n    0.01 \n    0.06 \n    0.01 \n    0.01 \n    0.01 \n    0.08 \n    0.06 \n  \n  \n    40-49 h \n    0.02 \n    0.02 \n    0.04 \n    0.01 \n    0.03 \n    0.00 \n    0.00 \n    0.01 \n    0.06 \n    0.03 \n  \n  \n    50-64 h \n    0.02 \n    0.03 \n    0.06 \n    0.01 \n    0.03 \n    0.01 \n    0.00 \n    0.00 \n    0.09 \n    0.03 \n  \n  \n    64+ h \n    0.01 \n    0.01 \n    0.05 \n    0.00 \n    0.03 \n    0.01 \n    0.00 \n    0.00 \n    0.05 \n    0.01 \n  \n  \n    01-12 m \n    0.01 \n    0.01 \n    0.02 \n    0.06 \n    0.01 \n    0.07 \n    0.06 \n    0.07 \n    0.01 \n    0.01 \n  \n  \n    12-14 m \n    0.03 \n    0.05 \n    0.04 \n    0.09 \n    0.04 \n    0.12 \n    0.05 \n    0.23 \n    0.01 \n    0.02 \n  \n  \n    15-17 m \n    0.07 \n    0.05 \n    0.02 \n    0.02 \n    0.03 \n    0.04 \n    0.01 \n    0.13 \n    0.00 \n    0.02 \n  \n  \n    18-20 m \n    0.06 \n    0.05 \n    0.03 \n    0.00 \n    0.02 \n    0.01 \n    0.01 \n    0.03 \n    0.01 \n    0.02 \n  \n  \n    21-29 m \n    0.16 \n    0.10 \n    0.05 \n    0.01 \n    0.04 \n    0.01 \n    0.01 \n    0.04 \n    0.01 \n    0.05 \n  \n  \n    30-39 m \n    0.14 \n    0.08 \n    0.04 \n    0.01 \n    0.03 \n    0.01 \n    0.02 \n    0.02 \n    0.01 \n    0.03 \n  \n  \n    40-49 m \n    0.07 \n    0.05 \n    0.03 \n    0.01 \n    0.02 \n    0.00 \n    0.00 \n    0.01 \n    0.01 \n    0.02 \n  \n  \n    50-64 m \n    0.07 \n    0.06 \n    0.08 \n    0.01 \n    0.04 \n    0.01 \n    0.01 \n    0.01 \n    0.01 \n    0.02 \n  \n  \n    64+ m \n    0.02 \n    0.03 \n    0.08 \n    0.00 \n    0.03 \n    0.02 \n    0.00 \n    0.00 \n    0.00 \n    0.02 \n  \n\n\n\n\n\n\n\nCódigo\nres_hurto_tbl <- left_join(perfiles_hurto_tbl, grupos_tbl |> rename(total = prop)) |> \n    select(-n) |> \n    select(-bienes, -discos, -perfumes) |> \n    mutate(across(where(is.numeric) & !total, ~ .x / total - 1)) |> \n    mutate(across(where(is.numeric), round, 2)) \nres_hurto_tbl |> \n    mutate(across(where(is.numeric) & ! total, \n                 ~ cell_spec(.x, color = ifelse(.x > 0.2, \"black\", \n                                         ifelse(.x < -0.2, \"red\", \"gray\"))))) |>\n    select(-total) |> \n    kable(escape = FALSE) |>\n    kable_styling(font_size = 10)\n\n\n\n\n \n  \n    grupo \n    ropa \n    accesorios \n    tabaco \n    escritura \n    libros \n    dulces \n    juguetes \n    joyería \n    herramientas \n    otros \n  \n \n\n  \n    01-12 h \n    -0.87 \n    -0.65 \n    -0.38 \n    1.1 \n    -0.52 \n    1.48 \n    3.52 \n    -0.36 \n    -0.06 \n    -0.23 \n  \n  \n    12-14 h \n    -0.89 \n    -0.45 \n    -0.29 \n    1.24 \n    -0.06 \n    0.86 \n    1.1 \n    0 \n    0.32 \n    0.02 \n  \n  \n    15-17 h \n    -0.6 \n    -0.17 \n    -0.25 \n    0.33 \n    0.48 \n    0.14 \n    -0.44 \n    0.16 \n    0.53 \n    0.34 \n  \n  \n    18-20 h \n    0.06 \n    0.35 \n    0.05 \n    -0.55 \n    0.77 \n    -0.61 \n    -0.87 \n    -0.42 \n    0.11 \n    0.57 \n  \n  \n    21-29 h \n    0.26 \n    0.31 \n    0.06 \n    -0.76 \n    0.49 \n    -0.86 \n    -0.92 \n    -0.48 \n    0.1 \n    0.89 \n  \n  \n    30-39 h \n    0.2 \n    0.2 \n    0.15 \n    -0.77 \n    0.42 \n    -0.87 \n    -0.8 \n    -0.69 \n    0.96 \n    0.47 \n  \n  \n    40-49 h \n    0 \n    -0.02 \n    0.72 \n    -0.61 \n    0.2 \n    -0.9 \n    -0.87 \n    -0.76 \n    1.51 \n    0.12 \n  \n  \n    50-64 h \n    -0.32 \n    0.11 \n    1.14 \n    -0.65 \n    0.23 \n    -0.7 \n    -0.94 \n    -0.84 \n    2.07 \n    0.01 \n  \n  \n    64+ h \n    -0.61 \n    -0.2 \n    2.19 \n    -0.71 \n    0.58 \n    -0.14 \n    -0.74 \n    -0.74 \n    1.83 \n    -0.33 \n  \n  \n    01-12 m \n    -0.65 \n    -0.69 \n    -0.27 \n    1.13 \n    -0.59 \n    1.39 \n    1.07 \n    1.37 \n    -0.78 \n    -0.73 \n  \n  \n    12-14 m \n    -0.46 \n    -0.28 \n    -0.37 \n    0.5 \n    -0.41 \n    0.9 \n    -0.18 \n    2.65 \n    -0.81 \n    -0.71 \n  \n  \n    15-17 m \n    0.49 \n    0.18 \n    -0.54 \n    -0.45 \n    -0.31 \n    -0.11 \n    -0.84 \n    1.83 \n    -0.92 \n    -0.49 \n  \n  \n    18-20 m \n    1.1 \n    0.71 \n    -0.08 \n    -0.83 \n    -0.32 \n    -0.8 \n    -0.82 \n    0.06 \n    -0.8 \n    -0.27 \n  \n  \n    21-29 m \n    1.58 \n    0.49 \n    -0.27 \n    -0.87 \n    -0.41 \n    -0.88 \n    -0.9 \n    -0.35 \n    -0.81 \n    -0.22 \n  \n  \n    30-39 m \n    1.64 \n    0.43 \n    -0.2 \n    -0.86 \n    -0.5 \n    -0.87 \n    -0.7 \n    -0.62 \n    -0.72 \n    -0.37 \n  \n  \n    40-49 m \n    1.39 \n    0.56 \n    0.09 \n    -0.79 \n    -0.37 \n    -0.84 \n    -0.86 \n    -0.7 \n    -0.67 \n    -0.31 \n  \n  \n    50-64 m \n    0.82 \n    0.56 \n    1.02 \n    -0.81 \n    -0.06 \n    -0.7 \n    -0.76 \n    -0.71 \n    -0.62 \n    -0.46 \n  \n  \n    64+ m \n    0.12 \n    0.36 \n    2.51 \n    -0.84 \n    0.26 \n    -0.04 \n    -0.85 \n    -0.77 \n    -0.79 \n    -0.2 \n  \n\n\n\n\n\n\nCompara tus conclusiones del mapa de correspondencias con esta información de los residuales\n\nNota adicionalmente que el ordenamiento de las categorías en la primera dimensión del mapa de correspondencias ayuda a interpretar:\n\n\nCódigo\nres_hurto_tbl |> select(\"grupo\", \"escritura\", \"juguetes\", \"dulces\", \"joyería\",\n                         \"herramientas\", \"otros\", \"libros\", \"tabaco\", \"accesorios\", \n                         \"ropa\") |> \n    mutate(across(where(is.numeric), \n                 ~ cell_spec(.x, color = ifelse(.x > 0.2, \"black\", \n                                         ifelse(.x < -0.2, \"red\", \"gray\"))))) |>\n    kable(escape = FALSE) |>\n    kable_styling(font_size = 10)\n\n\n\n\n \n  \n    grupo \n    escritura \n    juguetes \n    dulces \n    joyería \n    herramientas \n    otros \n    libros \n    tabaco \n    accesorios \n    ropa \n  \n \n\n  \n    01-12 h \n    1.1 \n    3.52 \n    1.48 \n    -0.36 \n    -0.06 \n    -0.23 \n    -0.52 \n    -0.38 \n    -0.65 \n    -0.87 \n  \n  \n    12-14 h \n    1.24 \n    1.1 \n    0.86 \n    0 \n    0.32 \n    0.02 \n    -0.06 \n    -0.29 \n    -0.45 \n    -0.89 \n  \n  \n    15-17 h \n    0.33 \n    -0.44 \n    0.14 \n    0.16 \n    0.53 \n    0.34 \n    0.48 \n    -0.25 \n    -0.17 \n    -0.6 \n  \n  \n    18-20 h \n    -0.55 \n    -0.87 \n    -0.61 \n    -0.42 \n    0.11 \n    0.57 \n    0.77 \n    0.05 \n    0.35 \n    0.06 \n  \n  \n    21-29 h \n    -0.76 \n    -0.92 \n    -0.86 \n    -0.48 \n    0.1 \n    0.89 \n    0.49 \n    0.06 \n    0.31 \n    0.26 \n  \n  \n    30-39 h \n    -0.77 \n    -0.8 \n    -0.87 \n    -0.69 \n    0.96 \n    0.47 \n    0.42 \n    0.15 \n    0.2 \n    0.2 \n  \n  \n    40-49 h \n    -0.61 \n    -0.87 \n    -0.9 \n    -0.76 \n    1.51 \n    0.12 \n    0.2 \n    0.72 \n    -0.02 \n    0 \n  \n  \n    50-64 h \n    -0.65 \n    -0.94 \n    -0.7 \n    -0.84 \n    2.07 \n    0.01 \n    0.23 \n    1.14 \n    0.11 \n    -0.32 \n  \n  \n    64+ h \n    -0.71 \n    -0.74 \n    -0.14 \n    -0.74 \n    1.83 \n    -0.33 \n    0.58 \n    2.19 \n    -0.2 \n    -0.61 \n  \n  \n    01-12 m \n    1.13 \n    1.07 \n    1.39 \n    1.37 \n    -0.78 \n    -0.73 \n    -0.59 \n    -0.27 \n    -0.69 \n    -0.65 \n  \n  \n    12-14 m \n    0.5 \n    -0.18 \n    0.9 \n    2.65 \n    -0.81 \n    -0.71 \n    -0.41 \n    -0.37 \n    -0.28 \n    -0.46 \n  \n  \n    15-17 m \n    -0.45 \n    -0.84 \n    -0.11 \n    1.83 \n    -0.92 \n    -0.49 \n    -0.31 \n    -0.54 \n    0.18 \n    0.49 \n  \n  \n    18-20 m \n    -0.83 \n    -0.82 \n    -0.8 \n    0.06 \n    -0.8 \n    -0.27 \n    -0.32 \n    -0.08 \n    0.71 \n    1.1 \n  \n  \n    21-29 m \n    -0.87 \n    -0.9 \n    -0.88 \n    -0.35 \n    -0.81 \n    -0.22 \n    -0.41 \n    -0.27 \n    0.49 \n    1.58 \n  \n  \n    30-39 m \n    -0.86 \n    -0.7 \n    -0.87 \n    -0.62 \n    -0.72 \n    -0.37 \n    -0.5 \n    -0.2 \n    0.43 \n    1.64 \n  \n  \n    40-49 m \n    -0.79 \n    -0.86 \n    -0.84 \n    -0.7 \n    -0.67 \n    -0.31 \n    -0.37 \n    0.09 \n    0.56 \n    1.39 \n  \n  \n    50-64 m \n    -0.81 \n    -0.76 \n    -0.7 \n    -0.71 \n    -0.62 \n    -0.46 \n    -0.06 \n    1.02 \n    0.56 \n    0.82 \n  \n  \n    64+ m \n    -0.84 \n    -0.85 \n    -0.04 \n    -0.77 \n    -0.79 \n    -0.2 \n    0.26 \n    2.51 \n    0.36 \n    0.12 \n  \n\n\n\n\n\n\nOtras dimensiones\nEn el caso anterior, la calidad de la representación es cercana al 80%. Existen algunas desviaciones que la posiblemente la gŕafica no explica del todo, y algunas proyecciones son aproximadas. Podemos ver cómo se ven otras dimensiones de este análisis para entender desviaciones adicionales:\n\n\nCódigo\nplot(corr_hurto, dim = c(1, 3), map = \"rowprincipal\", arrows = c(FALSE, TRUE))\n\n\n\n\n\n\n\n\n\nIzenman, A. J. 2009. Modern Multivariate Statistical Techniques: Regression, Classification, and Manifold Learning. Springer Texts en Statistics. Springer New York. https://books.google.com.mx/books?id=1CuznRORa3EC.\n\n\nLê, Sébastien, Julie Josse, y François Husson. 2008. «FactoMineR: An R Package for Multivariate Analysis». Journal of Statistical Software, Articles 25 (1): 1-18. https://doi.org/10.18637/jss.v025.i01."
  },
  {
    "objectID": "03-intro-inferencia.html",
    "href": "03-intro-inferencia.html",
    "title": "Inferencia estadística: pruebas de hipótesis",
    "section": "",
    "text": "A grandes rasgos, en la inferencia estadística buscamos hacer afirmaciones acerca de una colección de datos de la cual sólo tenemos información parcial.\nNos concentraremos en dos de las situaciones más comunes:\nPor ejemplo, consideremos esta población de 15 personas:\nPara una muestra de ellos tenemos información acerca de su estatura y peso. ¿Qué podríamos decir acerca de la estatura y el peso de la población general?\nEn este caso, la situación se ve como sigue. Imaginemos que tenemos 15 personas con dolor de cabeza, y obtenemos los siguientes datos:\nNuestra pregunta en este caso es del tipo: ¿ayuda la aspirina a reducir el dolor de cabeza en esta población? ¿qué tanto ayuda? Igualmente, tenemos información incompleta, en el sentido de que sólo observamos un resultado potencial de cada persona, dependiendo de si tomó aspirina o no. Si supiéramos los dos resultados potenciales de cada persona entonces podríamos contestar la pregunta sin dificultad."
  },
  {
    "objectID": "03-intro-inferencia.html#proceso-de-selección-o-asignación",
    "href": "03-intro-inferencia.html#proceso-de-selección-o-asignación",
    "title": "Inferencia estadística: pruebas de hipótesis",
    "section": "Proceso de selección o asignación",
    "text": "Proceso de selección o asignación\nLas preguntas que planteamos arriba son difíciles de contestar cuando no conocemos bien el proceso de selección de individuos en la muestra o no conocemos el proceso de asignación de la aspirina.\nPor ejemplo, llegaríamos a conclusiones muy distintas si nos dijeran que:\n\nEscogimos las 5 personas que usan ropa talla chica.\nEscogimos las 5 personas que llegaron primero en una carrera de 100 metros.\nEscogimos las personas cuyo día de nacimiento era más bajo.\n\nO en el ejemplo de la aspirina,\n\nSólo dimos aspirinas a las personas que reportaron un nivel de dolor de cabeza muy alto.\nSolo dimos aspirina a las personas que llegaron primero en una carrera de 100 metros.\nDimos una aspirina exclusivamente a las personas cuyo día de nacimiento es par.\n\n\n\n\n\n\n\nTip\n\n\n\nDiscute qué conclusiones podrías llegar en cada uno de estos escenarios. Puedes usar diagramas como los de la sección anterior para explicar tus respuestas.\n\n\nLos casos 1 y 2 en ambas poblaciones son en general difíciles de resolver adecuadamente, y explicaremos con más ejemplos. Adicionalmente, es también más difícil cuantificar el nivel de incertidumbre de nuestras respuestas, pues dependen de muchos detalles del proceso de selección o asignación.\n\n\n\n\n\n\nProceso generador de datos y selección/asignación\n\n\n\nCuando el proceso de selección de observaciones o asignación tiene relaciones complicadas con las cantidades de interés, puede ser muy difícil dar respuesta a preguntas inferenciales de manera adecuada, y es importante entender el proceso que genera los datos, muchas veces a un nivel muy detallado."
  },
  {
    "objectID": "03-intro-pruebas-hipotesis.html",
    "href": "03-intro-pruebas-hipotesis.html",
    "title": "6  Introducción a pruebas de hipótesis",
    "section": "",
    "text": "Las primeras técnicas que veremos intentan contestar la siguiente pregunta:\n\nSi observamos cierto patrón en los datos, ¿cómo podemos cuantificar la evidencia de que es un patrón notable y no sólo debido a fluctuaciones en los datos particulares que tenemos? ¿Cómo sabemos que no estamos sobreinterpretando esas fluctuaciones?\n\nPor ejemplo:\n\nUn sistema tiene cierto comportamiento “usual” para el cual tenemos datos históricos. El sistema presenta fluctuaciones en el tiempo.\nObservamos la última salida de nuestro sistema. Naturalmente, tiene fluctuaciones. ¿Esas fluctuaciones son consistentes con la operación usual del sistema? ¿Existe evidencia para pensar que algo en el sistema cambió?"
  },
  {
    "objectID": "03-intro-pruebas-hipotesis.html#comparación-con-poblaciones-de-referencia",
    "href": "03-intro-pruebas-hipotesis.html#comparación-con-poblaciones-de-referencia",
    "title": "6  Introducción a pruebas de hipótesis",
    "section": "6.2 Comparación con poblaciones de referencia",
    "text": "6.2 Comparación con poblaciones de referencia\nEn las prueba de hipótesis, tratamos de construir distribuciones de referencia para comparar resultados que obtengamos con un “estándar” de variación, y juzgar si nuestros resultados son consistentes con la referencia o no (Box et al. (1978)).\nEn algunos casos, ese estándar de variación puede construirse con datos históricos.\n\nEjemplo\nSupongamos que estamos considerando cambios rápidos en una serie de tiempo de alta frecuencia. Hemos observado la serie en su estado “normal” durante un tiempo considerable, y cuando observamos nuevos datos quisiéramos juzgar si hay indicaciones o evidencia en contra de que el sistema sigue funcionando de manera similar.\nDigamos que monitoreamos ventanas de tiempo de tamaño 20 y necesitamos tomar una decisión. Abajo mostramos cinco ejemplos donde el sistema opera normalmente, que muestra la variabilidad en el tiempo en ventanas cortas del sistema.\nAhora suponemos que obtenemos una nueva ventana de datos. ¿Hay evidencia en contra de que el sistema sigue funcionando de manera similar?\nNuestra primera inclinación debe ser comparar: en este caso, compararamos ventanas históricas con nuestra nueva serie:\n\n\n\n\n\nCódigo\n# usamos datos simulados para este ejemplo\nset.seed(8812)\nhistoricos <- simular_serie(2000)\n\n\n\n\n\n\n\n¿Vemos algo diferente en los datos nuevos (el panel de color diferente)?\nIndpendientemente de la respuesta, vemos que hacer este análisis de manera tan simple no es siempre útil: seguramente podemos encontrar maneras en que la nueva muestra (4) es diferente a muestras históricas. Por ejemplo, ninguna de muestras tiene un “forma de montaña” tan clara.\nNos preguntamos si no estamos sobreinterpretando variaciones que son parte normal del proceso.\nPodemos hacer un mejor análisis si extraemos varias muestras del comportamiento usual del sistema, graficamos junto a la nueva muestra, y revolvemos las gráficas para que no sepamos cuál es cuál. Entonces la pregunta es:\n\n¿Podemos detectar donde están los datos nuevos?\n\nEsta se llama una prueba de lineup, o una prueba de ronda de sospechosos (Wickham et al. (2010)). En la siguiente gráfica, en uno de los páneles están los datos recientemente observados. ¿Hay algo en los datos que distinga al patrón nuevo?\n\n\nCódigo\n# nuevos datos\nobs <- simular_serie(500, x_inicial = last(obs$obs))\n# muestrear datos históricos\nprueba_tbl <- muestrear_ventanas(historicos, obs[1:20, ], n_ventana = 20)\n# gráfica de pequeños múltiplos\nggplot(prueba_tbl$lineup, aes(x = t_0, y = obs)) + geom_line() + \n     facet_wrap(~rep, nrow = 4) + scale_y_log10()\n\n\n\n\n\nEjercicio: ¿cuáles son los datos nuevos (solo hay un panel con los nuevos datos)? ¿Qué implica que la gráfica que escogamos como “más diferente” no sean los datos nuevos? ¿Qué implica que le “atinemos” a la gráfica de los datos nuevos?\nAhora observamos al sistema en otro momento y repetimos la comparación. En el siguiente caso obtenemos:\n\n\n\n\n\nAunque es imposible estar seguros de que ha ocurrido un cambio, la diferencia de una de las series es muy considerable. Si identificamos los datos correctos, la probabilidad de que hayamos señalado la nueva serie “sobreinterpretando” fluctuaciones en un proceso que sigue comportándose normalente es 0.05 - relativamente baja. Detectar los datos diferentes es evidencia en contra de que el sistema sigue funcionando de la misma manera que antes.\nObservaciones y terminología:\n\nLlamamos hipótesis nula a la hipótesis de que los nuevos datos son producidos bajo las mismas condiciones que los datos de control o de referencia.\nSi no escogemos la gráfica de los nuevos datos, nuestra conclusión es que la prueba no aporta evidencia en contra de la hipótesis nula.\nSi escogemos la gráfica correcta, nuestra conclusión es que la prueba aporta evidencia en contra de la hipótesis nula.\n\n¿Qué tan fuerte es la evidencia, en caso de que descubrimos los datos no nulos?\n\nCuando el número de paneles es más grande y detectamos los datos, la evidencia es más alta en contra de la nula. Decimos que el nivel de significancia de la prueba es la probabilidad de seleccionar a los datos correctos cuando la hipótesis nula es cierta (el sistema no ha cambiado). En el caso de 20 paneles, la significancia es de 1/20 = 0.05.\nSi acertamos, y la diferencia es más notoria y fue muy fácil detectar la gráfica diferente (pues sus diferencias son más extremas), esto también sugiere más evidencia en contra de la hipótesis nula.\nFinalmente, esta prueba rara vez (o nunca) nos da seguridad completa acerca de ninguna conclusión, aún cuando hiciéramos muchos páneles.\n\n\n\n\n\n\n\nNota\n\n\n\nPruebas de hipótesis\nEn su escencia, en las pruebas de hipótesis comparamos los datos de interés con una colección de datos de referencia. Nuestro interés es decidir si los datos de interés son consistentes con los datos de referencia. Veremos que hay distintas maneras de definir “consistencia”:\n\nPodemos preguntarnos si el proceso generador de los datos de interés es consistente con el proceso generador de los datos de referencia\nPodemos también preguntarnos por aspectos particulares del proceso generador, por ejemplo, si los datos parecen tener valores excepcionalmente grandes o excepcionalmente chicos, si tienen más dispersión que los datos de referencia, etc."
  },
  {
    "objectID": "03-intro-pruebas-hipotesis.html#cuantificando-la-distribución-de-referencia",
    "href": "03-intro-pruebas-hipotesis.html#cuantificando-la-distribución-de-referencia",
    "title": "6  Introducción a pruebas de hipótesis",
    "section": "6.3 Cuantificando la distribución de referencia",
    "text": "6.3 Cuantificando la distribución de referencia\nEn el ejemplo anterior estamos intentando dectectar cualquier desviación del comportamiento normal del sistema de una manera rigurosa. Podemos hacerlo más cuantitativo creando estadísticas resumen de las series. Por ejemplo, podríamos utilizar la variabilidad que tienen las series alrededor de su nivel general.\n\n\nCódigo\nsd_simple <- function(x){\n  # suavizamiento exponencial\n  mod <- HoltWinters(x, beta=FALSE, gamma=FALSE)\n  suavizamiento <- fitted(mod)[,1] |> as.numeric()\n  sd(x[-1] - suavizamiento)\n}\nreferencia_tbl <- muestrear_ventanas(historicos, n_ventana = 1500) |> \n  pluck(\"lineup\") |> \n  group_by(rep) |> \n  summarise(est_prueba = sd_simple(obs))\nreferencia_tbl |> head()\n\n\n# A tibble: 6 × 2\n    rep est_prueba\n  <int>      <dbl>\n1     1      1.08 \n2     2      0.843\n3     3      0.934\n4     4      0.830\n5     5      0.799\n6     6      1.20 \n\n\n\n\nCódigo\nggplot(referencia_tbl, aes(x = est_prueba)) + \n  geom_histogram() +\n  geom_vline(xintercept = sd_simple(observados$obs), colour = \"red\") +\n  annotate(\"text\", x = 2.5, y = 30, \n     label = \"diferencia observada\", colour = \"red\", angle = 90)\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nY confirmamos que en efecto el valor observado (línea roja) es uno muy extremo, y poco consistente con el comportamiento usual del sistema.\nEl valor p (de una cola) Se define como la probabilidad de observar este resultado, o uno más grande, suponiendo que el sistema está funcionando usualmente, y en este caso lo calculamos como:\n\n\nCódigo\ndiferencia_obs <- sd_simple(observados$obs)\nreferencia_2 <- bind_rows(referencia_tbl,\n  tibble(rep = 0, est_prueba = diferencia_obs))\nreferencia_2 |> \n  mutate(mayor_obs = est_prueba > diferencia_obs) |> \n  summarise(valor_p = mean(mayor_obs)) |> \n  kable() |> kable_paper(full_width = FALSE)\n\n\n\n\n \n  \n    valor_p \n  \n \n\n  \n    0.0019987 \n  \n\n\n\n\n\nQue cuantifica que es muy poco probable observar el sistema en el estado actual si fuera cierto que no ha sufrido cambios.\n\n\n\n\n\n\nEstadísticas de prueba\n\n\n\nUna estadística de prueba es un resumen de datos, a partir del cual construimos una distribución de referencia bajo los supuestos de la hipótesis nula. Distintas estadísticas miden distintos aspectos de las diferencias que puede haber entre los datos de prueba y los de referencia.\n\n\n\n\n\n\nBox, George EP, William H Hunter, Stuart Hunter, et al. 1978. Statistics for experimenters. Vol. 664. John Wiley; sons New York.\n\n\nWickham, Hadley, Dianne Cook, Heike Hofmann, y Andreas Buja. 2010. «Graphical inference for infovis». IEEE Transactions on Visualization and Computer Graphics 16 (6): 973-79."
  },
  {
    "objectID": "03-pruebas-hipotesis-aleatorizacion.html",
    "href": "03-pruebas-hipotesis-aleatorizacion.html",
    "title": "7  Aleatorización en inferencia causal",
    "section": "",
    "text": "Empezaremos con ejemplos de inferencia causal y consideramos el ejemplo de (Box et al. (1978)).\nSupongamos que un jardinero aficionado tiene un fertilizante, y quiere ver si tiene un efecto agregarlo a sus plantas. Nuestro jardinero solamente tiene una línea donde caben 20 plantas.\nCuando las plantas crezcan, observaremos variabilidad, independientemente de si se usa fertilizante o no. Esta variabilidad proviene de muchos factores ambientales, variaciones en las condiciones del suelo, insectos, etc. Interpretar los resultados correctamente implica necesariamente cuantificar esa variabilidad.\nEl jardinero escogió algunos lugares dónde poner el fertilizante y dónde no. El resultado que obtuvo es:\nPara decidir qué tan bueno es el nuevo fertilizante, el jardinero decide usar la siguiente estadística \\(D\\) (Kolmogorov-Smirnov):\nUn valor de \\(D\\) grande sugiere que el fertilizante tiene algún efecto. En nuestro experimento, obtuvimos:\nLa diferencia más grande en estas curvas es:\nParece ser que las plantas con fertilizante tuvieron mejores resultados (la distribución de las fertilizadas está recorrida hacia la derecha). El problema aquí es que las plantas tienen variabilidad, y la diferencia que observamos, que no es muy grande, podría deberse a esa variabilidad, y no tener qué ver con el fertilizante.\n¿Cómo juzgamos si este resultado puede atribuirse a variabilidad en el crecimiento de cada planta?\nReescribimos nuestros datos como:\nNótese que escribimos en cada caso el dato observado y el no observado.\nAhora supongamos que el tratamiento no tiene ningún efecto sobre el crecimiento de las plantas. Bajo esta hipótesis, podemos rellenar los valores no observados: en cada caso, el dato faltante lo conocemos, y es igual al valor observado para cada planta.\nBajo esta hipótesis, podemos calcular qué pasaría si hubiéramos escogido distintas plantas para el tratamiento de fertilizante.\nSimplemente consideramos todas las permutaciones de la columna \\(T\\), y vemos el valor que tiene nuestra estadística \\(D\\) en cada caso. La distribución resultante es la distribución de referencia bajo la hipótesis de que el fertilizante no tiene efecto, y muestra la variabilidad de nuestra estadística bajo esta hipótesis.\nUsualmente, en lugar de calcular todas las permutaciones, simulamos un número grande de ellas (de mil a 10 mil, por ejemplo). Abajo mostramos dos ejemplos:\nY aquí vemos todos los posibles resultados bajo distintas asignaciones del fertilizante, bajo la hipótesis del que el fertilizante no tiene ningún efecto. Adicionalmente, marcamos el valor que observamos en el experimento.\nComo vemos, el resultado que obtuvimos está en el lado alto de la destribución. Parece ser que el fertilizante tiene algún efecto.\nSin embargo, hay un hueco en nuestro argumento. Por ejemplo,\nSi esto es cierto, entonces nuestro argumento no es válido. Quizá la diferencia es grande porque el fertilizante se aplicó a plantas con más potencial desde un principio.\nUna solución simple es la siguiente:\nLlamamos a este valor-p de la prueba, y cuanto más chico es, mayor evidencia tenemos contra la hipótesis nula."
  },
  {
    "objectID": "03-pruebas-hipotesis-aleatorizacion.html#pruebas-de-hipótesis-visuales",
    "href": "03-pruebas-hipotesis-aleatorizacion.html#pruebas-de-hipótesis-visuales",
    "title": "7  Aleatorización en inferencia causal",
    "section": "7.1 Pruebas de hipótesis visuales",
    "text": "7.1 Pruebas de hipótesis visuales\nOtra idea es hacer una prueba visual (ver por ejemplo (este artículo)[https://vita.had.co.nz/papers/inference-infovis.pdf]. Primero graficamos varias replicaciones de datos nulos, es decir, datos en donde hemos permutado al azar la columna de tratamiento. Entrenamos nuestra percepción a variaciones consistentes con la hipótesis nula:\n\n\nCódigo\nlibrary(nullabor)\n\nset.seed(83814)\n# comenzamos con rorsach, viendo datos nulos\nreps_rorschach <- rorschach(method = null_permute(\"T\"), n = 20, res_obs) |> \n  as_tibble()\nggplot(reps_rorschach, aes(sample = y, colour = T, group = T)) +\n  stat_qq(distribution = stats::qunif) +\n  stat_qq_line(distribution = stats::qunif, fullrange = TRUE) +\n  facet_wrap(~ .sample) + theme(strip.background =element_rect(fill=\"gray85\"))\n\n\n\n\n\nY ahora hacemos nuestra prueba. En la siguiente gráfica 19 cajas tienen datos nulos, y una caja tiene los datos verdaderos.\n¿Puedes identificar los datos verdaderos?\n\n\nCódigo\nreps <- lineup(method = null_permute(\"T\"), n = 20, res_obs) |> \n  as_tibble()\n\n\ndecrypt(\"W1U7 cEkE nN lVunknVN gy\")\n\n\n\n\nCódigo\nggplot(reps, aes(sample = y, colour = T, group = T)) +\n  stat_qq(distribution = stats::qunif) +\n  stat_qq_line(distribution = stats::qunif, fullrange = TRUE) +\n  facet_wrap(~ .sample) + theme(strip.background =element_rect(fill=\"gray85\"))\n\n\n\n\n\n\nEsta prueba es exacta: la probabilidad de identificar los datos correctamente cuando el fertilizante no tiene efecto es menor o igual a 0.05 (valor \\(p\\)). Esta es la probabilidad de equivocadamente declarar que tenemos evidencia de que la hipótesis nula no se cumple."
  },
  {
    "objectID": "03-pruebas-hipotesis-aleatorizacion.html#ejemplo-poca-evidencia-en-contra-de-la-nula",
    "href": "03-pruebas-hipotesis-aleatorizacion.html#ejemplo-poca-evidencia-en-contra-de-la-nula",
    "title": "7  Aleatorización en inferencia causal",
    "section": "7.2 Ejemplo: poca evidencia en contra de la nula",
    "text": "7.2 Ejemplo: poca evidencia en contra de la nula\nComo segundo ejemplo, imaginemos que hubiéramos obtenido los siguientes datos:\n\n\nCódigo\nres_obs <- tibble(planta = 1:20,\n       T = c(\"nf\", \"nf\", \"f\", \"f\", \"nf\", \"f\", \"f\", \"f\", \"nf\", \"nf\", \"f\", \"nf\", \"f\", \"f\", \"nf\", \"f\", \"f\", \"nf\", \"f\", \"nf\"),\n       y = c(16.9, 19.4, 18.6, 12.7, 22.3, 23.5, 18.2, 19.9, 14.5, 15.1, 29.1, 15.2, 23.5, 24.8, 20.5, 21.2, 22.3, 19.4, 23.1, 21.2) / 2) |> \n  mutate(y_nf = ifelse(T == \"nf\", y, NA),\n         y_f = ifelse(T == \"f\", y, NA))\nbajo_nula <- res_obs |> \n  mutate(y_f = y, y_nf = y)\nres_obs |> select(planta, T, y) |> kable() |> \n   kable_paper(full_width = FALSE)\n\n\n\n\n \n  \n    planta \n    T \n    y \n  \n \n\n  \n    1 \n    nf \n    8.45 \n  \n  \n    2 \n    nf \n    9.70 \n  \n  \n    3 \n    f \n    9.30 \n  \n  \n    4 \n    f \n    6.35 \n  \n  \n    5 \n    nf \n    11.15 \n  \n  \n    6 \n    f \n    11.75 \n  \n  \n    7 \n    f \n    9.10 \n  \n  \n    8 \n    f \n    9.95 \n  \n  \n    9 \n    nf \n    7.25 \n  \n  \n    10 \n    nf \n    7.55 \n  \n  \n    11 \n    f \n    14.55 \n  \n  \n    12 \n    nf \n    7.60 \n  \n  \n    13 \n    f \n    11.75 \n  \n  \n    14 \n    f \n    12.40 \n  \n  \n    15 \n    nf \n    10.25 \n  \n  \n    16 \n    f \n    10.60 \n  \n  \n    17 \n    f \n    11.15 \n  \n  \n    18 \n    nf \n    9.70 \n  \n  \n    19 \n    f \n    11.55 \n  \n  \n    20 \n    nf \n    10.60 \n  \n\n\n\n\n\n\n\nCódigo\nggplot(res_obs, aes(y, colour = T)) +\n  stat_ecdf() +\n  ylab(\"Proporción acumulada\")\n\n\n\n\n\n\n\nCódigo\nresumen <- res_obs |> \n  summarise(D = ks_est_2(res_obs, T)) \nperms_dist <- map_df(1:1000, function(i){\n  permutar_est(bajo_nula) |> \n    mutate(rep = i)\n})\n\nggplot(perms_dist, aes(sample = D)) +\n  geom_qq(distribution = qunif) +\n  geom_hline(yintercept = resumen$D, colour = \"red\") +\n  xlab(\"f\") + ylab(\"valor de D\") +\n  labs(subtitle = \"Distribución nula de referencia\") +\n  annotate(\"text\", x = 0.1 , y = 0.5, label = \"Valor observado\", colour = \"red\")\n\n\n\n\n\n\n\nCódigo\nmean(perms_dist$D >= resumen$D)\n\n\n[1] 0.144\n\n\nEste valor \\(p\\) es alto, y no es muy difícil que, bajo la hipótesis de que el tratamiento no tiene efecto, por azar el jardinero haya escogido una asignación con el valor observado de la estadística de prueba. En este caso, creemos que los datos son consistentes con la hipótesis nula."
  },
  {
    "objectID": "03-pruebas-hipotesis-aleatorizacion.html#ejemplo-tiempos-de-fusión",
    "href": "03-pruebas-hipotesis-aleatorizacion.html#ejemplo-tiempos-de-fusión",
    "title": "7  Aleatorización en inferencia causal",
    "section": "Ejemplo: tiempos de fusión",
    "text": "Ejemplo: tiempos de fusión\nPodemos utilizar la prueba de permutaciones con otras estadísticas de prueba (ver nota al final de estos ejemplos) como medias o medianas.\nEn el siguiente ejemplo (Cleveland (1993)), investigadores se preguntaron si es posible que las personas reconozcan más fácilmente la imagen escondida en un estereograma si se les da información verbal acerca de la imagen que tienen que encontrar.\nLa medición que consideraron el el tiempo de fusión en segundo, es decir, cuánto tarda la persona en ver la imagen 3D escondida. Naturalmente, existe mucha variación en el tiempo que tardan las personas en reconocer esas imágenes (algunos lo hacen casi instantáneamente y otros pueden tardar hasta minutos).\nEste experimento se diseño aleatorizando el tratamiento entre los participantes del estudio, que son voluntarios, de forma que si encontramos evidencia de diferencias entre los dos grupos, tenemos evidencia de que el tratamiento cambia el tiempo de fusión entre los partipantes.\nPodemos hacer una prueba de permutaciones para la diferencia de las medias y otras estadísticas como la mediana o promedio del cuartiles superior e inferior (son versiones menos dependientes de datos atípticos), por ejemplo. En este ejemplo usaremos la diferencia de medias:\n\n\nCódigo\nfusion <- read_table(\"./datos/fusion_time.txt\")\n# estadística de prueba\nstat_fusion <- function(x){\n    mean(x)\n    #(quantile(x, 0.75) + quantile(x, 0.25))/2\n}\n# calcular para cada grupo la estadística\ncalc_fusion <- function(stat_fusion){\n  fun <- function(datos){\n    datos |> \n      group_by(nv.vv) |> \n      summarise(est = stat_fusion(time)) |> \n      spread(nv.vv, est) |> mutate(dif = VV - NV ) |> pull(dif)\n  }\n  fun\n}\n# esta función hace permutaciones y calcula la diferencia para cada una\npermutaciones_est <- function(datos, variable, calc_diferencia, n = 1000){\n  # calcular estadística para cada grupo\n  permutar <- function(variable){\n    sample(variable, length(variable))\n  }\n  tbl_perms <- tibble(.sample = seq(1, n-1, 1)) |>\n    mutate(diferencia = map_dbl(.sample, \n              ~ datos |> mutate({{variable}}:= permutar({{variable}})) |> calc_diferencia()))\n  bind_rows(tbl_perms, tibble(.sample = n, diferencia = calc_diferencia(datos)))\n}\n\n\n\n\nCódigo\ncalc_cociente <- calc_fusion(stat_fusion)\ndif_obs <- calc_cociente(fusion)\n# permutar\nvalores_ref <- permutaciones_est(fusion, nv.vv, calc_cociente, n = 10000)\ndist_perm_nv <- ecdf(valores_ref$diferencia) \ncuantil_obs <- dist_perm_nv(dif_obs)\n\n\n\n\n\n\n\nLa observación es algo extrema, de manera que tenemos evidencia de que la información verbal ayuda. Para cuantificar esta evidencia, calcularemos el valor-p correspondiente\n\nValor p\nUsualmente preferimos usar un valor \\(p\\) de dos colas para cuantificar la evidencia contra la nula. Esto es porque podría ser que la diferencia fuera muy grande o muy positiva, y en ambos casos diríamos que los datos no son consistentes con la nula.\n\n\n\n\n\n\nValor p de dos colas\n\n\n\nSi la hipótesis nula es cierta, ¿cuál es la probabilidad de observar una diferencia tan extrema o más extrema de lo que observamos? Esto incluye valores muy grandes o muy chicos.\nEl estándar usual para pruebas de hipótesis es hacer utilizar el valor-\\(p\\) de dos colas.\n\n\nConsiderando en este caso interpretamos extrema como que cae lejos de donde a mayoría de la distribución se concentra, podemos calcular el valor p como sigue. A partir de el valor observado, consideramos cuál dato es menor: la probabilidad bajo lo hipótesis nula de observar una diferencia mayor de a que observamos, o la probabilidad de observar una diferencia menor a la que observamos. Tomamos el mínimo y multiplicamos por dos (Hesterberg (2015)):\n\n\nCódigo\ndist_perm_nv <- ecdf(valores_ref$diferencia)\n2 * min(dist_perm_nv(dif_obs), 1- dist_perm_nv(dif_obs))\n\n\n[1] 0.0412\n\n\nLo que muestra evidencia considerable, aunque no muy fuerte, de que la instrucción verbal ayuda a reducir el tiempo de fusión de los estereogramas. Los grupos gráficados se ven como sigue:\n\n\nCódigo\nggplot(fusion, aes(x = nv.vv, y = time)) +\n  geom_boxplot() + coord_flip()"
  },
  {
    "objectID": "03-pruebas-hipotesis-aleatorizacion.html#otros-tipos-de-hipótesis-nulas",
    "href": "03-pruebas-hipotesis-aleatorizacion.html#otros-tipos-de-hipótesis-nulas",
    "title": "7  Aleatorización en inferencia causal",
    "section": "Otros tipos de hipótesis nulas",
    "text": "Otros tipos de hipótesis nulas\nLas pruebas de permutaciones no están tan perfectamente adaptadas a este problema, pues prueban todos los aspectos de las distribuciones que se comparan, aún cuando escogamos una estadística particular que pretende medir, por ejemplo, diferencia de medias. Eso quiere decir que podemos rechazar igualdad de medias, por ejemplo, cuando en realidad otra característica de las distribuciones es la que difiere mucho en las poblaciones\nEn algunas referencias (ver Chihara, Efron y Tibshirani (1993)) se argumenta que de todas formas las pruebas de permutaciones son relativamente robustas a esta desadaptación. Un caso excepcional, por ejemplo, es cuando las poblaciones que comparamos resultan tener dispersión extremadamente distinta, y adicionalmente los tamaños de muestra de los grupos son muy desiguales (otra vez, ver ejemplos en Chihara y Hesterberg (2018)).\n\n\n\n\nBox, George EP, William H Hunter, Stuart Hunter, et al. 1978. Statistics for experimenters. Vol. 664. John Wiley; sons New York.\n\n\nChihara, Laura M., y Tim C. Hesterberg. 2018. Mathematical Statistics with Resampling and R. 2.ª ed. Hoboken, NJ: John Wiley & Sons. https://sites.google.com/site/chiharahesterberg/home.\n\n\nCleveland, William S. 1993. Visualizing Data. Hobart Press.\n\n\nEfron, B., y R. Tibshirani. 1993. «An Introduction to the Bootstrap». Miscellaneous. Macmillan Publishers Limited. All rights reserved.\n\n\nHesterberg, Tim C. 2015. «What teachers should know about the bootstrap: Resampling in the undergraduate statistics curriculum». The American Statistician 69 (4): 371-86."
  },
  {
    "objectID": "03-pruebas-hipotesis-2.html",
    "href": "03-pruebas-hipotesis-2.html",
    "title": "8  Diseño de experimentos e inferencia",
    "section": "",
    "text": "En los ejemplos que vimos en la sección anterior, consideramos siempre que el tratamiento se asigna al azar a cada individuo o unidad experimental. Cuando tenemos más información acerca del problema, podemos diseñar esquemas que mejoran la precisión controlando fuentes de variación.\nLa técnica básica para hacer esto es el bloqueo. Si las unidades experimentales vienen en grupos que son relativamente homogéneos, entonces tiene sentido considerar esos grupos"
  },
  {
    "objectID": "03-pruebas-hipotesis-2.html#ejemplo-zapatos-de-niños",
    "href": "03-pruebas-hipotesis-2.html#ejemplo-zapatos-de-niños",
    "title": "8  Diseño de experimentos e inferencia",
    "section": "8.1 Ejemplo: zapatos de niños",
    "text": "8.1 Ejemplo: zapatos de niños\nEn el siguiente ejemplo clásico de (Box et al. (1978)), nos interesa probar un material nuevo para suela de zapatos (el material B) y ver si es comparable con el material que se usa normalmente (el material A).\nSupongamos en primer lugar que aleatorizamos el material entre los 10 niños y después de cierto tiempo, medimos el desgaste.\n\n\nCódigo\ndatos_zapatos <- read_table(\"datos/zapatos.txt\") |> \n  mutate(lado = c(\"i\", \"d\", \"i\", \"d\", \"d\", \"i\", \"i\", \"d\", \"d\", \"i\", \"i\", \"d\",\n                  \"i\", \"d\", \"i\", \"d\", \"d\", \"i\", \"i\", \"d\")) |> \n  mutate(material = ifelse(material == 1, \"a\", \"b\"))\nset.seed(2312)\nzapatos_1 <- datos_zapatos |> group_by(niño) |> \n  slice_sample(n = 1) |> \n  select(niño, material, desgaste) |> \n  ungroup()\nzapatos_1\n\n\n# A tibble: 10 × 3\n    niño material desgaste\n   <dbl> <chr>       <dbl>\n 1     1 a            13.2\n 2     2 b             8.8\n 3     3 a            10.9\n 4     4 b            14.2\n 5     5 a            10.7\n 6     6 b             6.4\n 7     7 b             9.8\n 8     8 b            11.3\n 9     9 a             8.8\n10    10 a            13.3\n\n\nVeamos los datos:\n\n\nCódigo\nggplot(zapatos_1, aes(x = material, y = desgaste)) + geom_jitter(width = 0.1, height = 0)\n\n\n\n\n\nCódigo\ndiferencia_obs <- zapatos_1 |> \n  group_by(material) |> \n  summarise(media = mean(desgaste)) |> \n  pivot_wider(names_from = material, values_from = media) |> \n  mutate(diferencia = b - a) |> pull(diferencia)\n\n\nUna prueba de permutaciones para la media nos da lo siguiente:\n\n\nCódigo\nlibrary(nullabor)\nsims_nulas <- rorschach(null_permute(\"material\"), n = 1000) |> \n  group_by(.sample, material) |> \n  summarise(media = mean(desgaste)) |> \n  pivot_wider(names_from = material, values_from = media) |> \n  ungroup() |> \n  mutate(diferencia = b - a)\nggplot(sims_nulas, aes(x = diferencia)) + geom_histogram() +\n  geom_vline(xintercept = diferencia_obs, colour = \"red\")\n\n\n\n\n\nY no podemos concluir que algún material sea mejor que otro.\nSin embargo, consideramos que en este ejemplo probablemente el nivel de actividad de los niños sea un factor más importante en la variabilidad que el tipo de material, de modo que no es sorprendente que con esta muestra chica sea difícil concluir. Como cada niño tiene dos pies, podemos mejor asignar al azar un material a uno de sus zapatos y el otro material al otro.\nDespués de aleatorizar el material a cada pie, obtenemos los siguientes datos de nuestro experimento:\n\n\nCódigo\ndatos_zapatos\n\n\n# A tibble: 20 × 4\n   desgaste material  niño lado \n      <dbl> <chr>    <dbl> <chr>\n 1     13.2 a            1 i    \n 2     14   b            1 d    \n 3      8.2 a            2 i    \n 4      8.8 b            2 d    \n 5     10.9 a            3 d    \n 6     11.2 b            3 i    \n 7     14.3 a            4 i    \n 8     14.2 b            4 d    \n 9     10.7 a            5 d    \n10     11.8 b            5 i    \n11      6.6 a            6 i    \n12      6.4 b            6 d    \n13      9.5 a            7 i    \n14      9.8 b            7 d    \n15     10.8 a            8 i    \n16     11.3 b            8 d    \n17      8.8 a            9 d    \n18      9.3 b            9 i    \n19     13.3 a           10 i    \n20     13.6 b           10 d    \n\n\nCalculamos la diferencia de b menos a para cada niño:\n\n\nCódigo\ndiferencias_tbl <- datos_zapatos |>\n  select(-lado) |> \n  pivot_wider(names_from = material, values_from = desgaste) |> \n  mutate(dif = b - a)\ndiferencias_tbl\n\n\n# A tibble: 10 × 4\n    niño     a     b    dif\n   <dbl> <dbl> <dbl>  <dbl>\n 1     1  13.2  14    0.800\n 2     2   8.2   8.8  0.600\n 3     3  10.9  11.2  0.300\n 4     4  14.3  14.2 -0.100\n 5     5  10.7  11.8  1.10 \n 6     6   6.6   6.4 -0.200\n 7     7   9.5   9.8  0.300\n 8     8  10.8  11.3  0.5  \n 9     9   8.8   9.3  0.5  \n10    10  13.3  13.6  0.300\n\n\nY nuestra estadística de prueba es la media de estas diferencias:\n\n\nCódigo\ndif_obs <- diferencias_tbl$dif |> mean()\ndif_obs\n\n\n[1] 0.41\n\n\nAhora podemos hacer una prueba de permutaciones. El proceso de permutación bajo la nula debe respetar el diseño que elegimos, así que en este caso debemos considerar permutar, para cada niño, los dos zapatos.\n\n\nCódigo\n#! code-fold: false\npermutar_pares <- function(datos_tbl){\n  datos_tbl |> group_by(niño) |> \n    mutate(material = sample(material, size = 2, replace = FALSE))\n}\ndif_nula_tbl <- map_df(1:5000, function(i){\n  permutar_pares(datos_zapatos) |> \n    ungroup() |> \n    select(-lado) |> \n    pivot_wider(names_from = material, values_from = desgaste) |> \n    mutate(dif = b - a) |> select(dif) |> \n    summarise(dif = mean(dif))\n})\n\n\n\n\nCódigo\nggplot(dif_nula_tbl, aes(x = dif)) + geom_histogram() +\n  geom_vline(xintercept = dif_obs, colour = \"red\")\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\nCódigo\n2 * mean(dif_nula_tbl$dif > dif_obs)\n\n\n[1] 0.0104\n\n\nY vemos que obtenemos un resultado altamente significativo de que con el nuevo material se presenta más desgaste.\nAunque la diferencia no parece ser muy grande, la precisión de nuestra prueba aumentó en gran medida gracias al diseño pareado, y pudimos detectar que en efecto el material B no es tan bueno. Sin embargo, quizá es aceptable cambiar al material B si tiene otras ventajas.\n\n\n\n\n\n\nBloqueo y aleatorización\n\n\n\nDe Box et al. (1978), en el diseño de experimentos:\n\nBloquea lo que puedas y aleatoriza lo que no.\n\n\n\n\nBloquear nos permite tener comparaciones más precisas y detectar efectos más chicos cuando existen.\nAleatorizar es lo que nos permite construir una distribución de referencia adecuada para las pruebas de permutaciones.\n\n\n\n\n\nBox, George EP, William H Hunter, Stuart Hunter, et al. 1978. Statistics for experimenters. Vol. 664. John Wiley; sons New York."
  },
  {
    "objectID": "03-pruebas-hipotesis-3.html",
    "href": "03-pruebas-hipotesis-3.html",
    "title": "9  Más acerca de pruebas de hipótesis",
    "section": "",
    "text": "Comenzamos con varias recomendaciones y comentarios acerca de lo métodos que hemos visto en esta parte:"
  },
  {
    "objectID": "03-pruebas-hipotesis-3.html#la-crisis-de-replicabilidad",
    "href": "03-pruebas-hipotesis-3.html#la-crisis-de-replicabilidad",
    "title": "9  Más acerca de pruebas de hipótesis",
    "section": "La “crisis de replicabilidad”",
    "text": "La “crisis de replicabilidad”\nRecientemente (Ioannidis (2005)) se ha reconocido en campos de ciencias sociales y medicina la crisis de replicabilidad. Varios estudios que recibieron mucha publicidad inicialmente no han podido ser replicados posteriormente por otros investigadores. Por ejemplo:\n\nHacer poses poderosas produce cambios fisiológicos que mejoran nuestro desempeño en ciertas tareas\nMostrar palabras relacionadas con “viejo” hacen que las personas caminen más lento (efectos de priming)\n\nEn todos estos casos, el argumento de la evidencia de estos efectos fue respaldada por una prueba de hipótesis nula con un valor p menor a 0.05. La razón es que ese es el estándar de publicación seguido por varias áreas y revistas. La tasa de no replicabilidad parece ser mucho más alta (al menos la mitad o más según algunas fuentes, como la señalada arriba) que lo sugeriría la tasa de falsos positivos (menos de 5%)\nEste problema de replicabilidad parece ser más frecuente cuando:\n\nSe trata de estudios de potencia baja: mediciones ruidosas y tamaños de muestra chicos.\nEl plan de análisis no está claramente definido desde un principio (lo cual es difícil cuando se están investigando “fenómenos no estudiados antes”)\n\n¿A qué se atribuye esta crisis de replicabilidad?"
  },
  {
    "objectID": "03-pruebas-hipotesis-3.html#el-jardín-de-los-senderos-que-se-bifurcan",
    "href": "03-pruebas-hipotesis-3.html#el-jardín-de-los-senderos-que-se-bifurcan",
    "title": "9  Más acerca de pruebas de hipótesis",
    "section": "El jardín de los senderos que se bifurcan",
    "text": "El jardín de los senderos que se bifurcan\nAunque haya algunos ejemplos de manipulaciones conscientes –e incluso, en menos casos, malintencionadas– para obtener resultados publicables o significativos (p-hacking), como vimos en ejemplos anteriores, hay varias decisiones, todas razonables, que podemos tomar cuando estamos buscando las comparaciones correctas. Algunas pueden ser:\n\nTransformar los datos (tomar o no logaritmos, u otra transformación)\nEditar datos atípicos (razonable si los equipos pueden fallar, o hay errores de captura, por ejemplo)\nDistintas maneras de interpretar los criterios de inclusión de un estudio (por ejemplo, algunos participantes mostraron tener gripa, o revelaron que durmieron muy poco la noche anterior, etc. ¿los dejamos o los quitamos?)\n\nDado un conjunto de datos, las justificaciones de las decisiones que se toman en cada paso son razonables, pero con datos distintos las decisiones podrían ser diferentes. Este es el jardín de los senderos que se bifurcan Gelman, que invalida en parte el uso valores p como criterio de evidencia contra la hipótesis nula.\nEsto es exacerbado por:\n\nTamaños de muestra chicos y efectos “inestables” que se quieren medir (por ejemplo en sicología)\nEl hecho de que el criterio de publicación es obtener un valor p < 0.05, y la presión fuerte sobre los investigadores para producir resultados publicables (p < 0.05)\nEl que estudios o resultados similares que no obtuvieron valores \\(p\\) por debajo del umbral no son publicados o reportados.\n\nVer por ejemplo el comunicado de la ASA.\nOjo: esas presiones de publicación no sólo ocurre para investigadores en sicología. Cuando trabajamos en problemas de análisis de datos en problemas que son de importancia, es común que existan intereses de algunas partes o personas involucradas por algunos resultados u otros (por ejemplo, nuestros clientes de consultoría o clientes internos). Eso puede dañar nuestro trabajo como analistas, y el avance de nuestro equipo. Aunque esas presiones son inevitables, se vuelven manejables cuando hay una relación de confianza entre las partes involucradas."
  },
  {
    "objectID": "03-pruebas-hipotesis-3.html#ejemplo-decisiones-de-análisis-y-valores-p",
    "href": "03-pruebas-hipotesis-3.html#ejemplo-decisiones-de-análisis-y-valores-p",
    "title": "9  Más acerca de pruebas de hipótesis",
    "section": "Ejemplo: decisiones de análisis y valores p",
    "text": "Ejemplo: decisiones de análisis y valores p\nEn el ejemplo de datos de fusión, decidimos probar, por ejemplo, el promedio de los cuartiles inferior y superior, lo cual no es una decisión típica pero usamos como ilustración. Ahora intentamos usar distintas mediciones de la diferencia entre los grupos, usando distintas medidas resumen y transformaciones (por ejemplo, con o sin logaritmo). Aquí hay unas 12 combinaciones distintas para hacer el análisis (multiplicadas por criterios de “aceptación de datos en la muestra”, que simulamos tomando una submuestra al azar):\n\n\nCódigo\nfusion <- read_table(\"./datos/fusion_time.txt\")\n\n\n\n── Column specification ────────────────────────────────────────────────────────\ncols(\n  n = col_double(),\n  time = col_double(),\n  nv.vv = col_character()\n)\n\n\nCódigo\ncalc_fusion <- function(stat_fusion, trans, comparacion){\n  fun <- function(datos){\n    datos |> \n      group_by(nv.vv) |> \n      summarise(est = stat_fusion({{ trans }}(time))) |> \n      spread(nv.vv, est) |> mutate(dif = {{ comparacion }}) |> pull(dif)\n  }\n  fun\n}\nvalor_p <- function(datos, variable, calc_diferencia, n = 1000){\n  # calcular estadística para cada grupo\n  permutar <- function(variable){\n    sample(variable, length(variable))\n  }\n  tbl_perms <- tibble(.sample = seq(1, n-1, 1)) |>\n    mutate(diferencia = map_dbl(.sample, \n              ~ datos |> mutate({{variable}} := permutar({{variable}})) |> calc_diferencia()))\n  perms <- bind_rows(tbl_perms, tibble(.sample = n, diferencia = calc_diferencia(datos)))\n  perms_ecdf <- ecdf(perms$diferencia)\n  dif <- calc_diferencia(datos)\n  2 * min(perms_ecdf(dif), 1- perms_ecdf(dif))\n}\n\n\n\n\nCódigo\nset.seed(7272)\nmedia_cuartiles <- function(x){\n    (quantile(x, 0.75) + quantile(x, 0.25))/2\n}\n# nota: usar n=10000 o más, esto solo es para demostración:\ncalc_dif <- calc_fusion(mean, identity, VV - NV)\nvalor_p(fusion |> sample_frac(0.95), nv.vv, calc_dif, n = 1000)\n\n\n[1] 0.072\n\n\nCódigo\ncalc_dif <- calc_fusion(mean, log, VV - NV)\nvalor_p(fusion |> sample_frac(0.95), nv.vv, calc_dif, n = 1000)\n\n\n[1] 0.024\n\n\nCódigo\ncalc_dif <- calc_fusion(median, identity, VV / NV)\nvalor_p(fusion |> sample_frac(0.95), nv.vv, calc_dif, n = 1000)\n\n\n[1] 0.016\n\n\nCódigo\ncalc_dif <- calc_fusion(media_cuartiles, identity, VV / NV)\nvalor_p(fusion |> sample_frac(0.95), nv.vv, calc_dif, n = 1000)\n\n\n[1] 0.026\n\n\nSi existen grados de libertad - muchas veces necesarios para hacer un análisis exitoso-, entonces los valores p pueden tener poco significado."
  },
  {
    "objectID": "03-pruebas-hipotesis-3.html#alternativas-o-soluciones",
    "href": "03-pruebas-hipotesis-3.html#alternativas-o-soluciones",
    "title": "9  Más acerca de pruebas de hipótesis",
    "section": "Alternativas o soluciones",
    "text": "Alternativas o soluciones\nEl primer punto importante es reconocer que la mayor parte de nuestro trabajo es exploratorio (recordemos el proceso complicado del análisis de datos de refinamiento de preguntas). En este tipo de trabajo, reportar valores p puede tener poco sentido, y mucho menos tiene sentido aceptar algo “verdadero” cuando pasa un umbral de significancia dado.\nNuestro interés principal al hacer análisis es expresar correctamente y de manera útil la incertidumbre asociada a las conclusiones o patrones que mostramos (asociada a variación muestral, por ejemplo) para que el proceso de toma de decisiones sea informado. Un resumen de un número (valor p, o el que sea) no puede ser tomado como criterio para tomar una decisión que generalmente es compleja. En la siguiente sección veremos cómo podemos mostrar parte de esa incertidumbre de manera más útil.\nPor otra parte, los estudios confirmatorios (donde se reportan valores p) también tienen un lugar. En áreas como la sicología, existen ahora movimientos fuertes en favor de la repetición de estudios prometedores pero donde hay sospecha de grados de libertad del investigador. Este movimiento sugiere dar valor a los estudios exploratorios que no reportan valor p, y posteriormente, si el estudio es de interés, puede intentarse una replicación confirmatoria, con potencia más alta y con planes de análisis predefinidos.\n\n\n\n\nIoannidis, John PA. 2005. «Why most published research findings are false». PLoS medicine 2 (8): e124."
  }
]