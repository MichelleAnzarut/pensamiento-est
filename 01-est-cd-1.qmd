# Estadística y ciencia de datos {#estcd}

El término "ciencia de datos" surgió recientemente, y hay discusión acerca de qué tan
apropiado es el término, si es correcto llamarla "ciencia", y en general, en cómo
definirla exactamente. En este curso tomamos el punto de vista de que:


- La ciencia de datos antes se llamaba análisis de datos. Esto quiere decir que
no ocurre en un espacio teórico o matemático, sino en aplicaciones específicas donde
buscamos tomar decisiones informadas. A su vez, algunas personas consideran
el análisis de datos como "estadística aplicada".
- La ciencia de datos, a diferencia del análisis de datos más tradicional,
reconoce y adopta ideas de desarrollo de software
e ingeniería que son relevantes para producir análisis y productos con buena
calidad y desempeño.

Desde este punto de vista, 
el estándar de validez más importante en la ciencia de datos (@tukeyda) es su 
funcionamiento en la práctica, y no la adherencia a argumentos teóricos, 
matemáticos o estadísticos.

Igualmente puede ser difícil definir qué es la estadística (algunos la ven como una
parte o rama de las matemáticas, en un extremo, y otros la consideran algo más cercano
al análisis de datos). En cualquier caso:

- La estadística puede considerarse como parte de la ciencia de datos. Sus resultados 
teóricos son guías y
nos dan bases para juzgar y pensar en procedimientos para contestar 
preguntas con datos (@tukeyda).


## Preguntas y datos 

Cuando observamos un conjunto de datos, independientemente de su tamaño,
el paso inicial más importante es entender bajo qué *proceso se generan los
datos*. 

- A grandes rasgos, cuanto más sepamos de este proceso, mejor podemos
contestar preguntas de interés.
- En muchos casos, tendremos que hacer algunos supuestos de cómo se generan estos
datos para dar respuestas (condicionales a esos supuestos).


### Ejemplo: nacimientos

Comenzamos con un ejemplo de análisis exploratorio.
Consideremos una parte de los datos de nacimientos por día del INEGI de 1999 a 2016. Consideraremos sólo tres meses: enero a marzo de 2016. Estos datos, por su tamaño, pueden representarse de manera razonablemente efectiva en una visualización de serie de tiempo

```{r}
#| message: false
#| warning: false
library(tidyverse)
library(lubridate)
library(kableExtra)
ggplot2::theme_set(ggplot2::theme_light())
nacimientos <- read_rds("datos/nacimientos/natalidad.rds") |>
   ungroup() |> 
   filter(year(fecha) == 2016, month(fecha) <= 3)
```

Examinamos partes del contenido de la tabla:

```{r}
tab_1 <- nacimientos |> 
   select(fecha, n) |> 
   slice_head(n = 5)
tab_2 <- nacimientos |> 
   select(fecha, n) |> 
   slice_tail(n = 5)
kable(list(tab_1, tab_2)) |> kable_styling()
```

En un examen rápido de estos números no vemos nada fuera de orden. Los datos tienen forma de serie de tiempo regularmente espaciada (un dato para cada día). Podemos graficar de manera simple como sigue:

```{r, fig.width=9, fig.height = 2.5}
ggplot(nacimientos, aes(x = fecha, y = n)) +
   geom_point() +
   geom_line() + 
   scale_x_date(breaks = "1 week", date_labels = "%d-%b") 
```

Esta es una descripción de los datos, que quizá no es muy compacta pero muestra varios aspectos importantes. En este caso notamos algunos patrones que saltan a la vista. Podemos marcar los domingos de cada semana:

```{r, fig.width=9, fig.height = 2.5}
domingos_tbl <- nacimientos |> 
   filter(weekdays(fecha) == "Sunday")
ggplot(nacimientos, aes(x = fecha, y = n)) +
   geom_vline(aes(xintercept = fecha), domingos_tbl, colour = "salmon") +
   geom_point() +
   geom_line() + 
   scale_x_date(breaks = "1 week", date_labels = "%d-%b") 
```

Observamos que los domingos ocurren menos nacimientos y los sábados también ocurren relativamente menos nacimentos. ¿Por qué crees que sea esto?

Adicionalmente a estos patrones observamos otros aspectos interesantes:

-   El primero de enero hay considerablemente menos nacimientos de los que esperaríamos para un viernes. ¿Por qué?
-   El primero de marzo hay un exceso de nacimientos considerable. ¿Qué tiene de especial este primero de marzo?
-   ¿Cómo describirías lo que sucede en la semana que comienza el 21 de marzo? ¿Por qué crees que pase eso?
-   ¿Cuáles son los domingos con más nacimientos? ¿Qué tienen de especial y qué explicación puede tener?

La confirmación de estas hipótesis, dependiendo de su forma, puede ser relativamente simple (por ejemplo ver una serie más larga de domingos comparados con otros días de la semana) hasta muy compleja (investigar preferencias de madres, de doctores o de hospitales, costumbres y actitudes, procesos en el registro civil, etc.) En todo caso,
una descripción correcta de estos datos requiere conocer tanto hechos generales
como conocimiento detallado de prácticas relacionadas con la natalidad y el registro
de nacimientos.

- El análisis exploratorio y descripción de los datos requiere también conocimiento de dominio: ¿qué cosas intervienen en el proceso que genera estos datos?

### Ejemplo (cálculos renales) {.unnumbered}

Este es un estudio real acerca de tratamientos para cálculos renales (@kidney94). Pacientes se asignaron de una forma no controlada a dos tipos de tratamientos para reducir cálculos renales. Para cada paciente, conocemos el tipo de ćalculos que tenía (grandes o chicos) y si el tratamiento tuvo éxito o no.

La tabla original tiene 700 renglones (cada renglón es un paciente)

```{r, message = FALSE}
calculos <- read_csv("./datos/kidney_stone_data.csv")
names(calculos) <- c("tratamiento", "tamaño", "éxito")
calculos <- calculos |> 
   mutate(tamaño = ifelse(tamaño == "large", "grandes", "chicos")) |> 
   mutate(resultado = ifelse(éxito == 1, "mejora", "sin_mejora")) |> 
   select(tratamiento, tamaño, resultado)
nrow(calculos)
```

y se ve como sigue (muestreamos algunos renglones):

```{r, message = FALSE}
calculos |> 
   sample_n(20) |> kable() |> 
   kable_paper(full_width = FALSE)
```

Aunque estos datos contienen información de 700 pacientes, los datos pueden resumirse sin pérdida de información contando como sigue:

```{r}
calculos_agregada <- calculos |> 
   group_by(tratamiento, tamaño, resultado) |> 
   count()
calculos_agregada |> kable() |> 
   kable_paper(full_width = FALSE)
```

Este resumen no es muy informativo, pero al menos vemos qué valores aparecen en cada columna de la tabla. Como en este caso nos interesa principalmente la tasa de éxito de cada tratamiento, podemos mejorar mostrando como sigue:

```{r}
calculos_agregada |> pivot_wider(names_from = resultado, values_from = n) |> 
   mutate(total = mejora + sin_mejora) |> 
   mutate(prop_mejora = round(mejora / total, 2)) |> 
   select(tratamiento, tamaño, total, prop_mejora) |> 
   arrange(tamaño) |> 
   kable() |> 
   kable_paper(full_width = FALSE)
```

Esta tabla descriptiva es una reescritura de los datos, y no hemos resumido nada todavía. Pero es apropiada para empezar a contestar la pregunta:

-   ¿Qué indican estos datos acerca de qué tratamiento es mejor? ¿Acerca del tamaño de cálculos grandes o chicos?

Supongamos que otro analista decide comparar los pacientes que recibieron cada tratamiento, ignorando la variable de tamaño:

```{r}
calculos |> group_by(tratamiento) |> 
   summarise(prop_mejora = mean(resultado == "mejora") |> round(2)) |> 
   kable() |> 
   kable_paper(full_width = FALSE)
```

y parece ser que el tratamiento $B$ es mejor que el $A$. Esta es una paradoja (un ejemplo de la [paradoja de Simpson](https://es.wikipedia.org/wiki/Paradoja_de_Simpson)) . Si un médico no sabe que tipo de cálculos tiene el paciente, ¿entonces debería recetar $B$? ¿Si sabe debería recetar $A$? Esta discusión parece no tener mucho sentido.

Podemos investigar por qué está pasando esto considerando la siguiente tabla, que solo examina cómo se asignó el tratamiento dependiendo del tipo de cálculos de cada paciente:

```{r}
calculos |> group_by(tratamiento, tamaño) |> count() |> 
   kable() |> 
   kable_paper(full_width = FALSE)
```

Nuestra hipótesis aquí es que la decisión de qué tratamiento usar depende del tamaño de los cálculos.  En este caso, hay una decisión pues A es una cirugía y B es un procedimiento
menos invasivo, y se prefiere utilizar el tratamiento $A$ para cálculos grandes, y $B$ para cálculos chicos. Esto quiere decir que en la tabla total *el tratamiento* $A$ está en desventaja porque se usa en casos más difíciles, pero el tratamiento $A$ parece ser en general mejor. La razón es probablemente un proceso de optimización de recursos y riesgo que hacen los doctores.

- Una mejor respuesta a la pregunta
de qué tratamiento es mejor es la que presenta los datos desagregados
- La tabla desagregada de asignación del tratamiento nos informa acerca de cómo se está distribuyendo el tratamiento
en los pacientes.

Igual que en el ejemplo anterior, los resúmenes descriptivos están acompañados de hipótesis acerca del *proceso generador de datos*, y esto ilumina lo que estamos observando y nos guía hacia descripciones provechosas de los datos. Las explicaciones no son tan simples y, otra vez, interviene el comportamiento de doctores, tratamientos, y distintos tipos de padecimientos.

### Ejemplo (cálculos renales 2) {.unnumbered}

Contrastemos el ejemplo anterior usando exactamente los mismos datos, pero
con una interpretación diferente. En este caso, los tratamientos son para mejorar
alguna enfermedad del corazón. Sabemos que parte del efecto de este tratamiento
ocurre gracias a una baja en presión arterial de los pacientes, así que 
después de administrar el tratamiento, se toma la presión arterial de los pacientes.
Ahora tenemos la tabla agregada y desagregada como sigue:

```{r}
corazon <- calculos |> 
  select(tratamiento, presión = tamaño, resultado) |> 
  mutate(presión = ifelse(presión == "grandes", "alta", "baja"))
corazon_agregada <- corazon |> 
   group_by(tratamiento, presión, resultado) |> 
   count()
corazon_agregada |> pivot_wider(names_from = resultado, values_from = n) |> 
   mutate(total = mejora + sin_mejora) |> 
   mutate(prop_mejora = round(mejora / total, 2)) |> 
   select(tratamiento, presión, total, prop_mejora) |> 
   arrange(presión) |> 
   kable() |> 
   kable_paper(full_width = FALSE)
```

```{r}
corazon |> group_by(tratamiento) |> 
   summarise(prop_mejora = mean(resultado == "mejora") |> round(2)) |> 
   kable() |> 
   kable_paper(full_width = FALSE)
```

¿Cuál creemos que es el mejor tratamiento en este caso? ¿Deberíamos usar
la tabla agregada o la desagregada por presión?

- En este caso, la tabla agregada es más apropiada (B es mejor tratamiento).
- La razón es que *presión* en este caso es una consecuencia de tomar el tratamiento,
y como las tablas muestran, B es más exitoso en bajar la presión de los pacientes.
- Si sólo comparamos dentro de los grupos de presión baja o de presión alta, 
ignoramos parte del efecto del tratamiento en la probabilidad de mejorar.

## Diagramas causales

Podemos utilizar diagramas causales introducidos por Judea Pearl (@pearl2016causal) para explicar por
qué el análisis se hace de manera diferente en cada uno de los casos de arriba.
Los diagramas causales son representaciones de nuestro conocimiento de dominio acerca
de cómo se relacionan de manera causal las variables de interés. En el caso 
de cálculos renales, podemos escribir el diagrama como sigue:

```{r}
#| warning: false
#| message: false
library(dagitty)
library(ggdag)
dag_1 <- dagitty('dag{"Tratamiento" [exposure,pos="-3,0"]
  "Resultado" [outcome,pos="3,0"]
  "Tamaño" [pos="0,1"]
  "Tamaño"  -> "Tratamiento"
    "Tamaño" -> "Resultado"
    "Tratamiento" -> "Resultado"
  }')
dag_1_tidy <- tidy_dagitty(dag_1) 
dag_1_tidy |>
  ggplot(aes(x = x, y = y, xend = xend, yend = yend )) + 
  geom_dag_edges() +
  geom_dag_point(colour = "salmon", size = 20) +
  geom_dag_text(colour = "gray20") +
  theme_dag() 
```
- El tamaño de los cálculos afecta al resultado y a la asignación del
tratamiento. Es un *confusor* si queremos entender el efecto del tratamiento en
el resultado.
- Partimos los datos según este confusor para "comparar peras con peras".

Sin embargo, en el segundo ejemplo tenemos:

```{r}
library(dagitty)
library(ggdag)
dag_1 <- dagitty('dag{"Tratamiento" [exposure,pos="-3,0"]
  "Resultado" [outcome,pos="3,0"]
  "Presión" [pos="0,1"]
  "Tratamiento"  -> "Presión"
    "Presión" -> "Resultado"
    "Tratamiento" -> "Resultado"
  }')
dag_1_tidy <- tidy_dagitty(dag_1) 
dag_1_tidy |>
  ggplot(aes(x = x, y = y, xend = xend, yend = yend )) + 
  geom_dag_edges() +
  geom_dag_point(colour = "salmon", size = 20) +
  geom_dag_text(colour = "gray20") +
  theme_dag()
```
- En este caso, la presión es consecuencia también del tratamiento, así que
es un camino por medio del cual el tratamiento produce resultados.
- Comparar el tratamiento dentro de grupos de presión alta o baja estima el efecto
del tratamiento que no tiene qué ver con la regulación de la presión, lo cual
da una respuesta incompleta.

Adicionalmente, en ambos ejemplos, estamos suponiendo que no existen
otras variables confusoras que puedan afectar nuestro análisis. Qué tan
correcta es esa suposición depende de que conozcamos los detalles de cómo fueron
recopilados estos datos.

### Ejemplo: prevalencia de anemia {.unnumbered}

En un estudio de hospitales en Australia se registró que
57% de una muestra pacientes tenían anemia cuando fueron ingresados. ¿Qué podemos decir
acerca de la prevalencia de anemia en la población general de Australia? Con información
básica acerca del proceso generador de esta muestra podemos concluir que
será difícil generalizar con estos datos a la población general. La razón es que:

- Muchas enfermedades graves (por ejemplo del corazón) pueden producir anemia.
- Estas enfermededes hacen más probable que alguien sea hospitalizado.
- Por lo tanto, en este estudio hay una asociación entre tener anemia
y ser seleccionado para el estudio (tener anemia sube la probabilidad de ser
seleccionado para el estudio)
- Nuestra conclusión es que el 57% es probablemente 
una sobreestimación de la prevalencia de anemia en la población.

```{r}
#| message: false
#| warning: false
dag_1 <- dagitty('dag{"Selección" [exposure, pos = "2,1"]
  "Anemia" [outcome, pos = "-1, 2.5"]
  "Hospitalización" [pos="1,2"]
  "Enfermedad" [pos="0, 3"]
  "Hospitalización" -> "Selección"
    "Enfermedad" -> "Anemia"
    "Anemia" -> "Hospitalización"
    "Enfermedad" -> "Hospitalización"
  }')
dag_1_tidy <- tidy_dagitty(dag_1) 
dag_1_tidy |>
  ggplot(aes(x = x, y = y, xend = xend, yend = yend )) + 
  geom_dag_edges() +
  geom_dag_point(colour = "salmon", size = 20) +
  geom_dag_text(colour = "gray20") +
  theme_dag()
```

Este diagrama indica que puede ser difícil generalizar con las personas
que han sido seleccionadas, porque tanto la selección como la variable de interés
tienen una causa común: la existencia o no de una enfermedad en la persona. Será 
difícil generalizar para las personas no observadas en el estudio.

### Ejemplo: colisionadores y sesgo de selección {.unnumbered}

En los ejemplos anteriores vimos dos estructuras causales importantes
para entender cómo interpretar datos: vimos variables
*confusoras* que afectan a tratamiento y resultado (como el ejemplo
de anemia), y vimos *cadenas* (como en el ejemplo de presión alta).

Una tercera estructura importante es la de colisionador: una variable que
tiene como causa tratamiento y resultado. La interpretación de los datos
cambia dependiendo si están condicionados a un valor del colisionador o no.
Por ejemplo:

- Supongamos que queremos entender la relación en desempeño en matemáticas y
en español para estudiantes que entran a una universidad.
- Encontramos una relación negativa entre las calificaciones de los dos exámenes:
parece ser que habilidad verbal se contrapone a habilidad numérica.

¿Por qué tenemos que tener cuidado al interpretar esta correlación? ¿Existe 
esta correlación en la población general?

```{r}
library(dagitty)
library(ggdag)
dag_1 <- dagitty('dag{"Español" [exposure,pos="1,1"]
  "Mate" [outcome,pos="1,-1"]
  "Admisión" [pos="2,0"]
  "Español"  -> "Admisión"
    "Mate" -> "Admisión"
  }')
dag_1_tidy <- tidy_dagitty(dag_1) 
dag_1_tidy |>
  ggplot(aes(x = x, y = y, xend = xend, yend = yend )) + 
  geom_dag_edges() +
  geom_dag_point(colour = "salmon", size = 20) +
  geom_dag_text(colour = "gray20") +
  theme_dag()
```

- Descubrimos que la universidad hace una calificación compuesta de español
y matemáticas para que los alumnos sean aceptados en la universidad
- Esto quiere decir que para entrar es necesario al menos desempeñarse bien en alguna
de las dos

Ahora observamos que aunque en la población general no hay tal relación,
al seleccionar sólo a los alumnos de la universidad "activamos" una correlación
debido al proceso de selección:

```{r}
set.seed(823)
tibble(x = rnorm(2000), y = rnorm(2000)) |> 
  mutate(aceptados = x + y > 1.5 ) |> 
ggplot(aes(x, y, colour = aceptados)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "lm", se = FALSE)
```



### Ejemplo: sesgo de Berkson {.unnumbered}

Algunos estudios fueron publicados en la primera mitad de 2020
que notaban que el porcentaje fumadores
entre los casos positivos de COVID era menor que en la población general, y 
se hicieron algunas interpretaciones acerca de este hecho. Estos estudios 
se hicieron con personas que se hicieron una prueba.

En este ejemplo replicaremos cómo es que podemos encontrar esta asociación
en este tipo de estudios aún cuando no exista tal asociación en la población 
general (ver [este artículo](https://www.nature.com/articles/s41467-020-19478-2)). 
Usaremos datos sintéticos (simulados).

Primero vamos a razonar acerca del proceso generador de datos y a hacer
algunos supuestos:

1. En primer lugar, ¿cuándo decide hacerse alguien una prueba? A principios de 2020,
son principalmente personas que tienen síntomas considerables, y trabajadores de salud (tengan o no síntomas). 
2. Ser trabajador de salud incrementa el riesgo de contagiarse.
3. En algunos países, fumar está asociado con ser trabajador de salud (no tienen la misma tasa de tabaquismo
que la población general).
4. Sólo observamos a las personas que se hicieron una prueba.

Podemos resumir cualitativamente con el siguiente diagrama:

```{r}
library(dagitty)
library(ggdag)
dag_1 <- dagitty('dag{"Covid" [outcome, pos = "-0.5, 2.5"]
  "Prueba" [pos="0,-2"]
  "TrabSalud" [pos="0, 3"]
  "Sintomas" [pos="-1, 1"]
  "Fumar" [pos = "1, 1"]
  "TrabSalud" -> "Covid"
  "TrabSalud" -> "Prueba"
  "TrabSalud" -> "Fumar"
  "Covid" -> "Sintomas"
  "Sintomas" -> "Prueba"
  }')
dag_1_tidy <- tidy_dagitty(dag_1) 
dag_1_tidy |>
  ggplot(aes(x = x, y = y, xend = xend, yend = yend )) + 
  geom_dag_edges() +
  geom_dag_point(colour = "salmon", size = 20) +
  geom_dag_text(colour = "gray20") +
  theme_dag()
```

El código para simular es el siguiente: todas las variables toman
valores 0 o 1, pero con diferentes probabilidades y dependiendo de las
variables que son padres en la gráfica de arriba. 

1. Simulamos 100,000 personas de las cuales aproximadamente el 1% son trabajadores de salud.
2. Suponemos que el 4% de los trabajadores de salud resultaron covid positivo y el 1% del resto de las personas resultaron covid positivo. 
3. Suponemos que de las personas que tienen covid, el 50% tienen síntomas y de las personas que no tienen covid, el 1% tiene síntomas.
4. Suponemos que de los trabadores de salud el 99% se hicieron prueba (sin importar si tenían o no síntomas) y el resto de las personas se divide en 2, de los no trabadores de salud con síntomas, el 60% se hicieron una prueba y de los no trabajdores de salud sin síntomas, el 1% se hizo una prueba
5. De los trabajadores de salud, el 30% fuman, del resto de las personas el 10% fuman.


```{r}
#| code-fold: show
set.seed(821)
#simular población
n <- 1000000
trab_salud <- rbinom(n, 1, 0.01)
covid <- rbinom(n, 1, ifelse(trab_salud==1, 0.04, 0.01))
datos <- tibble(trab_salud = trab_salud, covid) |> 
  mutate(sintomas = rbernoulli(n, ifelse(covid == 1, 0.5, 0.01))) |> 
  mutate(prueba = rbernoulli(n, ifelse(trab_salud ==1, 0.99, 0.6 * sintomas + 0.01))) |> 
  mutate(fumar = rbernoulli(n, ifelse(trab_salud == 1, 0.3, 0.1))) |> 
  mutate(covid = ifelse(covid ==1, "positivo", "negativo")) |> 
  mutate(fumar = ifelse(fumar, "fuma", "no_fuma"))
```

Suponemos ahora que tomamos como muestra a *todas aquellas personas que se
hicieron una prueba*.
En primer lugar, la proporción de fumadores en la muestra es un poco más alta que la población, porque los trabajadores de salud están sobrerrepresentados

```{r}
datos_pruebas <- filter(datos, prueba == 1)
table(datos_pruebas$fumar) |> prop.table()
```

Y ahora vemos que están asociados fumar y salir positivo:

```{r}
table(datos_pruebas$covid, datos_pruebas$fumar) |> prop.table(margin = 2) |> 
  round(2)
```

En la población no existe tal asociación, además de que la tasa de positivos
es considerablemente más baja:

```{r}
table(datos$covid, datos$fumar) |> prop.table(margin = 2) |> 
  round(3)
```

- En este ejemplo, al seleccionar sólo aquellas personas que
tomaron una prueba, cambia la relación entre tener covid y ser trabajador de salud,
pues sólo los que tienen síntomas de la población general toman la prueba. Esto
produce que una prueba negativa esté más relacionada con ser trabajador de salud, y
por lo tanto, mayor probabilidad de ser fumador.
- También puede entenderse pensando que cuando tomamos solamente las personas
que se hicieron pruebas, entonces los trabajadores de salud están sobrerrepresantados
en la muestra.

## Procesos generadores de datos {.unnumbered}

Nótese que en todas estas preguntas hemos tenido que recurrir a conocimientos generales y de dominio para interpretar y hacer hipótesis acerca de lo que vemos en la gráfica. Una visión descontextualizada no tiene mucha utilidad. Las explicaciones son típicamente complejas e intervienen distintos aspectos del comportamiento de actores, sistemas, y métodos de recolección de datos involucrados.

::: callout-note
# El proceso generador de datos

Al conjunto de esos aspectos que determinan los datos que finalmente observamos le llamamos el **proceso generador de datos**. Para datos que observamos "naturalmente" este proceso
generalmente es complicado.

:::

En la Ciencia de Datos buscamos entender las partes importantes del proceso generador

- La **descripción** correcta de los datos se logra con ese entendimiento de dominio y del proceso generador.
- La formulación y refinamiento de **preguntas** importantes y sus respuestas 
acerca de estos datos requiere entendimiento de dominio y del proceso generador.
- Más tarde, veremos que la inferencia estadística también depende de este entendimiento,
junto con propuestas del **diseño estadístico** que nos permite obtener los datos
necesarios para simplificar y dar certeza en el proceso de contestar las preguntas de interés.

Mucha parte de este trabajo no es estadístico, sino que es un esfuerzo
por entender el dominio (como sugiere el título de artículo de David A. Friedman: [Statistical Models and Shoe Leather](https://psychology.okstate.edu/faculty/jgrice/psyc5314/Freedman_1991A.pdf)).


## Ejercicio: admisiones de Berkeley {.unnumbered}

Consideramos ahora los siguientes datos de admisión a distintos departamentos de Berkeley en 1975:

```{r}
data("UCBAdmissions")
adm_original <- UCBAdmissions |> as_tibble() |> 
   pivot_wider(names_from = Admit, values_from = n) 
adm_original |> knitr::kable() |> 
   kable_paper(full_width = FALSE)
```

Con algo de manipulación podemos ver tasas de admisión para *Male* y *Female*, y los totales de cada grupo que solicitaron en cada Departamento.

```{r}
adm_tbl <- adm_original |> 
   mutate(prop_adm = round(Admitted / (Admitted + Rejected), 2), total = Admitted + Rejected) |> 
   select(Gender, Dept, prop_adm, total) |> 
   pivot_wider(names_from = Gender, values_from = prop_adm:total)
adm_tbl |> knitr::kable() |> 
   kable_paper(full_width = FALSE)
```

Y complementamos con las tasas de aceptación a total por género, y tasas de aceptación por departamento:

```{r}
adm_original |> group_by(Gender) |> 
   summarise(Admitted = sum(Admitted), Rejected = sum(Rejected)) |> 
   mutate(prop_adm = round(Admitted / (Admitted + Rejected),2)) |> 
   kable() |> 
   kable_paper(full_width = FALSE)
```

```{r}
adm_original |> group_by(Dept) |> 
   summarise(Admitted = sum(Admitted), Rejected = sum(Rejected)) |> 
   mutate(prop_adm = round(Admitted / (Admitted + Rejected),2)) |> 
   kable() |> 
   kable_paper(full_width = FALSE)
```

-   Dibuja el diagrama causal
-   ¿Qué observas acerca de las tasas de admisión en cada departamento, diferenciadas por género? ¿Qué tiene qué ver con el número de personas que solicitan en cada departamento?
-   Esta es una tabla *descriptiva*. Sin embargo, tiene que ser entendida en el contexto de los datos y su generación. ¿Qué hipótesis importantes sugieren estos datos? ¿Por qué hay tanta diferencia de género de solicitudes en algunos departamentos? ¿Por qué es sorprendente o no las variaciones en tasas de aceptación de estudiantes de cada género?

## Diseño estadístico e inferencia

Una primera contribución importante de la estadística al análisis de datos
contesta la siguiente pregunta:

- El análisis correcto depende del proceso generador de datos
- Incluso cuando tenemos conocimiento detallado de dominio, es posible que algunos
de nuestros supuestos sean cuestionables.

Sin embargo,

- Si pudiéramos alterar el proceso generador de datos de alguna manera
razonable, ¿sería posible hacer un análisis que dependa de menos supuestos?
- En lugar de usar los datos que tenemos a la mano, ¿podemos pensar en una
manera de producir los datos que nos de más certeza acerca de las conclusiones 
que extraemos de ellos, y que nos permita extraer la mayor información posible?

El **diseño estadístico** (de experimentos, o de muestreo por ejemplo) nos guía
a cómo modificar el proceso generador para simplificar el análisis, y en ese
caso nos provee de herramientas para contestar preguntas de interés y cuantificar
la incertidumbre ne las respuestas. Veremos
más adelante por qué, pero por lo pronto señalamos alguna característica central:

- En los ejemplos que vimos arriba, ocurren dificultades porque la aplicación
del tratamiento o la selección de individuos depende de una variable relacionada
también con la variable respuesta que nos interesa medir. Veremos que podemos usar
*aleatorización* para cortar estas dependencias.
- El diseño de muestras y experimentos también nos provee herramientas para decidir
cuántos datos necesitamos y de qué tipo para dar respuestas con suficiente precisión para
nuestros propósitos.




